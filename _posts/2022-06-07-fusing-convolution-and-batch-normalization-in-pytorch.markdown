---
layout: post
title:  "åœ¨ PyTorch ä¸­èåˆå·ç§¯å’Œæ‰¹é‡æ ‡å‡†åŒ–"
date:   2022-06-07 00:00:00 +0800
categories: AI Optimization
tags: [Fusion, Convolution, BatchNorm, PyTorch]
---

## èåˆå·ç§¯å’Œæ‰¹é‡æ ‡å‡†åŒ–çš„åŸç†
![](/images/2022/fusion/fusing-convolution-and-batch-normalization.png)
* [PyTorch å·ç§¯ä¸BatchNormçš„èåˆ](https://zhuanlan.zhihu.com/p/49329030)

## [PyTorch çš„å®ç°](https://github.com/pytorch/pytorch/blob/master/torch/nn/utils/fusion.py)
```py
def fuse_conv_bn_eval(conv, bn, transpose=False):
    assert(not (conv.training or bn.training)), "Fusion only for eval!"
    fused_conv = copy.deepcopy(conv)

    fused_conv.weight, fused_conv.bias = \
        fuse_conv_bn_weights(fused_conv.weight, fused_conv.bias,
                             bn.running_mean, bn.running_var, bn.eps, bn.weight, bn.bias, transpose)

    return fused_conv

def fuse_conv_bn_weights(conv_w, conv_b, bn_rm, bn_rv, bn_eps, bn_w, bn_b, transpose=False):
    if conv_b is None:
        conv_b = torch.zeros_like(bn_rm)
    if bn_w is None:
        bn_w = torch.ones_like(bn_rm)
    if bn_b is None:
        bn_b = torch.zeros_like(bn_rm)
    bn_var_rsqrt = torch.rsqrt(bn_rv + bn_eps)

    if transpose:
        shape = [1, -1] + [1] * (len(conv_w.shape) - 2)
    else:
        shape = [-1, 1] + [1] * (len(conv_w.shape) - 2)

    conv_w = conv_w * (bn_w * bn_var_rsqrt).reshape(shape)
    conv_b = (conv_b - bn_rm) * bn_var_rsqrt * bn_w + bn_b

    return torch.nn.Parameter(conv_w), torch.nn.Parameter(conv_b)
```

## è¿™é‡Œä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ ResNet18 çš„ä¸¤ä¸ªå±‚æµ‹è¯•
```py
import torch
import torchvision

torch.set_grad_enabled(False)
x = torch.randn(16, 3, 256, 256)

rn18 = torchvision.models.resnet18(pretrained=True)
rn18.eval()
net = torch.nn.Sequential(
	rn18.conv1,
	rn18.bn1
)

y1 = net.forward(x)

fused_conv = torch.nn.utils.fusion.fuse_conv_bn_eval(net[0], net[1])
y2 = fused_conv.forward(x)

d = (y1 - y2).norm().div(y1.norm()).item()
print("error: %.8f" % d)
```
```
error: 0.00000022
```
* [Fusing batch normalization and convolution in runtime](https://nenadmarkus.com/p/fusing-batchnorm-and-conv/)

## æ€§èƒ½æµ‹é‡(ğŸš€25%)
```py
import timeit

starttime = timeit.default_timer()
[net.forward(x) for _ in range(100)]
print("èåˆå‰æ¨ç†100æ¬¡çš„æ—¶é—´ :", timeit.default_timer() - starttime)


starttime = timeit.default_timer()
[fused_conv.forward(x) for _ in range(100)]
print("èåˆåæ¨ç†100æ¬¡çš„æ—¶é—´ :", timeit.default_timer() - starttime)
```
```
èåˆå‰æ¨ç†100æ¬¡çš„æ—¶é—´ : 2.601980792125687
èåˆåæ¨ç†100æ¬¡çš„æ—¶é—´ : 2.0703182069119066
```
* [Python Timeit() with Examples](https://www.guru99.com/timeit-python-examples.html)

## å‚è€ƒèµ„æ–™
* [PyTorch å·ç§¯ä¸BatchNormçš„èåˆ](https://zhuanlan.zhihu.com/p/49329030)
* [Fusing batch normalization and convolution in runtime](https://nenadmarkus.com/p/fusing-batchnorm-and-conv/)
* [OpenVINO æ€§èƒ½ä¼˜åŒ–æŒ‡å—](https://docs.openvino.ai/cn/latest/openvino_docs_optimization_guide_dldt_optimization_guide.html)
* [CONV2D](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)
* [BATCHNORM1D](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm1d.html)
* [FUSING CONVOLUTION AND BATCH NORM USING CUSTOM FUNCTION](https://pytorch.org/tutorials/intermediate/custom_function_conv_bn_tutorial.html)
* [TORCH.RSQRT](https://pytorch.org/docs/stable/generated/torch.rsqrt.html)
* [æ·±åº¦å­¦ä¹ CNNç½‘ç»œæ¨ç†æ—¶Batchnormå±‚å’Œå·ç§¯å±‚çš„èåˆï¼Œä»¥æå‡æ¨ç†é€Ÿåº¦ã€‚](https://blog.csdn.net/zengwubbb/article/details/109317661)
* [Batch Normalization in Convolutional Neural Networks](https://www.baeldung.com/cs/batch-normalization-cnn)
