---
layout: single
title:  "PyTorch ç¥ç»ç½‘ç»œå®æˆ˜ï¼šä»è®­ç»ƒåˆ°æ¨ç†çš„å®Œæ•´æŒ‡å—"
date:   2025-08-21 08:00:00 +0800
categories: PyTorch DeepLearningAI
tags: [PyTorch, DeepLearningAI, MPS, MacBookProM2Max]
---

è¯¥æ–‡æœ¬æä¾›äº†ä¸€ä¸ªå…³äº**PyTorchäºŒåˆ†ç±»ç¥ç»ç½‘ç»œçš„å®ç°ä¸æ€§èƒ½åˆ†æ**çš„å…¨é¢æ¦‚è¿°ã€‚é¦–å…ˆï¼Œå®ƒé€šè¿‡**å…·ä½“ä»£ç ç¤ºä¾‹**å±•ç¤ºäº†å¦‚ä½•**æ„å»ºã€è®­ç»ƒã€è¯„ä¼°å’Œä¿å­˜ä¸€ä¸ªåŸºç¡€çš„ç¥ç»ç½‘ç»œæ¨¡å‹**ï¼Œå¹¶æ¼”ç¤ºäº†å¦‚ä½•**åŠ è½½æ¨¡å‹è¿›è¡Œæ¨ç†**ã€‚å…¶æ¬¡ï¼Œæ–‡ç« æ·±å…¥æ¢è®¨äº†**ä¸åŒæ¨¡å‹å‚æ•°è§„æ¨¡ä¸‹**ï¼Œ**Appleçš„MPSï¼ˆMetal Performance Shadersï¼‰æ¡†æ¶ä¸CPU**åœ¨**è®­ç»ƒæ—¶é—´ä¸Šçš„æ€§èƒ½å¯¹æ¯”**ï¼Œé€šè¿‡**è¡¨æ ¼æ•°æ®**æ¸…æ™°åœ°å‘ˆç°äº†**MPSåœ¨å¤„ç†å¤§å‹æ¨¡å‹æ—¶ç›¸è¾ƒäºCPUçš„æ˜¾è‘—ä¼˜åŠ¿**ï¼Œå¹¶æŒ‡å‡ºäº†**æ€§èƒ½çš„â€œè½¬æŠ˜ç‚¹â€**ã€‚

<!--more-->

æˆ‘çš„ç”µè„‘æ˜¯ Apple MacBook Pro M2 Max 16å¯¸ 64Gå†…å­˜

## PyTorch äºŒåˆ†ç±»ç¥ç»ç½‘ç»œå®ç°ä¸è®­ç»ƒç¤ºä¾‹
```python
import torch
import torch.nn.functional as F

from torch.utils.data import Dataset
from torch.utils.data import DataLoader


# æ¨¡å‹ç½‘ç»œ
class NeuralNetwork(torch.nn.Module):
    def __init__(self, num_inputs, num_outputs):
        super().__init__()

        self.layers = torch.nn.Sequential(
            torch.nn.Linear(num_inputs, 30),
            torch.nn.ReLU(),

            torch.nn.Linear(30, 20),
            torch.nn.ReLU(),

            torch.nn.Linear(20, num_outputs)
        )

    def forward(self, x):
        logits = self.layers(x)
        return logits

# æ•°æ®é›†
class MyDataset(Dataset):
    def __init__(self, X, Y):
        super().__init__()
        self.X = X
        self.Y = Y

    def __getitem__(self, index):
        return self.X[index], self.Y[index]
    
    def __len__(self):
        return self.X.shape[0]
    
X_train = torch.tensor([
    [-1.2, 3.1],
    [-0.9, 2.9],
    [-0.5, 2.6],
    [2.3, -1.1],
    [2.7, -1.5]
])
Y_train = torch.tensor([0, 0, 0, 1, 1])

X_test = torch.tensor([
    [-0.8, 2.8], 
    [2.6, -1.6]
])
Y_test = torch.tensor([0, 1])

train_ds = MyDataset(X_train, Y_train)
test_ds = MyDataset(X_test, Y_test)

# æ•°æ®åŠ è½½å™¨
torch.manual_seed(123)

train_loader = DataLoader(
    dataset=train_ds,
    batch_size=2,
    shuffle=True,
    drop_last=True,
    num_workers=0
)

test_loader = DataLoader(
    dataset=test_ds,
    batch_size=2,
    shuffle=False,
    num_workers=0
)

# è®­ç»ƒ
model = NeuralNetwork(num_inputs=2, num_outputs=2)
optimizer = torch.optim.SGD(model.parameters(), lr=0.5)

num_epochs = 3
for epoch in range(num_epochs):
    model.train()

    for batch_idx, (x, y) in enumerate(train_loader):
        logits = model(x)
        loss = F.cross_entropy(logits, y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        print(f"Epoch: {epoch+1:02d}/{num_epochs:02d}"
              f" | Batch: {batch_idx+1:02d}/{len(train_loader):02d}"
              f" | Train Loss: {loss:.2f}")

    # è¯„ä¼°
    model.eval()
    correct = 0.0
    total = 0
    for batch_idx, (x, y) in enumerate(test_loader):
        with torch.no_grad():
            logits = model(x)
        
        predictions = torch.argmax(logits, dim=1)
        compare = predictions == y
        correct += torch.sum(compare)
        total += len(compare)

        print(f"Eval Accuracy: {correct/total:.2f}")

# æ¨¡å‹å­˜å‚¨
torch.save(model.state_dict(), "model.pth") # åªä¿å­˜æ¨¡å‹å‚æ•°
```

### åŠ è½½æ¨¡å‹å¹¶æ¨ç†
```python
model = NeuralNetwork(2, 2)
model.load_state_dict(torch.load("model.pth"))

model.eval() # å…³é—­Dropoutã€BatchNormç­‰è®­ç»ƒç‰¹æ€§
with torch.no_grad(): # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜
    y = torch.argmax(mmodel(X_test), dim=-1)
```


## å‚æ•°è§„æ¨¡ä¸è®¾å¤‡ï¼ˆCPU & MPSï¼‰çš„æ€§èƒ½åˆ†æ

![](/images/2025/LLMs-from-scratch/A/loader-flow.png)

- [Taking Datasets, DataLoaders, and PyTorchâ€™s New DataPipes for a Spin](https://sebastianraschka.com/blog/2022/datapipes.html)

### æ•°æ®é›†
```python
from torch.utils.data import Dataset

class MyDataset(Dataset):
    def __init__(self, X, Y):
        super().__init__()
        self.X = X
        self.Y = Y

    def __getitem__(self, index):
        return self.X[index], self.Y[index]
    
    def __len__(self):
        return self.X.shape[0]
    
num_samples = 1000
scale = 10
num_input = 100 * scale
X_train = torch.randn(num_samples, num_input)
Y_train = torch.randint(0, 2, (num_samples,))

X_test = torch.randn(int(num_samples*0.2), num_input)
Y_test = torch.randint(0, 2, (int(num_samples*0.2),))

train_ds = MyDataset(X_train, Y_train)
test_ds = MyDataset(X_test, Y_test)
```


### æ•°æ®åŠ è½½å™¨
```python
import torch
from torch.utils.data import DataLoader

train_loader = DataLoader(
    dataset=train_ds,
    batch_size=10,
    shuffle=True,
    num_workers=0
)

test_loader = DataLoader(
    dataset=test_ds,
    batch_size=10,
    shuffle=False,
    num_workers=0
)
```

è¿™ä¸æ˜¯å¥½çš„å®è·µï¼Œå› ä¸ºè®­ç»ƒå’Œæ•°æ®åŠ è½½åœ¨åŒä¸€ä¸ª for å¾ªç¯ä¸­é¡ºåºè¿›è¡Œã€‚æ¯æ¬¡æˆ‘ä»¬åŠ è½½ä¸‹ä¸€ä¸ªå°æ‰¹é‡æ—¶ï¼Œæ¨¡å‹å’Œ GPU éƒ½å¤„äºç©ºé—²çŠ¶æ€ã€‚

![](/images/2025/LLMs-from-scratch/A/dataflow-bad.png)

ç†æƒ³æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¸Œæœ›æ¨¡å‹åœ¨åå‘è°ƒç”¨å’Œå‚æ•°æ›´æ–°ï¼ˆé€šè¿‡`.step()`ï¼‰åç«‹å³å¤„ç†ä¸‹ä¸€ä¸ªå°æ‰¹é‡ã€‚æ¢å¥è¯è¯´ï¼Œç›®æ ‡æ˜¯åœ¨æ¨¡å‹å‡†å¤‡å°±ç»ªåç«‹å³å‡†å¤‡å¥½ä¸‹ä¸€ä¸ªå°æ‰¹é‡ï¼Œå› æ­¤æˆ‘ä»¬å¸Œæœ›åœ¨æ¨¡å‹è®­ç»ƒæœŸé—´æŒç»­åœ¨åå°åŠ è½½å°æ‰¹é‡ã€‚é—æ†¾çš„æ˜¯ï¼Œç”±äº Python æœ‰ä¸€ä¸ªå…¨å±€è§£é‡Šå™¨é” (GIL)ï¼Œé»˜è®¤æƒ…å†µä¸‹åªå…è®¸å®ƒè¿è¡Œå•ä¸ªè¿›ç¨‹ï¼Œå› æ­¤æˆ‘ä»¬å¿…é¡»ç¼–å†™ä¸€ä¸ªå¤æ‚çš„è§£å†³æ–¹æ³•ã€‚

å€¼å¾—åº†å¹¸çš„æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ PyTorch çš„ `DataLoader` æ¥å®ç°è¿™ä¸€ç‚¹ã€‚DataLoader å…è®¸æˆ‘ä»¬æŒ‡å®šåŠ è½½ä¸‹ä¸€ä¸ªå°æ‰¹é‡çš„åå°è¿›ç¨‹æ•°é‡ï¼ˆ`num_workers`ï¼‰ï¼Œè¿™æ ·å°±ä¸ä¼šé˜»å¡ GPUã€‚æ ¹æ®ç»éªŒï¼Œè®¾ç½® `num_workers=4` é€šå¸¸ä¼šåœ¨è®¸å¤šçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šè·å¾—æœ€ä½³æ€§èƒ½ï¼Œä½†æœ€ä½³è®¾ç½®å–å†³äºä½ çš„ç ”ç©¶å’Œæ•°æ®é›†ã€‚

![](/images/2025/LLMs-from-scratch/A/dataflow-good.png)


### æ¨¡å‹
```python
class NeuralNetwork(torch.nn.Module):
    def __init__(self, num_inputs, num_outputs):
        super().__init__()

        self.layers = torch.nn.Sequential(
            torch.nn.Linear(num_inputs, 300 * scale),
            torch.nn.ReLU(),

            torch.nn.Linear(300 * scale, 200 * scale),
            torch.nn.ReLU(),

            torch.nn.Linear(200 * scale, num_outputs)
        )

    def forward(self, x):
        logits = self.layers(x)
        return logits
```


### è®­ç»ƒ
```python
import torch.nn.functional as F

torch.manual_seed(123)

device = torch.device(
    "mps" if torch.backends.mps.is_available() else "cpu"
)

model = NeuralNetwork(num_inputs=num_input, num_outputs=2)
model = model.to(device)
optimizer = torch.optim.SGD(model.parameters(), lr=0.5)

print("Total Parameters: ", sum(p.numel() for p in model.parameters() if p.requires_grad))

num_epochs = 10
for epoch in range(num_epochs):
    model.train()

    for batch_idx, (x, y) in enumerate(train_loader):
        x, y = x.to(device), y.to(device)

        logits = model(x)
        loss = F.cross_entropy(logits, y)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        print(f"Epoch: {epoch+1:02d}/{num_epochs:02d}"
              f" | Batch: {batch_idx+1:02d}/{len(train_loader):02d}"
              f" | Train Loss: {loss:.2f}")

    model.eval()
    correct = 0.0
    total = 0
    for batch_idx, (x, y) in enumerate(test_loader):
        x, y = x.to(device), y.to(device)
        
        with torch.no_grad():
            logits = model(x)
        
        predictions = torch.argmax(logits, dim=1)
        print(predictions, y)
        compare = predictions == y
        correct += torch.sum(compare)
        total += len(compare)

        print(f"Eval Accuracy: {correct/total:.2f}")
```


### æ€§èƒ½å¯¹æ¯”

| å‚æ•° | è®¾å¤‡ | è€—æ—¶ | é€Ÿåº¦ |
| --- | --- | --- | --- |
| 90902 | MPS | 2.6s | 0.19 |
|         | CPU | 0.5s | |
| 361802 | MPS | 3.4s | 0.23 |
|         | CPU | 0.8s | |
| 812702 | MPS | 3.1s | 0.58 |
|         | CPU | 1.8s | |
| 1443602 | MPS | 3.3s | 0.72 |
|         | CPU | 2.4s | |
| 2254502 | MPS | 3.6s | 0.94 |
|         | CPU | 3.4s | |
| **300ä¸‡** | **MPS** | | ğŸš€ `è½¬æŠ˜ç‚¹` |
| 9009002 | MPS | 4.5s | 1.66 |
|         | CPU | 7.5s | |
| 225045002 | MPS | 23.2s | 6.37 |
|           | CPU | 2m 27.9s | |
| 506317502 | MPS | 57.7s | 5.58 |
|           | CPU | 5m 37.2s | |
| 900090002 | MPS | 1m 44s | 5.53 |
|           | CPU | 9m 35.2s | |
