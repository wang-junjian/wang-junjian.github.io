---
layout: single
title:  "OpenAI API Documentation Embeddings"
date:   2023-04-25 08:00:00 +0800
categories: OpenAI-API-Embedding
tags: ["OpenAI API", Embedding, Faiss]
---

## [ä»€ä¹ˆæ˜¯ Embeddingï¼Ÿ](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)
æ–‡æœ¬åµŒå…¥ç”¨äºè¡¡é‡æ–‡æœ¬å­—ç¬¦ä¸²çš„ç›¸å…³æ€§ã€‚åµŒå…¥é€šå¸¸ç”¨äºï¼š
* æœç´¢ï¼ˆç»“æœæŒ‰ä¸æŸ¥è¯¢å­—ç¬¦ä¸²çš„ç›¸å…³æ€§æ’åºï¼‰
* èšç±»ï¼ˆå…¶ä¸­æ–‡æœ¬å­—ç¬¦ä¸²æŒ‰ç›¸ä¼¼æ€§åˆ†ç»„ï¼‰
* æ¨èï¼ˆæ¨èå…·æœ‰ç›¸å…³æ–‡æœ¬å­—ç¬¦ä¸²çš„é¡¹ç›®ï¼‰
* å¼‚å¸¸æ£€æµ‹ï¼ˆè¯†åˆ«å‡ºç›¸å…³æ€§å¾ˆå°çš„å¼‚å¸¸å€¼ï¼‰
* å¤šæ ·æ€§æµ‹é‡ï¼ˆåˆ†æç›¸ä¼¼æ€§åˆ†å¸ƒï¼‰
* åˆ†ç±»ï¼ˆå…¶ä¸­æ–‡æœ¬å­—ç¬¦ä¸²æŒ‰å…¶æœ€ç›¸ä¼¼çš„æ ‡ç­¾åˆ†ç±»ï¼‰

`åµŒå…¥æ˜¯æµ®ç‚¹æ•°çš„å‘é‡ï¼ˆåˆ—è¡¨ï¼‰ã€‚ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„è·ç¦»è¡¡é‡å®ƒä»¬çš„ç›¸å…³æ€§ã€‚å°è·ç¦»è¡¨ç¤ºé«˜ç›¸å…³æ€§ï¼Œå¤§è·ç¦»è¡¨ç¤ºä½ç›¸å…³æ€§ã€‚`

## [å¦‚ä½•è·å¾— Embeddingï¼Ÿ](https://platform.openai.com/docs/guides/embeddings/how-to-get-embeddings)
### [Embedding API](https://platform.openai.com/docs/api-reference/embeddings)
#### è¯·æ±‚æ ¼å¼
```json
{
  "input": "A string to be embedded",
  "model": "text-embedding-ada-002"
}
```

#### å“åº”æ ¼å¼
```json
{
  "data": [
    {
      "embedding": [
        -0.02181987278163433,
        ...
        -0.0034146346151828766
      ],
      "index": 0,
      "object": "embedding"
    }
  ],
  "model": "text-embedding-ada-002-v2",
  "object": "list",
  "usage": {
    "prompt_tokens": 1,
    "total_tokens": 1
  }
}
```

### è·å¾—ä¸€ä¸ªå­—ç¬¦ä¸²çš„ Embedding
```py
embedding = openai.Embedding.create(input = "Hello", model="text-embedding-ada-002").data[0].embedding
print(len(embedding), embedding)
```
```
1536 [-0.021849708631634712, -0.007138177752494812, ..., -0.004309536889195442, -0.0034034624695777893]
```

### è·å¾—å¤šä¸ªå­—ç¬¦ä¸²çš„ Embedding
```py
embeddings = [data.embedding for data in openai.Embedding.create(input = ['Hi', 'Hello', 'ä½ å¥½', 'æ‚¨å¥½'], model="text-embedding-ada-002").data]
```

## [ä½™å¼¦ç›¸ä¼¼æ€§](https://zh.wikipedia.org/wiki/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E6%80%A7)
### ä»‹ç»
ä½™å¼¦ç›¸ä¼¼æ€§é€šè¿‡æµ‹é‡ä¸¤ä¸ªå‘é‡çš„å¤¹è§’çš„ä½™å¼¦å€¼æ¥åº¦é‡å®ƒä»¬ä¹‹é—´çš„ç›¸ä¼¼æ€§ã€‚0åº¦è§’çš„ä½™å¼¦å€¼æ˜¯1ï¼Œè€Œå…¶ä»–ä»»ä½•è§’åº¦çš„ä½™å¼¦å€¼éƒ½ä¸å¤§äº1ï¼›å¹¶ä¸”å…¶æœ€å°å€¼æ˜¯-1ã€‚ä»è€Œä¸¤ä¸ªå‘é‡ä¹‹é—´çš„è§’åº¦çš„ä½™å¼¦å€¼ç¡®å®šä¸¤ä¸ªå‘é‡æ˜¯å¦å¤§è‡´æŒ‡å‘ç›¸åŒçš„æ–¹å‘ã€‚ä¸¤ä¸ªå‘é‡æœ‰ç›¸åŒçš„æŒ‡å‘æ—¶ï¼Œä½™å¼¦ç›¸ä¼¼åº¦çš„å€¼ä¸º1ï¼›ä¸¤ä¸ªå‘é‡å¤¹è§’ä¸º90Â°æ—¶ï¼Œä½™å¼¦ç›¸ä¼¼åº¦çš„å€¼ä¸º0ï¼›ä¸¤ä¸ªå‘é‡æŒ‡å‘å®Œå…¨ç›¸åçš„æ–¹å‘æ—¶ï¼Œä½™å¼¦ç›¸ä¼¼åº¦çš„å€¼ä¸º-1ã€‚è¿™ç»“æœæ˜¯ä¸å‘é‡çš„é•¿åº¦æ— å…³çš„ï¼Œä»…ä»…ä¸å‘é‡çš„æŒ‡å‘æ–¹å‘ç›¸å…³ã€‚ä½™å¼¦ç›¸ä¼¼åº¦é€šå¸¸ç”¨äºæ­£ç©ºé—´ï¼Œå› æ­¤ç»™å‡ºçš„å€¼ä¸º0åˆ°1ä¹‹é—´ã€‚

æ³¨æ„è¿™ä¸Šä¸‹ç•Œå¯¹ä»»ä½•ç»´åº¦çš„å‘é‡ç©ºé—´ä¸­éƒ½é€‚ç”¨ï¼Œè€Œä¸”ä½™å¼¦ç›¸ä¼¼æ€§æœ€å¸¸ç”¨äºé«˜ç»´æ­£ç©ºé—´ã€‚ä¾‹å¦‚åœ¨ä¿¡æ¯æ£€ç´¢ä¸­ï¼Œæ¯ä¸ªè¯é¡¹è¢«èµ‹äºˆä¸åŒçš„ç»´åº¦ï¼Œè€Œä¸€ä¸ªæ–‡æ¡£ç”±ä¸€ä¸ªå‘é‡è¡¨ç¤ºï¼Œå…¶å„ä¸ªç»´åº¦ä¸Šçš„å€¼å¯¹åº”äºè¯¥è¯é¡¹åœ¨æ–‡æ¡£ä¸­å‡ºç°çš„é¢‘ç‡ã€‚ä½™å¼¦ç›¸ä¼¼åº¦å› æ­¤å¯ä»¥ç»™å‡ºä¸¤ç¯‡æ–‡æ¡£åœ¨å…¶ä¸»é¢˜æ–¹é¢çš„ç›¸ä¼¼åº¦ã€‚

OpenAI æ¨èä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—è·ç¦»ã€‚è·ç¦»å‡½æ•°çš„é€‰æ‹©é€šå¸¸æ— å…³ç´§è¦ï¼Œä½†æ˜¯ï¼Œä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—è·ç¦»çš„é€Ÿåº¦æ¯”æ¬§å‡ é‡Œå¾—è·ç¦»å¿«å¾—å¤šï¼Œå› ä¸ºå®ƒä¸éœ€è¦è®¡ç®—å¹³æ–¹æ ¹ã€‚æ­¤å¤–ï¼Œä½™å¼¦ç›¸ä¼¼åº¦çš„èŒƒå›´æ˜¯[-1,1]ï¼Œè€Œæ¬§å‡ é‡Œå¾—è·ç¦»çš„èŒƒå›´æ˜¯[0,âˆ)ã€‚å› æ­¤ï¼Œä½™å¼¦ç›¸ä¼¼åº¦çš„èŒƒå›´æ›´é€‚åˆäºæœç´¢ã€‚

## é›¶æ ·æœ¬åˆ†ç±»
### å¥½è¯„å·®è¯„åˆ†ç±»ï¼ˆcosine_similarityï¼‰
```py

from openai.embeddings_utils import cosine_similarity, get_embedding

# é€‰æ‹©ä½¿ç”¨æœ€å°çš„adaæ¨¡å‹
model = "text-embedding-ada-002"

# è·å–"å¥½è¯„"å’Œ"å·®è¯„"çš„
good_embedding = get_embedding("å¥½", engine=model)
bad_embedding = get_embedding("å", engine=model)
class_embeddings = (good_embedding, bad_embedding)

good_example = get_embedding("ä¹°çš„é“¶è‰²ç‰ˆçœŸçš„å¾ˆå¥½çœ‹ï¼Œä¸€å¤©å°±åˆ°äº†ï¼Œæ™šä¸Šå°±å¼€å§‹æ‹¿èµ·æ¥å®Œç³»ç»Ÿå¾ˆä¸æ»‘æµç•…ï¼Œåšå·¥æ‰å®ï¼Œæ‰‹æ„Ÿç»†è…»ï¼Œå¾ˆç²¾è‡´å“¦è‹¹æœä¸€å¦‚æ—¢å¾€çš„å¥½å“è´¨", engine=model)
bad_example = get_embedding("é™ä»·å‰å®³ï¼Œä¿ä»·ä¸åˆç†ï¼Œä¸æ¨è", engine=model)

def get_score(embedding, class_embeddings):
  good_embedding, bad_embedding = class_embeddings
  return cosine_similarity(embedding, good_embedding) - cosine_similarity(embedding, bad_embedding)

print("å¥½è¯„ä¾‹å­çš„è¯„åˆ† : %f" % get_score(good_example, class_embeddings))
print("å·®è¯„ä¾‹å­çš„è¯„åˆ† : %f" % get_score(bad_example, class_embeddings))
```

```
å¥½è¯„ä¾‹å­çš„è¯„åˆ† : 0.036553
å·®è¯„ä¾‹å­çš„è¯„åˆ† : -0.026165
```


{% highlight wjj %}
å€¼ = è¯„è®ºçš„embeddingä¸å¥½è¯„embeddingçš„ä½™å¼¦ç›¸ä¼¼åº¦ - è¯„è®ºembeddingä¸å·®è¯„embeddingçš„ä½™å¼¦ç›¸ä¼¼åº¦
å€¼ > 0ï¼Œå€¾å‘äºå¥½è¯„
å€¼ < 0ï¼Œå€¾å‘äºå·®è¯„
{% endhighlight %}


### å¥½è¯„å·®è¯„åˆ†ç±»ï¼ˆdistances_from_embeddingsï¼‰
```py
import pandas as pd
from openai.embeddings_utils import distances_from_embeddings, get_embedding

# é€‰æ‹©ä½¿ç”¨æœ€å°çš„adaæ¨¡å‹
model = "text-embedding-ada-002"

# è·å–è¯„ä»·çš„ embedding
df_good_bad = pd.DataFrame({'evaluation': ['å¥½', 'å']})
df_good_bad['embedding'] = df_good_bad['evaluation'].apply(lambda x: get_embedding(x, engine=model))

comments = [
    'ä¹°çš„é“¶è‰²ç‰ˆçœŸçš„å¾ˆå¥½çœ‹ï¼Œä¸€å¤©å°±åˆ°äº†ï¼Œæ™šä¸Šå°±å¼€å§‹æ‹¿èµ·æ¥å®Œç³»ç»Ÿå¾ˆä¸æ»‘æµç•…ï¼Œåšå·¥æ‰å®ï¼Œæ‰‹æ„Ÿç»†è…»ï¼Œå¾ˆç²¾è‡´å“¦è‹¹æœä¸€å¦‚æ—¢å¾€çš„å¥½å“è´¨',
    'é™ä»·å‰å®³ï¼Œä¿ä»·ä¸åˆç†ï¼Œä¸æ¨è',
]

df_comments = pd.DataFrame({'comment': comments, 'evaluation': ['', '']})
df_comments['embedding'] = df_comments['comment'].apply(lambda x: get_embedding(x, engine=model))
df_comments['evaluation'] = '' # å¢åŠ ç©ºåˆ—

for i, row in df_comments.iterrows():
    df_good_bad['distance'] = distances_from_embeddings(row['embedding'], df_good_bad['embedding'])
    df_comments.at[i, 'evaluation'] = df_good_bad.sort_values(by='distance', ascending=True)['evaluation'].values[0]

df_comments[['comment', 'evaluation']]
```

|    | comment                                                                                                              | evaluation   |
|---:|:---------------------------------------------------------------------------------------------------------------------|:-------------|
|  0 | ä¹°çš„é“¶è‰²ç‰ˆçœŸçš„å¾ˆå¥½çœ‹ï¼Œä¸€å¤©å°±åˆ°äº†ï¼Œæ™šä¸Šå°±å¼€å§‹æ‹¿èµ·æ¥å®Œç³»ç»Ÿå¾ˆä¸æ»‘æµç•…ï¼Œåšå·¥æ‰å®ï¼Œæ‰‹æ„Ÿç»†è…»ï¼Œå¾ˆç²¾è‡´å“¦è‹¹æœä¸€å¦‚æ—¢å¾€çš„å¥½å“è´¨                     | å¥½           |
|  1 | é™ä»·å‰å®³ï¼Œä¿ä»·ä¸åˆç†ï¼Œä¸æ¨è                                                                                              | å           |


{% highlight wjj %}
distances_from_embeddings è¿”å›çš„å€¼è¶Šå°ï¼Œè¶Šç›¸ä¼¼ã€‚
{% endhighlight %}


## [Kaggle æä¾›çš„äºšé©¬é€Šè€³æœºè¯„è®ºæ•°æ®é›†](https://www.kaggle.com/datasets/shitalkat/amazonearphonesreviews)
### ç”Ÿæˆ Embedding
```py
model = "text-embedding-ada-002"

def get_good_bad_embeddings(good='good', bad='bad', model=model):
    good_embedding = get_embedding(good, engine=model)
    bad_embedding = get_embedding(bad, engine=model)
    return [good_embedding, bad_embedding]

def is_good_bad(comment_embedding, good_bad_embeddings):
    good_embedding, bad_embedding = good_bad_embeddings
    return 'Good' if cosine_similarity(comment_embedding, good_embedding) - cosine_similarity(comment_embedding, bad_embedding)>0 else 'Bad'

good_bad_embeddings = get_good_bad_embeddings(good='good', bad='bad')

# åŠ è½½æ•°æ®
df_all_product_reviews = pd.read_csv('Datasets/AllProductReviews.csv')

# éšæœºæŠ½å–100æ¡è¯„è®º
df_product_reviews = df_all_product_reviews.sample(100).copy().reset_index(drop=True)

# å°†è¯„è®ºæ ‡é¢˜å’Œè¯„è®ºå†…å®¹æ‹¼æ¥èµ·æ¥ç”Ÿæˆ Embedding
df_product_reviews['embedding'] = df_product_reviews.apply(lambda x: get_embedding(x['ReviewTitle']+x['ReviewBody'], engine=model), axis=1)
```

### è¯„ä»·å¥½ååˆ†ç±»
```py
def check_human_and_ai(review_star, review):
    return True if (review_star>=3 and review=='Good') or (review_star<3 and review=='Bad') else False

df_product_reviews['HumanReview'] = df_product_reviews['ReviewStar'].apply(lambda x: 'Good' if x>=3 else 'Bad')
df_product_reviews['AIReview'] = df_product_reviews['embedding'].apply(lambda x: is_good_bad(x, good_bad_embeddings))
df_product_reviews['Check_Human_AI'] = df_product_reviews.apply(lambda x: check_human_and_ai(x['ReviewStar'], x['AIReview']), axis=1)

# ç»“æœç»Ÿè®¡
df_product_reviews['Check_Human_AI'].value_counts()
```
```
Check_Human_AI
True     91
False     9
Name: count, dtype: int64
```

### æŒ‡æ ‡è¯„ä¼°ï¼ˆPrecision, Recall, F1-Scoreï¼‰
```py
from sklearn.metrics import classification_report

# è¯„ä¼°
report = classification_report(df_product_reviews['HumanReview'], df_product_reviews['AIReview'])
print(report)
```
```
              precision    recall  f1-score   support

         Bad       0.85      0.74      0.79        23
        Good       0.93      0.96      0.94        77

    accuracy                           0.91       100
   macro avg       0.89      0.85      0.87       100
weighted avg       0.91      0.91      0.91       100
```

### ç»˜åˆ¶ Precision-Recall æ›²çº¿
```py
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay

# ç»˜å›¾ä¸èƒ½ä½¿ç”¨å­—ç¬¦ä¸²ç±»å‹çš„æ•°æ®ï¼Œéœ€è¦è½¬æ¢æˆæ•°å€¼ç±»å‹
y_true = [1 if x=='Good' else 0 for x in df_product_reviews['HumanReview']]
y_pred = [1 if x=='Good' else 0 for x in df_product_reviews['AIReview']]

# ç»˜åˆ¶ Precision-Recall æ›²çº¿
precision, recall, _ = precision_recall_curve(y_true, y_pred)
disp = PrecisionRecallDisplay(precision=precision, recall=recall)
disp.plot()
plt.show()
```

## è¯­ä¹‰æ£€ç´¢
### è·Ÿæ¯ä¸€æ¡è¯„è®ºè®¡ç®—è·ç¦»ï¼Œç„¶åå‡åºæ’åº
```py
query_embedding = get_embedding('Best Bluetooth headset', engine=model)

def search_product(df, query_embedding, top_k=3):
    df['distance'] = distances_from_embeddings(query_embedding, df['embedding'])
    return df.sort_values(by='distance', ascending=True).head(top_k)

search_product(df_product_reviews, query_embedding)[['ReviewTitle', 'ReviewBody', 'ReviewStar', 'distance']]
```

### ä½¿ç”¨ [Faiss](https://faiss.ai) åŠ é€Ÿ
Faiss æ˜¯ä¸€ä¸ªç”¨äº`é«˜æ•ˆç›¸ä¼¼æ€§æœç´¢`å’Œ`å¯†é›†å‘é‡èšç±»`çš„åº“ã€‚å®ƒåŒ…å«æœç´¢ä»»ä½•å¤§å°çš„å‘é‡é›†çš„ç®—æ³•ï¼Œæ•°æ®å­˜å‚¨åœ¨å†…å­˜ä¸­ã€‚

* [GitHub Faiss](https://github.com/facebookresearch/faiss)

#### å®‰è£…
##### CPU
```shell
conda install -c pytorch faiss-cpu
```

##### GPU
```shell
conda install -c pytorch faiss-gpu
```

#### å®ç°
```py
import faiss
import numpy as np

def load_faiss_index(df, column='embedding'):
    embeddings = df[column].tolist()
    embeddings = np.array(embeddings).astype('float32')
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return index

index = load_faiss_index(df_product_reviews)
distances, indexes = index.search(np.array(query_embedding).astype('float32').reshape(1, -1), k=3)
df_product_reviews.iloc[indexes[0]][['ReviewTitle', 'ReviewBody', 'ReviewStar']]
```

#### æ€§èƒ½å¯¹æ¯”ï¼ˆğŸš€ æå‡äº† 354 å€ï¼‰
##### ä½™å¼¦è·ç¦»è®¡ç®—
```py
for _ in range(1000):
    search_product(df_product_reviews, query_embedding)
```
```
7.8s
```

##### Faiss è®¡ç®—
```py
q = np.array(query_embedding).astype('float32').reshape(1, -1)
for _ in range(100000):
    index.search(q, k=3)
```
```
2.2s
```
