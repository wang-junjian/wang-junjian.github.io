---
layout: single
title:  "AI å¤§æ¨¡å‹"
date:   2023-07-24 08:00:00 +0800
categories: ChatGPT
tags: [LLM, GPT, Data, SAM]
---

## ğŸ”¥ å¤§æ¨¡å‹
### [ChatGPT](https://chat.openai.com)
### [è®¯é£æ˜Ÿç«](https://xinghuo.xfyun.cn/desk)
### [æ´»å­—é€šç”¨å¤§æ¨¡å‹](https://github.com/HIT-SCIR/huozi)

## ğŸ”¥ Andrej Karpathy
### [State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A)
* [å¾®è½¯2023å¹´Buildå¤§ä¼šæ¼”è®²ï¼šå¦‚ä½•è®­ç»ƒå’Œåº”ç”¨GPT](https://www.youtube.com/watch?v=YrBJiy-V8MY)
* [State of GPT ç¬”è®°]({% post_url 2023-05-30-state-of-gpt %})

## ğŸ”¥ ææ²
### è®ºæ–‡ç²¾è¯»
* [å¦‚ä½•è¯»è®ºæ–‡](https://www.youtube.com/watch?v=txjl_Q4jCyQ)
* [AlexNet](https://www.youtube.com/watch?v=zjnxu8KUYKA)
* [ResNet](https://www.youtube.com/watch?v=pWMnzCX4cwQ)
* [é›¶åŸºç¡€å¤šå›¾è¯¦è§£å›¾ç¥ç»ç½‘ç»œï¼ˆGNN/GCNï¼‰](https://www.youtube.com/watch?v=sejA2PtCITw)
* [GAN](https://www.youtube.com/watch?v=g_0HtlrLiDo)
* [Transformer](https://www.youtube.com/watch?v=nzqlFIcCSWQ)
* [BERT](https://www.youtube.com/watch?v=ULD3uIb2MHQ)
    * [Pre-training](https://youtu.be/ULD3uIb2MHQ?t=104)
* [ViT](https://www.youtube.com/watch?v=FRFt3x0bO94)
    * [å·ç§¯ç¥ç»ç½‘ç»œçš„ä¸¤ä¸ªå½’çº³åç½®ï¼š1ã€localityï¼ˆç›¸åŒåŒºåŸŸæœ‰ç›¸åŒçš„ç‰¹å¾ï¼‰ï¼›2ã€translation equivarianceï¼ˆå¹³ç§»ç­‰å˜æ€§ï¼‰](https://youtu.be/FRFt3x0bO94?t=1004)
    * [local neighborhoods](https://youtu.be/FRFt3x0bO94?t=1585)
* [MAE](https://www.youtube.com/watch?v=mYlX2dpdHHM)
    * [Autoencoder](https://youtu.be/mYlX2dpdHHM?t=222)
* [å¯¹æ¯”å­¦ä¹ è®ºæ–‡ç»¼è¿°](https://www.youtube.com/watch?v=1pvxufGRuW4)
    * [æ•°æ®å¢å¼ºï¼šCrop å’Œ Color çš„ç»„åˆæœ€æœ‰æ•ˆ](https://youtu.be/1pvxufGRuW4?t=1694)
* [MoCo](https://www.youtube.com/watch?v=pXvMXfPJZ2M)
* [CLIP](https://www.youtube.com/watch?v=OZF1t_Hieq8)
    * [How to Train Really Large Models on Many GPUs?](https://lilianweng.github.io/posts/2021-09-25-train-large/)
    * [Zero-Shot Transfer](https://youtu.be/OZF1t_Hieq8?t=3143)
    * [Using Zero-Shot Transfer](https://youtu.be/OZF1t_Hieq8?t=3222)
    * [PROMPT ENGINEERING AND ENSEMBLING](https://youtu.be/OZF1t_Hieq8?t=3434)
    * [Prompt Engineering for ImageNet](https://github.com/openai/CLIP/blob/main/notebooks/Prompt_Engineering_for_ImageNet.ipynb)
    * [åœ¨ 27 ä¸ªæ•°æ®é›†ä¸Šæµ‹è¯• Zero-Shot](https://youtu.be/OZF1t_Hieq8?t=3813)
* [DALLÂ·E 2](https://www.youtube.com/watch?v=hO57mntSMl0)
    * [GAN]()
    * [Autoencoder](https://youtu.be/hO57mntSMl0?t=1833)
    * [DAE(Denoising Autoencoder)](https://youtu.be/hO57mntSMl0?t=1870)
    * [VAE(Variational Autoencoder)](https://youtu.be/hO57mntSMl0?t=1976)
    * [VQVAE(Vector Quantized Variational Autoencoder)](https://youtu.be/hO57mntSMl0?t=2100)
    * [VQVAE2](https://youtu.be/hO57mntSMl0?t=2330)
    * [DALLÂ·E](https://youtu.be/hO57mntSMl0?t=2384)
    * [Diffusion Model](https://youtu.be/hO57mntSMl0?t=2488)
    * [U-Net](https://youtu.be/hO57mntSMl0?t=2690)
    * [æ‰©æ•£æ¨¡å‹çš„å‘å±•å†ç¨‹](https://youtu.be/hO57mntSMl0?t=2738)
        * [DDPM(Denoising Diffusion Probabilistic Models)](https://youtu.be/hO57mntSMl0?t=2762)
        * [Improved DDPM](https://youtu.be/hO57mntSMl0?t=3125)
        * [Diffusion Models Beat GANs](https://youtu.be/hO57mntSMl0?t=3189)
* [CLIP æ”¹è¿›å·¥ä½œä¸²è®²ï¼ˆä¸Šï¼‰](https://www.youtube.com/watch?v=x4CDhZz_Dvg)
* [CLIP æ”¹è¿›å·¥ä½œä¸²è®²ï¼ˆä¸‹ï¼‰](https://www.youtube.com/watch?v=ugJeBivv65s)
* [ViLT](https://www.youtube.com/watch?v=ug8YvZOjOCE)
* [GPTï¼ŒGPT-2ï¼ŒGPT-3](https://www.youtube.com/watch?v=t70Bl3w7bxY)
* [OpenAI Codex](https://www.youtube.com/watch?v=oZriUGkQSNM)
    * [HumanEval: Hand-Written Evaluation Set](https://github.com/openai/human-eval)
* [DeepMind AlphaCode](https://www.youtube.com/watch?v=t8Gzkca9pW4)
* [InstructGPT](https://www.youtube.com/watch?v=zfIGAwD1jOQ)
    * [aligned](https://youtu.be/zfIGAwD1jOQ?t=615)
    * [RLHF](https://youtu.be/zfIGAwD1jOQ?t=992)
    * [Train InstructGPT Models](https://youtu.be/zfIGAwD1jOQ?t=1337)
* [GPT-4](https://www.youtube.com/watch?v=K0SZ9mdygTw)

## ğŸ”¥ æå®æ¯…
### [MACHINE LEARNING 2023 SPRING](https://speech.ee.ntu.edu.tw/~hylee/ml/2023-spring.php)
* [ã€DLHLP 2020ã€‘ä¾†è‡ªçµäººæš—é»‘å¤§é™¸çš„æ¨¡å‹ GPT-3](https://www.youtube.com/watch?v=DOG1L9lvsDY)
* [ã€æ©Ÿå™¨å­¸ç¿’2021ã€‘Transformer (ä¸Š)](https://www.youtube.com/watch?v=n9TlOhRjYoc)
* [ã€æ©Ÿå™¨å­¸ç¿’2021ã€‘Transformer (ä¸‹)](https://www.youtube.com/watch?v=N6aRv06iv2g)
* [ML Lecture 6: Brief Introduction of Deep Learning](https://www.youtube.com/watch?v=Dr-WRlEFefw)
### [æ©Ÿå™¨å­¸ç¿’2022](https://www.youtube.com/watch?v=7XZR0-4uS5s&list=PLJV_el3uVTsPM2mM-OQzJXziCGJa8nJL8)
### [æ©Ÿå™¨å­¸ç¿’2021](https://www.youtube.com/playlist?list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J)
### [Machine Learning (Hung-yi Lee, NTU)](https://www.youtube.com/playlist?list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49)

## ğŸ”¥ DeepLearning.AI è¯¾ç¨‹ [ä¸­æ–‡è§†é¢‘](https://www.bilibili.com/video/BV1Bo4y1A7FU/)
### [ChatGPT Prompt Engineering for Developers](https://learn.deeplearning.ai/chatgpt-prompt-eng)
[ä¸­æ–‡ç¬”è®°](https://github.com/datawhalechina/prompt-engineering-for-developers/tree/main/content/Prompt%20Engineering)
### [LangChain for LLM Application Development](https://learn.deeplearning.ai/langchain)
[ä¸­æ–‡ç¬”è®°](https://github.com/datawhalechina/prompt-engineering-for-developers/tree/main/content/LangChain%20for%20LLM%20Application%20Development)
### [Building Systems with the ChatGPT API](https://learn.deeplearning.ai/chatgpt-building-system)
[ä¸­æ–‡ç¬”è®°](https://github.com/datawhalechina/prompt-engineering-for-developers/tree/main/content/Building%20Systems%20with%20the%20ChatGPT%20API)
### [How Diffusion Models Work](https://learn.deeplearning.ai/diffusion-models)

## ğŸ”¥ Datawhale
### [Bilibili Datawhale](https://space.bilibili.com/431850986)
### [GitHub Datawhale]
### [HuggingLLM](https://github.com/datawhalechina/hugging-llm)

## ğŸ”¥ å¼€å‘æ–‡æ¡£
### [OpenAI Cookbook](https://github.com/openai/openai-cookbook)
### [LangChain](https://github.com/hwchase17/langchain)

## ğŸ”¥ ç›¸å…³æ–‡æ¡£
* [Building the New Bing](https://blogs.bing.com/search-quality-insights/february-2023/Building-the-New-Bing)

## ğŸ”¥ æ•°æ®
### æŒ‡ä»¤æ•°æ®ï¼ˆç”¨äºå¾®è°ƒï¼‰
* [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter/blob/main/llama_adapter_v2_multimodal/docs/train.md)
    * [alpaca_gpt4_data.json](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data.json)
    * [alpaca_gpt4_data_zh.json](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json)
    * [llava_instruct_150k.json](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K/raw/main/llava_instruct_150k.json)
    * [alpaca_data_zh_51k.json](https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/data/alpaca_data_zh_51k.json)

## ğŸ”¥ æµ‹è¯„åŸºå‡†
### [é€šç”¨è¯­è¨€ç†è§£æµ‹è¯„åŸºå‡† CLUE](https://gluebenchmark.com/)
é€šç”¨è¯­è¨€ç†è§£è¯„ä¼° (GLUE) åŸºå‡†æ˜¯ç”¨äºè®­ç»ƒã€è¯„ä¼°å’Œåˆ†æè‡ªç„¶è¯­è¨€ç†è§£ç³»ç»Ÿçš„èµ„æºé›†åˆã€‚
* ä¹ä¸ªå¥å­æˆ–å¥å­å¯¹è¯­è¨€ç†è§£ä»»åŠ¡çš„åŸºå‡†ï¼Œå»ºç«‹åœ¨å·²å»ºç«‹çš„ç°æœ‰æ•°æ®é›†ä¸Šï¼Œå¹¶é€‰æ‹©è¦†ç›–å„ç§æ•°æ®é›†å¤§å°ã€æ–‡æœ¬ç±»å‹å’Œéš¾åº¦ï¼Œ
* è¯Šæ–­æ•°æ®é›†ï¼Œæ—¨åœ¨è¯„ä¼°å’Œåˆ†æè‡ªç„¶è¯­è¨€ä¸­å‘ç°çš„å„ç§è¯­è¨€ç°è±¡çš„æ¨¡å‹æ€§èƒ½ï¼Œä»¥åŠ
* ç”¨äºè·Ÿè¸ªåŸºå‡†æ€§èƒ½çš„å…¬å…±æ’è¡Œæ¦œå’Œç”¨äºå¯è§†åŒ–è¯Šæ–­é›†ä¸Šæ¨¡å‹æ€§èƒ½çš„ä»ªè¡¨æ¿ã€‚

GLUE åŸºå‡†æµ‹è¯•çš„æ ¼å¼ä¸æ¨¡å‹æ— å…³ï¼Œå› æ­¤ä»»ä½•èƒ½å¤Ÿå¤„ç†å¥å­å’Œå¥å­å¯¹å¹¶äº§ç”Ÿç›¸åº”é¢„æµ‹çš„ç³»ç»Ÿéƒ½æœ‰èµ„æ ¼å‚ä¸ã€‚ é€‰æ‹©åŸºå‡†ä»»åŠ¡æ˜¯ä¸ºäº†æ”¯æŒä½¿ç”¨å‚æ•°å…±äº«æˆ–å…¶ä»–è¿ç§»å­¦ä¹ æŠ€æœ¯è·¨ä»»åŠ¡å…±äº«ä¿¡æ¯çš„æ¨¡å‹ã€‚ GLUE çš„æœ€ç»ˆç›®æ ‡æ˜¯æ¨åŠ¨é€šç”¨ä¸”å¼ºå¤§çš„è‡ªç„¶è¯­è¨€ç†è§£ç³»ç»Ÿçš„å¼€å‘ç ”ç©¶ã€‚

### [ä¸­æ–‡è¯­è¨€ç†è§£æµ‹è¯„åŸºå‡†(CLUE)](https://cluebenchmarks.com/)
ä¸­æ–‡è¯­è¨€ç†è§£æµ‹è¯„åŸºå‡†ï¼ŒåŒ…æ‹¬ä»£è¡¨æ€§çš„æ•°æ®é›†ã€åŸºå‡†(é¢„è®­ç»ƒ)æ¨¡å‹ã€è¯­æ–™åº“ã€æ’è¡Œæ¦œã€‚æˆ‘ä»¬ä¼šé€‰æ‹©ä¸€ç³»åˆ—æœ‰ä¸€å®šä»£è¡¨æ€§çš„ä»»åŠ¡å¯¹åº”çš„æ•°æ®é›†ï¼Œåšä¸ºæˆ‘ä»¬æµ‹è¯•åŸºå‡†çš„æ•°æ®é›†ã€‚è¿™äº›æ•°æ®é›†ä¼šè¦†ç›–ä¸åŒçš„ä»»åŠ¡ã€æ•°æ®é‡ã€ä»»åŠ¡éš¾åº¦ã€‚

### [SUPERB(Speech processing Universal PERformance Benchmark)](https://superbbenchmark.org)


## [Segment Anything](https://segment-anything.com/)
### [Demo](https://segment-anything.com/demo)
### [è®ºæ–‡ï¼ˆä¸­æ–‡ï¼‰](https://zhuanlan.zhihu.com/p/619962145)
### [GitHub](https://github.com/facebookresearch/segment-anything)

## Grounded-Segment-Anything
### [HuggingFace](https://huggingface.co/spaces/yizhangliu/Grounded-Segment-Anything)
### [GitHub](https://github.com/IDEA-Research/Grounded-Segment-Anything)

## å‚è€ƒèµ„æ–™
* [FastSAM](https://github.com/CASIA-IVA-Lab/FastSAM)
* [Recognize Anything](https://recognize-anything.github.io/)


## ğŸ”¥ AI åº”ç”¨
* [CodeGeeX](https://codegeex.cn/zh-CN)


## äººå·¥æ™ºèƒ½ä¼šè®®
[2023 ä¸–ç•Œäººå·¥æ™ºèƒ½å¤§ä¼š - WORLD ARTIFICIAL INTELLIGENCE CONFERENCEï¼ˆWAICï¼‰](https://www.worldaic.com.cn/)


## å‚è€ƒèµ„æ–™
* [ç»æµæœºå™¨æ˜¯æ€æ ·è¿è¡Œçš„ (æ—¶é•¿30åˆ†é’Ÿ) Ray Dalio](https://www.youtube.com/watch?v=rFV7wdEX-Mo)
* [LLM å…¨æ™¯å›¾ï¼ˆThe Landscape of LLMï¼‰](https://zhuanlan.zhihu.com/p/637154782)
* [LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Modelï¼ˆ2023ï¼‰](https://zhuanlan.zhihu.com/p/626278423)
* [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
* [MiniGPT-4](https://minigpt-4.github.io)
* [ä»€ä¹ˆæ˜¯å¤§æ¨¡å‹ï¼Ÿè¶…å¤§æ¨¡å‹å’Œ Foundation Model å‘¢ï¼Ÿ](https://www.zhihu.com/question/498275802)
* [Best ChatGPT Prompts](https://prompthero.com/chatgpt-prompts)
