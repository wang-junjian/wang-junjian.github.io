---
layout: post
title:  "2023 å¹´å…¨å›½è¡Œä¸šèŒä¸šæŠ€èƒ½ç«èµ›"
date:   2023-11-25 08:00:00 +0800
categories: Race
tags: [è¯­éŸ³è¯†åˆ«, è¯­éŸ³åˆæˆ, StanfordCoreNLP, Similarword, PlaintextCorpusReader, re, BeautifulSoup, etree, requests]
---

2023å¹´å…¨å›½è¡Œä¸šèŒä¸šæŠ€èƒ½ç«èµ› ç¬¬äºŒå±Šå…¨å›½ç”µå­ä¼ä¸šèŒä¸šæŠ€èƒ½ç«èµ›

## ä»»åŠ¡ä¸€
### ä»»åŠ¡1.1

### ä»»åŠ¡1.2

```py
# TODO ï¼ˆ1ï¼‰å¯¼å…¥æ‰€éœ€pythonå·¥å…·åº“,å¹¶å°†ä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-1.docxâ€ä¸­ã€‚
import json
import base64

from tencentcloud.common import credential
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.asr.v20190614 import asr_client, models

SecretId = 'AKIDBJWahprjTCpIazPrEPMFAyhHepzzqicj'
SecretKey = 'BIKNLG5tblpokbN6nRwGao166ze9RVQ9'

# TODO ï¼ˆ2ï¼‰é€šè¿‡è´¦æˆ·å¯†é’¥SecretId å’Œ SecretKeyå®ä¾‹åŒ–ä¸€ä¸ªè®¤è¯å¯¹è±¡ï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-1.docxâ€ä¸­ã€‚
cred = credential.Credential(SecretId, SecretKey)

# TODO ï¼ˆ3ï¼‰å®ä¾‹åŒ–è¯­éŸ³è¯†åˆ«æ‰€ç”¨æ¥å£çš„httpé€‰é¡¹åŠä¸€ä¸ªå®¢æˆ·ç«¯å¯¹è±¡ï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-1.docxâ€ä¸­ã€‚
httpProfile = HttpProfile()
httpProfile.endpoint = "asr.tencentcloudapi.com"
clientProfile = ClientProfile()
clientProfile.httpProfile = httpProfile
client = asr_client.AsrClient(cred, 'ap-beijing', clientProfile)
# TODO ï¼ˆ4ï¼‰å°†æ‰€æä¾›çš„éŸ³é¢‘ç´ æè½¬æ¢ä¸ºbase64ç¼–ç è§„èŒƒè¾“å‡ºï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-1.docxâ€ä¸­ã€‚
def ToBase64(file):
    with open(file, 'rb') as f:
        data = f.read()
        bytes_base64 = base64.b64encode(data)
        str_base64 = bytes.decode(bytes_base64)
        return str_base64

def SentenceRecognition(file, prompt):
    voice = ToBase64(file)
    # print(voice)

    # TODO ï¼ˆ5ï¼‰æ ¹æ®æä¾›çš„æ¥å£æ–‡æ¡£è®¾ç½®è¯­éŸ³è¯†åˆ«æ¥å£çš„è¯·æ±‚å‚æ•°â€™paramsâ€™ï¼Œè¦æ±‚ä»¥è¯­éŸ³æ•°æ®base64å½¢å¼å¯¹ä¸­æ–‡mp3ç±»å‹ä¸”ä¸è¿‡æ»¤è¯­æ°”è¯å’Œæ ‡ç‚¹ç¬¦å·çš„éŸ³é¢‘æ–‡ä»¶è¿›è¡Œé…ç½®ï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-1.docxâ€ä¸­ã€‚
    params = {
        'EngSerViceType': '16k_zh',
        'SourceType': 1,
        'Data': voice,
        'VoiceFormat': 'mp3',
        'FilterDirty': 0,
        'FilterPunc': 0
    }

    # TODO ï¼ˆ6ï¼‰å°†è¯·æ±‚å‚æ•°è½¬æ¢ä¸ºjsonæ ¼å¼å‘å®¢æˆ·ç«¯å‘é€è¯·æ±‚ï¼Œåœ¨æ§åˆ¶å°è¾“å‡ºè¯­éŸ³è¯†åˆ«ç»“æœï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-1.docxâ€ä¸­ã€‚
    req = models.SentenceRecognitionRequest()
    req.from_json_string(json.dumps(params))
    resp = client.SentenceRecognition(req)

    result=resp.to_json_string()
    print(prompt)
    print(result)


import os

dir = '/home/tione/notebook/ä»»åŠ¡ä¸€/è¯­éŸ³è¯†åˆ«/éŸ³é¢‘æ–‡ä»¶/'
for root, dirs, files in os.walk(dir):
    for file in files:
        file_path = os.path.join(root, file)
        SentenceRecognition(file_path, f'{os.path.splitext(file)[0]}è¯†åˆ«ç»“æœ')
```
```txt
éŸ³é¢‘4è¯†åˆ«ç»“æœ
{"Result": "å°†æ‚£è€…æ”¾å¹³èººä¸‹ï¼Œå°†é¼»çœ¼ç›¸åçš„æ‰‹é«˜ä¸¾ã€‚", "AudioDuration": 7366, "WordSize": 0, "WordList": null, "RequestId": "c67c06ec-f11c-4486-963b-3eb35a90a490"}
éŸ³é¢‘6è¯†åˆ«ç»“æœ
{"Result": "æŠŠå¤§è‘±ç™½åˆ‡ç¢å¹¶è£…ç›˜æ”¾åœ¨åºŠå‰ã€‚", "AudioDuration": 7340, "WordSize": 0, "WordList": null, "RequestId": "a89d01c5-706d-465a-b8e2-3749a229d136"}
éŸ³é¢‘3è¯†åˆ«ç»“æœ
{"Result": "å¦‚ä½•å¿«é€Ÿæ­¢ä½é¼»è¡€ï¼Ÿ", "AudioDuration": 6504, "WordSize": 0, "WordList": null, "RequestId": "39614c67-4a32-4a2b-8dfd-b751b15da34e"}
éŸ³é¢‘5è¯†åˆ«ç»“æœ
{"Result": "å¦‚ä½•ç¼“è§£å¤±çœ ï¼Ÿ", "AudioDuration": 6217, "WordSize": 0, "WordList": null, "RequestId": "b184e9b8-6b1f-4819-a285-6132482bf43a"}
éŸ³é¢‘1è¯†åˆ«ç»“æœ
{"Result": "è¯ç‰©çš„å‰¯ä½œç”¨å’Œä¸è‰¯ååº”æœ‰åŒºåˆ«å—ï¼Ÿ", "AudioDuration": 8202, "WordSize": 0, "WordList": null, "RequestId": "ff0b2fe1-78c1-4fc2-aa7d-c7fca0e5b41e"}
éŸ³é¢‘2è¯†åˆ«ç»“æœ
{"Result": "æœ‰åŒºåˆ«ã€‚è¯ç‰©ä¸è‰¯ååº”ä¸ä»…åŒ…æ‹¬è¯ç‰©çš„å‰¯ä½œç”¨ï¼Œè¿˜åŒ…æ‹¬è¯ç‰©çš„æ¯’æ€§ã€è¿‡æ•ååº”ç­‰ã€‚", "AudioDuration": 12486, "WordSize": 0, "WordList": null, "RequestId": "62558141-cab7-4e3d-a4fd-6f272bcbd014"}
```


### ä»»åŠ¡1.3

```py
# TODO ï¼ˆ1ï¼‰å¯¼å…¥æ‰€éœ€pythonå·¥å…·åº“,å¹¶å°†ä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-2.docxâ€ä¸­ã€‚
import json
import base64

from tencentcloud.common import credential
from tencentcloud.common.profile.http_profile import HttpProfile
from tencentcloud.common.profile.client_profile import ClientProfile
from tencentcloud.tts.v20190823 import tts_client, models

import uuid

# TODO ï¼ˆ2ï¼‰é€šè¿‡è´¦æˆ·å¯†é’¥SecretId å’Œ SecretKeyå®ä¾‹åŒ–ä¸€ä¸ªè®¤è¯å¯¹è±¡ï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-2.docxâ€ä¸­ã€‚
SecretId = 'AKIDBJWahprjTCpIazPrEPMFAyhHepzzqicj'
SecretKey = 'BIKNLG5tblpokbN6nRwGao166ze9RVQ9'
cred = credential.Credential(SecretId, SecretKey)

# TODO ï¼ˆ3ï¼‰å®ä¾‹åŒ–è¯­éŸ³åˆæˆæ‰€ç”¨æ¥å£çš„httpé€‰é¡¹åŠä¸€ä¸ªå®¢æˆ·ç«¯å¯¹è±¡,å¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-2.docxâ€ä¸­ã€‚
httpProfile = HttpProfile()
httpProfile.endpoint = "tts.tencentcloudapi.com"
clientProfile = ClientProfile()
clientProfile.httpProfile = httpProfile
client = tts_client.TtsClient(cred, 'ap-beijing', clientProfile)

# TODO ï¼ˆ4ï¼‰ç”Ÿæˆæ ‡è¯†ç”¨æˆ·å”¯ä¸€èº«ä»½çš„ä¼šè¯å·sessionIdï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-2.docxâ€ä¸­ã€‚
sessionId = str(uuid.uuid1())
# TODO ï¼ˆ5ï¼‰æ ¹æ®æä¾›çš„æ¥å£æ–‡æ¡£å’Œä¼šè¯å·ï¼Œé…ç½®è¯­éŸ³åˆæˆçš„è¯·æ±‚å‚æ•°â€™paramsâ€™ï¼Œè¦æ±‚å°†æ–‡æœ¬â€œæ¬¢è¿ä½¿ç”¨æ™ºèƒ½åŒ»é™¢æœåŠ¡â€åˆæˆä¸ºä¸­æ–‡â€œæ™ºäº‘â€éŸ³è‰²å…¶ä¸­åˆæˆéŸ³é¢‘çš„éŸ³é‡ä¸º5ï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-2.docxâ€ä¸­ã€‚
params = {
    'Text': 'æ¬¢è¿ä½¿ç”¨æ™ºèƒ½åŒ»é™¢æœåŠ¡',
    'SessionId': sessionId,
    'Volume': 5,
    'VoiceType': 1004,
    'PrimaryLanguage': 1,
    'Codec': 'mp3' # ä¸è¦å¿˜è®°äº†
}

# TODO ï¼ˆ6ï¼‰å°†è¯·æ±‚å‚æ•°è½¬æ¢ä¸ºjsonæ ¼å¼å‘å®¢æˆ·ç«¯å‘é€è¯·æ±‚ï¼Œæ‰“å°å“åº”çš„å­—ç¬¦ä¸²åŒ…ï¼ŒæŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-2.docxâ€ä¸­ã€‚
req = models.TextToVoiceRequest()
req.from_json_string(json.dumps(params))
resp = client.TextToVoice(req)
json_resp = json.loads(resp.to_json_string())
base64_data = json_resp['Audio']
# print(base64_data)

# # TODO ï¼ˆ7ï¼‰å°†å­—ç¬¦ä¸²åŒ…è§£ææˆéŸ³é¢‘æ–‡ä»¶ï¼Œå‘½åä¸ºâ€œèµ›ä½å·_è¯­éŸ³åˆæˆç»“æœ.mp3â€ï¼Œå¹¶æŠŠä»£ç æˆªå›¾å­˜æ”¾è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£1-2.docxâ€ä¸­ã€‚
def ToFile(base64_data, file):
    data = base64.b64decode(base64_data)
    with open(file, 'wb') as f:
        f.write(data)
    
file = 'èµ›ä½å·_è¯­éŸ³åˆæˆç»“æœ.mp3'
ToFile(base64_data, file)
```


### çŸ¥è¯†ç‚¹

GitHub Copilot: åœ¨Pythonä¸­ï¼Œ`base64.b64encode`å’Œ`base64.b64decode`æ˜¯ç”¨äºå¤„ç†Base64ç¼–ç çš„ä¸¤ä¸ªå‡½æ•°ã€‚

`base64.b64encode`å‡½æ•°æ¥å—ä¸€ä¸ªå­—èŠ‚ä¸²ï¼ˆbytesï¼‰ä½œä¸ºå‚æ•°ï¼Œè¿”å›è¯¥å­—èŠ‚ä¸²çš„Base64ç¼–ç ã€‚Base64ç¼–ç æ˜¯ä¸€ç§å¸¸ç”¨çš„äºŒè¿›åˆ¶åˆ°æ–‡æœ¬çš„ç¼–ç æ–¹æ³•ï¼Œå®ƒå¯ä»¥å°†ä»»æ„çš„äºŒè¿›åˆ¶æ•°æ®è½¬æ¢ä¸ºåªåŒ…å«ASCIIå­—ç¬¦çš„å­—ç¬¦ä¸²ï¼Œä»è€Œå¯ä»¥åœ¨æ–‡æœ¬åè®®ä¸­ä¼ è¾“ã€‚

ä¾‹å¦‚ï¼š

```python
import base64

data = b'Hello, world!'
encoded_data = base64.b64encode(data)
print(encoded_data)
```

è¿™æ®µä»£ç ä¼šæ‰“å°å‡º`Hello, world!`çš„Base64ç¼–ç ï¼š`SGVsbG8sIHdvcmxkIQ==`ã€‚

`base64.b64decode`å‡½æ•°åˆ™æ˜¯`base64.b64encode`çš„é€†æ“ä½œï¼Œå®ƒæ¥å—ä¸€ä¸ªBase64ç¼–ç çš„å­—èŠ‚ä¸²ï¼ˆbytesï¼‰æˆ–å­—ç¬¦ä¸²ï¼ˆstrï¼‰ä½œä¸ºå‚æ•°ï¼Œè¿”å›è¯¥ç¼–ç å¯¹åº”çš„åŸå§‹å­—èŠ‚ä¸²ã€‚

ä¾‹å¦‚ï¼š

```python
import base64

encoded_data = 'SGVsbG8sIHdvcmxkIQ=='
data = base64.b64decode(encoded_data)
print(data)
```

è¿™æ®µä»£ç ä¼šæ‰“å°å‡º`SGVsbG8sIHdvcmxkIQ==`å¯¹åº”çš„åŸå§‹æ•°æ®ï¼š`Hello, world!`ã€‚


## ä»»åŠ¡äºŒ

### ä»»åŠ¡2.2

```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
from speech_model import ModelSpeech       # è¯­éŸ³æ¨¡å‹ç±»
from speech_model_zoo import SpeechModel26
from speech_features import Spectrogram    # è¯­éŸ³è¯†åˆ«å†…ç½®çš„è¯­è°±å›¾å£°å­¦ç‰¹å¾æå–ç±»
from LanguageModel import ModelLanguage
from utils.ops import cosine_similarity

os.environ["CUDA_VISIBLE_DEVICES"] = "0"


class modelTest:
    """
    TODO:
    å®šä¹‰åˆå§‹åŒ–æ–¹æ³•__init__ï¼Œåˆå§‹åŒ–æ¨¡å‹è·¯å¾„,åˆ›å»ºå£°å­¦æ¨¡å‹å¯¹è±¡ã€‚
    """
    def __init__(self):
        # (1)åˆå§‹åŒ–æ¨¡å‹è·¯å¾„ã€‚
        self.model_path = 'save_models/PretrainedModel.h5'
        
        # (2)åˆ›å»ºåˆå§‹å£°å­¦æ¨¡å‹ç±»å®ä¾‹å¯¹è±¡ï¼Œè¦æ±‚åˆå§‹æ¨¡å‹çš„è¾“å‡ºçš„æ‹¼éŸ³è¡¨ç¤ºä¸º1428ï¼Œé€šé“æ•°ä¸º1ï¼ŒéŸ³é¢‘é•¿åº¦ä¸º1600ï¼Œç‰¹å¾å€¼åºåˆ—ä¸º200ç»´ã€‚
        pinyin = 1428
        channel = 1
        voice_len = 1600
        spec_dim = 200
        
        # (3)åˆ›å»ºå£°å­¦ç‰¹å¾ç±»å‹å®ä¾‹å¯¹è±¡ã€‚
        self.speech_model = SpeechModel26(
            input_shape = (voice_len, spec_dim, channel),
            output_size = pinyin
        )
        
    '''
    TODO:
    å®šä¹‰è¯†åˆ«å‡½æ•°recognize()ï¼Œå®ç°æ¨¡å‹çš„è°ƒç”¨å¹¶æˆåŠŸè¾“å‡ºè¯†åˆ«åˆ°çš„è¯­å¥ã€‚
    '''
    def recognize(self):
        # (4)åˆ›å»ºå£°å­¦æ¨¡å‹åŠŸèƒ½ç±»å®ä¾‹å¯¹è±¡ï¼Œæœ€é•¿æ ‡ç­¾é•¿åº¦è®¾ç½®ä¸º32ã€‚
        spec = Spectrogram()
        model_speech = ModelSpeech(self.speech_model, spec, max_label_length = 32)

        # (5)åŸºäºé¢„è®­ç»ƒæ¨¡å‹â€œPretrainedModel.h5â€ï¼Œè¿›è¡Œæ¨¡å‹çš„è°ƒç”¨ï¼Œè¯†åˆ«â€œ1.wavâ€è¿™ä¸ªè¯­éŸ³æ–‡ä»¶
        model_speech.load_model(self.model_path)
        pinyin = model_speech.recognize_speech_from_file('1.wav')
        print(pinyin)
        model_lang = ModelLanguage('model_language')
        model_lang.LoadModel()
        text = model_lang.SpeechToText(pinyin)
        print(text)
        
        return text

if __name__ == '__main__':
    mt = modelTest()
    print(cosine_similarity(mt.recognize(), 1))
```

### æ¨¡å‹è®­ç»ƒ
```py
import os

from keras.optimizers import Adam
from speech_model import ModelSpeech
from speech_model_zoo import SpeechModel26
from data_loader import DataLoader
from speech_features import Spectrogram

os.environ["CUDA_VISIBLE_DEVICES"] = "0"

sm = SpeechModel26(
    input_shape = (1600, 200, 1), 
    output_size = 1428
)

feat = Spectrogram()

train_data = DataLoader('train')
ms = ModelSpeech(sm, feat, max_label_length=64)
opt = Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
ms.load_model('save_models/PretrainedModel.h5')
ms.train_model(optimizer=opt, data_loader=train_data, epochs=10, save_step=1, batch_size=16)
```

## ä»»åŠ¡ä¸‰
### ä»»åŠ¡3.1
* requests

```py
import requests

def get_content(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36"
    }

    response = requests.get(url=url, headers=headers)
    response.encoding = 'utf-8'
    return response.text

url = 'http://43.139.169.182/hospital.html'

content = get_content(url)
print(content)

with open('èµ›ä½å·_hosptial.txt', 'w') as fout:
    fout.write(content)
```

* re

```py
import re

items = re.findall('<div class="text">(.*?)</div>', content)
for item in items:
    print(item)
```
```
ä½ å¥½ï¼Œæˆ‘è¦é¢„çº¦ã€‚
å¥½çš„ï¼Œè¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨ï¼Ÿ
æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨ã€‚
å¥½çš„ï¼Œè¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤ã€‚
æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘ã€‚
ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰ï¼šå¼ ä¸‰ï¼ˆä¸»ä»»ï¼‰ã€æå››ï¼ˆå‰¯ä¸»ä»»ï¼‰ã€æä¸½ï¼ˆå‰¯ä¸»ä»»ï¼‰ï¼Œè¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿï¼Ÿ
é¢„çº¦å¼ ä¸‰åŒ»ç”Ÿã€‚
å¥½çš„ï¼Œå¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰10å·ï¼ˆ9:00â€”9:20ï¼‰ã€16å·ï¼ˆ11:00â€”11:20ï¼‰ã€‚
å°±é¢„çº¦3å·å§ã€‚
å¥½çš„ã€‚è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·ã€‚
æˆ‘å«ç‹äº”ï¼Œèº«ä»½è¯å·1234567ã€‚
{{content}}
{{content}}
```

* BeautifulSoup

```py
bs = BeautifulSoup(content)
items = bs.select('.history .messages .text')
texts = [item.text for item in items]
for text in texts:
    print(text)

output_file = 'èµ›ä½å·_hosptial.txt'
with open(output_file, 'w') as f:
    f.write('\n'.join(texts))
```
```txt
ä½ å¥½ï¼Œæˆ‘è¦é¢„çº¦ã€‚
å¥½çš„ï¼Œè¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨ï¼Ÿ
æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨ã€‚
å¥½çš„ï¼Œè¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤ã€‚
æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘ã€‚
ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰ï¼šå¼ ä¸‰ï¼ˆä¸»ä»»ï¼‰ã€æå››ï¼ˆå‰¯ä¸»ä»»ï¼‰ã€æä¸½ï¼ˆå‰¯ä¸»ä»»ï¼‰ï¼Œè¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿï¼Ÿ
é¢„çº¦å¼ ä¸‰åŒ»ç”Ÿã€‚
å¥½çš„ï¼Œå¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰10å·ï¼ˆ9:00â€”9:20ï¼‰ã€16å·ï¼ˆ11:00â€”11:20ï¼‰ã€‚
å°±é¢„çº¦3å·å§ã€‚
å¥½çš„ã€‚è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·ã€‚
æˆ‘å«ç‹äº”ï¼Œèº«ä»½è¯å·1234567ã€‚
```

* etree

```py
from lxml import etree

tree = etree.HTML(content)
items = tree.xpath('//div[@class="text"]/text()') # //div[@class="messages"]//div[@class="text"]/text()
for item in items:
    print(item)
```
```
ä½ å¥½ï¼Œæˆ‘è¦é¢„çº¦ã€‚
å¥½çš„ï¼Œè¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨ï¼Ÿ
æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨ã€‚
å¥½çš„ï¼Œè¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤ã€‚
æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘ã€‚
ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰ï¼šå¼ ä¸‰ï¼ˆä¸»ä»»ï¼‰ã€æå››ï¼ˆå‰¯ä¸»ä»»ï¼‰ã€æä¸½ï¼ˆå‰¯ä¸»ä»»ï¼‰ï¼Œè¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿï¼Ÿ
é¢„çº¦å¼ ä¸‰åŒ»ç”Ÿã€‚
å¥½çš„ï¼Œå¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰10å·ï¼ˆ9:00â€”9:20ï¼‰ã€16å·ï¼ˆ11:00â€”11:20ï¼‰ã€‚
å°±é¢„çº¦3å·å§ã€‚
å¥½çš„ã€‚è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·ã€‚
æˆ‘å«ç‹äº”ï¼Œèº«ä»½è¯å·1234567ã€‚
```

```py
yqq_content = get_content('https://y.qq.com/')
yqq_bs = BeautifulSoup(yqq_content)
#ul[class="playlist__list slide__list"] li
#ul.playlist__list.slide__list li
#ul.playlist__list li
#ul.slide__list li
items = yqq_bs.select('ul.playlist__list li')
for item in items:
    print(item.text)
```
```
JJ æ—ä¿Šæ° | æœ‰äº›æ­Œï¼Œåªä¸ºçˆ±è€Œä½œæ’­æ”¾é‡ï¼š1003.9ä¸‡
æŠ–éŸ³è½¦è½½DJï½œè§£å‹100ï¼…æ’­æ”¾é‡ï¼š2245.8ä¸‡
æŠ–éŸ³çƒ­æ­Œï¼šè¶…å¥½å¬çš„åº—é“ºBGMæ’­æ”¾é‡ï¼š3874.4ä¸‡
ä¼¤æ„Ÿemoç‰‡æ®µï¼šå¿ä¸ä½å°±çº¢äº†çœ¼çœ¶æ’­æ”¾é‡ï¼š2127.9ä¸‡
èˆ’å‹è½»éŸ³ï¼šå®‰é™å¬é£ï¼Œå°†ç–²æƒ«æš‚ç¼“æ’­æ”¾é‡ï¼š1789.2ä¸‡
é•¿æœˆçƒ¬æ˜ ç”µè§†å‰§åŸå£°æ’­æ”¾é‡ï¼š1442.9ä¸‡
åè¯­ä½³ä½œ200é¦–â†»è®©å¬æ­Œæˆä¸ºäº«å—æ’­æ”¾é‡ï¼š2286.8ä¸‡
æ·±å¤œemoç¥æ›²:å“ªé¦–æ˜¯ä½ å¿ƒä¸­çš„No.1æ’­æ”¾é‡ï¼š1161.1ä¸‡
åˆ°ç‚¹äº†è¯¥emoäº†ï¼Œ00åçš„å¬æ­Œç°çŠ¶æ’­æ”¾é‡ï¼š1042.4ä¸‡
ä¸€å¬ä¸€æ•´å¤©ï¼ä¹…å¬ä¸åŒçš„ç‚™å£çƒ­æ›²æ’­æ”¾é‡ï¼š2981.2ä¸‡
ç‹æº2023ã€Œå®¢å…ç‹‚æ¬¢ã€å·¡æ¼”æ­Œå•æ’­æ”¾é‡ï¼š237.4ä¸‡
å…¨ç½‘è¶…å¥½å¬æŠ–éŸ³æƒ…æ­Œï¼ˆæŒç»­æ›´æ–°ï¼‰æ’­æ”¾é‡ï¼š7714.7ä¸‡
æ—¶ä»£å°‘å¹´å›¢ | çŒœæ­ŒæŒ‘æˆ˜ç­”é¢˜å®å…¸æ’­æ”¾é‡ï¼š211.0ä¸‡
è½¦è½½DJå—¨æ›²ï¼Œè·Ÿä¸ŠèŠ‚å¥ä¸€è·¯é£é©°æ’­æ”¾é‡ï¼š1445.6ä¸‡
R.I.P CoCoæçŸæ’­æ”¾é‡ï¼š674.0ä¸‡
æŠ–éŸ³çƒ­æ­Œï½œæè‡´å£°çº¿æ’©äººè€³è†œæ’­æ”¾é‡ï¼š2241.3ä¸‡
æ·±æƒ…çƒŸå—“ï¼šå¼€å£å³æ˜¯æ²§æ¡‘æ³ªæ’­æ”¾é‡ï¼š1601.0ä¸‡
æŠ–éŸ³è¶…ç‡ƒDJï½œæ‘‡æ‘†çš„çƒ­èˆæ´¾å¯¹æ’­æ”¾é‡ï¼š1809.3ä¸‡
16å²çš„æˆ‘å¬è§22å²çš„æ°ä¼¦ï¼Œä½ å‘¢ï¼Ÿæ’­æ”¾é‡ï¼š1702.6ä¸‡
åªæœ‰å¤œæ™šï¼Œéš¾è¿‡æ‰ä¼šé“ºå¤©ç›–åœ°è¢­æ¥æ’­æ”¾é‡ï¼š1388.0ä¸‡
è½¦å†…éŸ³å“ç‚¸è£‚ğŸ§é‡Šæ”¾é•¿é€”ç–²æƒ«æ’­æ”¾é‡ï¼š2647.5ä¸‡
æŠ–éŸ³çƒ­æ­Œï¼šå…¨ç½‘æœ€ç«è¶…å¥½å¬æ’­æ”¾é‡ï¼š1.2äº¿
æŠ–éŸ³åŠ²çˆ†ä¸­æ–‡DJï¼ˆæŒç»­æ›´æ–°ï¼‰æ’­æ”¾é‡ï¼š3529.9ä¸‡
Crushé™ä¸´ğŸ’—å¿ƒåŠ¨è¯´å”±è¡¨è¾¾çˆ±æ‹æ’­æ”¾é‡ï¼š2090.5ä¸‡
å‘¨æ·± Â· æ²»æ„ˆäººå¿ƒçš„å¤©ç±æ­Œæ‰‹æ’­æ”¾é‡ï¼š1397.8ä¸‡
```


### ä»»åŠ¡3.2

```py
# (1)å¯¼å…¥ç›¸å…³çš„Pythonåº“æˆ–Pythonæ¨¡å—ã€‚
import re

from nltk.corpus import PlaintextCorpusReader
from nlpcda import Similarword
from stanfordcorenlp import StanfordCoreNLP

# (2)å°†â€œèµ›ä½å·_ hosptial.txtâ€æ–‡ä»¶å†…å®¹ä½œä¸ºè¯­æ–™ï¼Œé€‰æ‹©ç”¨äºåˆ†ææ–‡æœ¬æ–‡ä»¶çš„æ–¹æ³•è½½å…¥è¯­æ–™ï¼Œå¹¶è¾“å‡ºæ–‡æœ¬å†…å®¹
file = 'èµ›ä½å·_hosptial.txt'
corpus = PlaintextCorpusReader('.', file)
text = corpus.raw(file)
print(f'åŸæ–‡æœ¬ï¼š{text}')

# (3)å°†è¯­æ–™å†…å®¹èµ‹å€¼ï¼ŒåŒ¹é…å­—ç¬¦ä¸²åè¿›è¡Œå†…å®¹æ›¿æ¢ï¼Œä»è€Œå®Œæˆæ•°æ®æ¸…æ´—æ“ä½œï¼Œå¹¶è¾“å‡ºæ•°æ®æ¸…æ´—ç»“æœï¼Œå¹¶å°†ç»“æœæˆªå›¾ä¿å­˜è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£3-2.docxâ€ï¼Œè¦æ±‚ï¼šæ¸…æ´—æ‰é™¤æ±‰å­—ä»¥å¤–çš„å­—ç¬¦ã€‚
cleaned_text = re.sub(r'[^\u4e00-\u9fa5]', '', text)
print(f'æ¸…æ´—çš„æ–‡æœ¬ï¼š{cleaned_text}')

# (4)é‡‡ç”¨é€‚å½“çš„æ•°æ®æ‰©å……æ–¹æ³•ï¼Œå¯¹æ•°æ®æ¸…æ´—ä¹‹åçš„å†…å®¹è¿›è¡Œæ•°æ®æ‰©å……ï¼Œå¹¶è¿”å›2ä¸ªå¢å¼ºæ–‡æœ¬ï¼Œæ–‡æœ¬æ”¹å˜ç‡è¦æ±‚ä¸º25%ï¼Œç»“åˆå¾ªç¯é€šè¿‡ç´¢å¼•è¾“å‡ºæ•°æ®æ‰©å……ç»“æœ
similarword = Similarword(create_num=2, change_rate=0.25)
similar_cleaned_text = similarword.replace(cleaned_text)
for i, s in enumerate(similar_cleaned_text):
    print(f'æ‰©å……æ ·æœ¬ {i+1}ï¼š{s}')

# (5)è°ƒç”¨CoreNLPä¸­æ–‡è¯­æ–™åŒ…ã€‚
nlp = StanfordCoreNLP('../stanford-corenlp-full-2018-02-27/')

# (6)é’ˆå¯¹â€œèµ›ä½å·_ hosptial.txtâ€ï¼Œä½¿ç”¨Stanford CoreNLPå®ç°ä¸­æ–‡åˆ†è¯ã€è¯æ€§æ ‡æ³¨ä»¥åŠä¸­æ–‡å‘½åå®ä½“è¯†åˆ«çš„è¾“å‡ºï¼Œå¹¶å°†ä»¥ä¸Šä¸‰ä¸ªç»“æœæˆªå›¾åˆ†åˆ«ä¿å­˜è‡³â€œèµ›ä½å·_ç­”é¢˜æ–‡æ¡£3-2.docxâ€ã€‚
word = nlp.word_tokenize(text)
print(f'ä¸­æ–‡åˆ†è¯: {word}')

pos_tag = nlp.pos_tag(text)
print(f'è¯æ€§æ ‡æ³¨: {pos_tag}')

ner = nlp.ner(text)
print(f'ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«: {ner}')
```
```txt
åŸæ–‡æœ¬ï¼šä½ å¥½ï¼Œæˆ‘è¦é¢„çº¦ã€‚
å¥½çš„ï¼Œè¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨ï¼Ÿ
æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨ã€‚
å¥½çš„ï¼Œè¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤ã€‚
æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘ã€‚
ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰ï¼šå¼ ä¸‰ï¼ˆä¸»ä»»ï¼‰ã€æå››ï¼ˆå‰¯ä¸»ä»»ï¼‰ã€æä¸½ï¼ˆå‰¯ä¸»ä»»ï¼‰ï¼Œè¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿï¼Ÿ
é¢„çº¦å¼ ä¸‰åŒ»ç”Ÿã€‚
å¥½çš„ï¼Œå¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰10å·ï¼ˆ9:00â€”9:20ï¼‰ã€16å·ï¼ˆ11:00â€”11:20ï¼‰ã€‚
å°±é¢„çº¦3å·å§ã€‚
å¥½çš„ã€‚è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·ã€‚
æˆ‘å«ç‹äº”ï¼Œèº«ä»½è¯å·1234567ã€‚
æ¸…æ´—çš„æ–‡æœ¬ï¼šä½ å¥½æˆ‘è¦é¢„çº¦å¥½çš„è¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨å¥½çš„è¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰å¼ ä¸‰ä¸»ä»»æå››å‰¯ä¸»ä»»æä¸½å‰¯ä¸»ä»»è¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿé¢„çº¦å¼ ä¸‰åŒ»ç”Ÿå¥½çš„å¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰å·å·å°±é¢„çº¦å·å§å¥½çš„è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·æˆ‘å«ç‹äº”èº«ä»½è¯å·
load :/opt/conda/envs/zy_race/lib/python3.10/site-packages/nlpcda/data/åŒä¹‰è¯.txt done
æ‰©å……æ ·æœ¬ 1ï¼šä½ å¥½æˆ‘è¦é¢„çº¦å¥½çš„è¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨å¥½çš„è¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰å¼ ä¸‰ä¸»ä»»æå››å‰¯ä¸»ä»»æä¸½å‰¯ä¸»ä»»è¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿé¢„çº¦å¼ ä¸‰åŒ»ç”Ÿå¥½çš„å¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰å·å·å°±é¢„çº¦å·å§å¥½çš„è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·æˆ‘å«ç‹äº”èº«ä»½è¯å·
æ‰©å……æ ·æœ¬ 2ï¼šä½ å¥½æˆ‘è¦çº¦å®šå¥½çš„è¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨å¥½çš„è¯·é—®æ‚¨è¦çº¦å®šä»€ä¹ˆç§‘å®¤æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰å¼ ä¸‰ä¸»ä»»æå››å‰¯ä¸»ä»»æä¸½å‰¯ä¸»ä»»è¯·é—®æ‚¨ç”¨çº¦å®šå“ªä½ç™½è¡£æˆ˜å£«é¢„çº¦å¼ ä¸‰åŒ»ç”Ÿå¥½çš„å¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰å·å·å°±é¢„çº¦å·å§å¥½çš„è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·æˆ‘å«ç‹äº”èº«ä»½è¯å·
ä¸­æ–‡åˆ†è¯: ['ä½ å¥½', 'ï¼Œ', 'æˆ‘è¦é¢„çº¦', 'ã€‚', 'å¥½çš„', 'ï¼Œ', 'è¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨', 'ï¼Ÿ', 'æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨', 'ã€‚', 'å¥½çš„', 'ï¼Œ', 'è¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤', 'ã€‚', 'æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘', 'ã€‚', 'ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰', 'ï¼š', 'å¼ ä¸‰', 'ï¼ˆ', 'ä¸»ä»»', 'ï¼‰', 'ã€', 'æå››', 'ï¼ˆ', 'å‰¯ä¸»ä»»', 'ï¼‰', 'ã€', 'æä¸½', 'ï¼ˆ', 'å‰¯ä¸»ä»»', 'ï¼‰', 'ï¼Œ', 'è¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿ', 'ï¼Ÿ', 'é¢„çº¦å¼ ä¸‰åŒ»ç”Ÿ', 'ã€‚', 'å¥½çš„', 'ï¼Œ', 'å¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰10å·', 'ï¼ˆ', '9:00', 'â€”', '9:20', 'ï¼‰', 'ã€', '16å·', 'ï¼ˆ', '11:00', 'â€”', '11:20', 'ï¼‰', 'ã€‚', 'å°±é¢„çº¦3å·å§', 'ã€‚', 'å¥½çš„', 'ã€‚', 'è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·', 'ã€‚', 'æˆ‘å«ç‹äº”', 'ï¼Œ', 'èº«ä»½è¯å·1234567', 'ã€‚']
è¯æ€§æ ‡æ³¨: [('ä½ å¥½', 'NN'), ('ï¼Œ', 'CD'), ('æˆ‘è¦é¢„çº¦', 'CD'), ('ã€‚', 'NN'), ('å¥½çš„', 'NN'), ('ï¼Œ', 'CD'), ('è¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨', 'CD'), ('ï¼Ÿ', 'NN'), ('æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨', 'NN'), ('ã€‚', 'SYM'), ('å¥½çš„', 'NN'), ('ï¼Œ', 'CD'), ('è¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤', 'CD'), ('ã€‚', 'NN'), ('æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘', 'JJ'), ('ã€‚', 'NN'), ('ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰', 'NN'), ('ï¼š', 'SYM'), ('å¼ ä¸‰', 'FW'), ('ï¼ˆ', 'FW'), ('ä¸»ä»»', 'FW'), ('ï¼‰', 'FW'), ('ã€', 'FW'), ('æå››', 'FW'), ('ï¼ˆ', 'FW'), ('å‰¯ä¸»ä»»', 'FW'), ('ï¼‰', 'FW'), ('ã€', 'FW'), ('æä¸½', 'FW'), ('ï¼ˆ', 'FW'), ('å‰¯ä¸»ä»»', 'FW'), ('ï¼‰', 'FW'), ('ï¼Œ', 'FW'), ('è¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿ', 'FW'), ('ï¼Ÿ', 'FW'), ('é¢„çº¦å¼ ä¸‰åŒ»ç”Ÿ', 'JJ'), ('ã€‚', 'NN'), ('å¥½çš„', 'NN'), ('ï¼Œ', 'CD'), ('å¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰10å·', 'CD'), ('ï¼ˆ', 'CD'), ('9:00', 'CD'), ('â€”', ':'), ('9:20', 'CD'), ('ï¼‰', 'CD'), ('ã€', 'NN'), ('16å·', 'CD'), ('ï¼ˆ', 'CD'), ('11:00', 'CD'), ('â€”', ':'), ('11:20', 'CD'), ('ï¼‰', 'CD'), ('ã€‚', 'NN'), ('å°±é¢„çº¦3å·å§', 'CD'), ('ã€‚', 'CD'), ('å¥½çš„', 'NN'), ('ã€‚', 'SYM'), ('è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·', 'NN'), ('ã€‚', 'SYM'), ('æˆ‘å«ç‹äº”', 'CD'), ('ï¼Œ', 'CD'), ('èº«ä»½è¯å·1234567', 'CD'), ('ã€‚', 'NN')]
ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«: [('ä½ å¥½', 'O'), ('ï¼Œ', 'NUMBER'), ('æˆ‘è¦é¢„çº¦', 'NUMBER'), ('ã€‚', 'O'), ('å¥½çš„', 'O'), ('ï¼Œ', 'NUMBER'), ('è¯·é—®æ‚¨è¦é¢„çº¦é—¨è¯Šéƒ¨è¿˜æ˜¯ä½é™¢éƒ¨', 'NUMBER'), ('ï¼Ÿ', 'O'), ('æˆ‘è¦é¢„çº¦é—¨è¯Šéƒ¨', 'O'), ('ã€‚', 'O'), ('å¥½çš„', 'O'), ('ï¼Œ', 'NUMBER'), ('è¯·é—®æ‚¨è¦é¢„çº¦ä»€ä¹ˆç§‘å®¤', 'NUMBER'), ('ã€‚', 'O'), ('æˆ‘è¦é¢„çº¦å¿ƒè¡€ç®¡ç§‘', 'O'), ('ã€‚', 'O'), ('ä»Šæ—¥å¿ƒè¡€ç®¡ç§‘åè¯ŠåŒ»ç”Ÿæœ‰', 'O'), ('ï¼š', 'O'), ('å¼ ä¸‰', 'O'), ('ï¼ˆ', 'O'), ('ä¸»ä»»', 'O'), ('ï¼‰', 'O'), ('ã€', 'O'), ('æå››', 'O'), ('ï¼ˆ', 'O'), ('å‰¯ä¸»ä»»', 'O'), ('ï¼‰', 'O'), ('ã€', 'O'), ('æä¸½', 'O'), ('ï¼ˆ', 'O'), ('å‰¯ä¸»ä»»', 'O'), ('ï¼‰', 'O'), ('ï¼Œ', 'O'), ('è¯·é—®æ‚¨éœ€è¦é¢„çº¦å“ªä½åŒ»ç”Ÿ', 'O'), ('ï¼Ÿ', 'O'), ('é¢„çº¦å¼ ä¸‰åŒ»ç”Ÿ', 'O'), ('ã€‚', 'O'), ('å¥½çš„', 'O'), ('ï¼Œ', 'NUMBER'), ('å¼ ä¸‰åŒ»ç”Ÿä»Šæ—¥åè¯Šå‰©ä½™æ—¶æ®µå·æœ‰10å·', 'NUMBER'), ('ï¼ˆ', 'NUMBER'), ('9:00', 'TIME'), ('â€”', 'O'), ('9:20', 'TIME'), ('ï¼‰', 'NUMBER'), ('ã€', 'O'), ('16å·', 'NUMBER'), ('ï¼ˆ', 'NUMBER'), ('11:00', 'TIME'), ('â€”', 'O'), ('11:20', 'TIME'), ('ï¼‰', 'NUMBER'), ('ã€‚', 'O'), ('å°±é¢„çº¦3å·å§', 'NUMBER'), ('ã€‚', 'NUMBER'), ('å¥½çš„', 'O'), ('ã€‚', 'O'), ('è¯·ç™»è®°æ‚¨çš„å§“åå’Œèº«ä»½è¯å·', 'O'), ('ã€‚', 'O'), ('æˆ‘å«ç‹äº”', 'NUMBER'), ('ï¼Œ', 'NUMBER'), ('èº«ä»½è¯å·1234567', 'NUMBER'), ('ã€‚', 'O')]
```

## ä»»åŠ¡å››

### ä»»åŠ¡4.1
```py
%matplotlib inline

import xlrd
import matplotlib
# matplotlib.use('Agg')
import matplotlib.pyplot as plt

import os



#TODO åŠ è½½excelæ•°æ®
def read_excel(path):
    #TODO æ‰“å¼€æ–‡ä»¶
    workbook = xlrd.open_workbook(path)
    #TODO è·å–sheet
    sheet1_name = workbook.sheet_names()[0]
    #TODO æ ¹æ®sheetç´¢å¼•æˆ–è€…åç§°è·å–sheetå†…å®¹
    sheet1 = workbook.sheet_by_name(sheet1_name)
    #TODO è·å–è¡Œæ•°åˆ—æ•°
    nrows = sheet1.nrows
    ncols = sheet1.ncols
    #TODO è·å–æ¯ä¸€è¡Œçš„æ•°æ®å­˜å…¥åˆ—è¡¨
    rows_list = []
    for i in range(nrows):
        rows_list.append(sheet1.row_values(i))
    #TODO è¿”å›æ¯ä¸€è¡Œæ•°æ®
    return rows_list


def getData():
    root_path = '/home/tione/notebook/ä»»åŠ¡å››'

    #TODO åŠ è½½excelæ•°æ®
    excel_path = os.path.join(root_path,'èµ›ä½å·_ hosptial.xls')#r'D:/test/yundong.xls'#excelå­˜å‚¨ä½ç½®
    row_list = read_excel(excel_path)
    # print(row_list)
    
    # (1)ç»è¿‡è®¡ç®—åˆ†åˆ«å¾—åˆ°è¿‘äº”å¤©æ€¥è¯Šç§‘ç”·å¥³åˆ†åˆ«çš„äººæ•°ï¼Œè¿‘äº”å¤©æ¥åŒ»é™¢å°±è¯Šçš„äººæ•°ï¼Œè¿‘äº”å¤©æ¯ä¸ªè¯Šå®¤å°±è¯Šäººæ•°ï¼Œå¹¶åœ¨æ§åˆ¶å°è¾“å‡ºã€‚
    from collections import defaultdict
    
    sex_count = defaultdict(int)
    person_per_day_count = defaultdict(int)
    person_per_clinic_count = defaultdict(int)
    for name, sex, age, clinic, date in row_list:
        if name == 'å§“å':
            continue
        sex_count[sex] += 1
        person_per_day_count[date] += 1
        person_per_clinic_count[clinic] += 1
    
    print('è¿‘äº”å¤©æ€¥è¯Šç§‘ç”·å¥³åˆ†åˆ«çš„äººæ•°ï¼š', dict(sex_count))
    print('è¿‘äº”å¤©æ¥åŒ»é™¢å°±è¯Šçš„äººæ•°ï¼š', dict(person_per_day_count))
    print('è¿‘äº”å¤©æ¯ä¸ªè¯Šå®¤å°±è¯Šäººæ•°ï¼š',dict(person_per_clinic_count))

    # (2)å°†è¿‘äº”å¤©æ€¥è¯Šç§‘å°±è¯Šç”·å¥³æ¯”ä¾‹ç”Ÿæˆé¥¼çŠ¶å›¾å¹¶ä¿å­˜å›¾ç‰‡ï¼Œè¦æ±‚: è¡¨å¤´è®¾ç½®ä¸ºâ€™Male to female ratio in the last five days of emergency departmentâ€™ã€‚
    plt.figure()
    plt.pie(sex_count.values(), labels=sex_count.keys())
    plt.title('Male to female ratio in the last five days of emergency department')
    plt.savefig('sex.jpg')
    plt.show()

    # (3)å°†è¿‘äº”å¤©æ¯ä¸ªè¯Šå®¤å°±è¯Šäººæ•°ç”ŸæˆæŸ±çŠ¶å›¾å¹¶ä¿å­˜å›¾ç‰‡ï¼Œè¦æ±‚ï¼šè¡¨å¤´è®¾ç½®ä¸ºâ€™Number of visits per consultation roomâ€™ï¼Œxlabelè®¾ç½®ä¸ºâ€™consulting roomâ€™,ylabelè®¾ç½®ä¸ºâ€™numberâ€™ã€‚
    plt.figure()
    plt.bar(person_per_clinic_count.keys(), person_per_clinic_count.values())
    plt.title('Number of visits per consultation room')
    plt.xlabel('consulting room')
    plt.ylabel('number')
    plt.savefig('clinic.jpg')
    plt.show()

    # (4)å°†è¿‘äº”å¤©æ¥åŒ»é™¢å°±è¯Šçš„äººæ•°ç”ŸæˆæŠ˜çº¿å›¾å¹¶ä¿å­˜å›¾ç‰‡ï¼Œè¦æ±‚ï¼šè¡¨å¤´è®¾ç½®ä¸ºâ€™The number of people who came to the hospital in the last five daysâ€™,xlabelè®¾ç½®ä¸ºâ€™dayâ€™, ylabelè®¾ç½®ä¸ºâ€™numberâ€™ã€‚
    plt.figure()
    plt.plot(person_per_day_count.keys(), person_per_day_count.values())
    plt.title('The number of people who came to the hospital in the last five days')
    plt.xlabel('day')
    plt.ylabel('number')
    plt.savefig('day.jpg')
    plt.show()
    
getData()
```
```txt
è¿‘äº”å¤©æ€¥è¯Šç§‘ç”·å¥³åˆ†åˆ«çš„äººæ•°ï¼š {'boy': 9, 'girl': 7}
è¿‘äº”å¤©æ¥åŒ»é™¢å°±è¯Šçš„äººæ•°ï¼š {'2023.1.1': 3, '2023.1.2': 2, '2023.1.3': 4, '2023.1.4': 3, '2023.1.5': 4}
è¿‘äº”å¤©æ¯ä¸ªè¯Šå®¤å°±è¯Šäººæ•°ï¼š {'EW': 2, 'OD': 4, 'DD': 4, 'IMD': 2, 'ED': 4}
```

### çŸ¥è¯†ç‚¹

GitHub Copilot: åœ¨Pythonä¸­ï¼Œä½ å¯ä»¥ä½¿ç”¨`matplotlib`åº“çš„`pyplot`æ¨¡å—æ¥ç”Ÿæˆé¥¼çŠ¶å›¾ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼š

```python
import matplotlib.pyplot as plt

# å‡è®¾ä½ å·²ç»æœ‰äº†è¿‘äº”å¤©æ€¥è¯Šç§‘å°±è¯Šç”·å¥³æ¯”ä¾‹çš„æ•°æ®
sex_ratio = {'boy': 9, 'girl': 7}

# åˆ›å»ºä¸€ä¸ªæ–°çš„å›¾å½¢
plt.figure()

# ç”Ÿæˆé¥¼çŠ¶å›¾
plt.pie(sex_ratio.values(), labels=sex_ratio.keys(), autopct='%1.1f%%')

# è®¾ç½®å›¾å½¢çš„æ ‡é¢˜
plt.title('è¿‘äº”å¤©æ€¥è¯Šç§‘å°±è¯Šç”·å¥³æ¯”ä¾‹')

# ä¿å­˜å›¾å½¢ä¸ºå›¾ç‰‡
plt.savefig('sex_ratio.png')

# æ˜¾ç¤ºå›¾å½¢
plt.show()
```

è¿™æ®µä»£ç ä¼šç”Ÿæˆä¸€ä¸ªæ˜¾ç¤ºè¿‘äº”å¤©æ€¥è¯Šç§‘å°±è¯Šç”·å¥³æ¯”ä¾‹çš„é¥¼çŠ¶å›¾ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸º`sex_ratio.png`å›¾ç‰‡ã€‚

* [Pie charts](https://matplotlib.org/stable/gallery/pie_and_polar_charts/pie_features.html)
