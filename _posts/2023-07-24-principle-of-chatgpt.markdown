---
layout: single
title:  "AI 大模型"
date:   2023-07-24 08:00:00 +0800
categories: ChatGPT
tags: [LLM, GPT, Data, SAM]
---

## 🔥 大模型
### [ChatGPT](https://chat.openai.com)
### [讯飞星火](https://xinghuo.xfyun.cn/desk)
### [活字通用大模型](https://github.com/HIT-SCIR/huozi)

## 🔥 Andrej Karpathy
### [State of GPT](https://www.youtube.com/watch?v=bZQun8Y4L2A)
* [微软2023年Build大会演讲：如何训练和应用GPT](https://www.youtube.com/watch?v=YrBJiy-V8MY)
* [State of GPT 笔记]({% post_url 2023-05-30-state-of-gpt %})

## 🔥 李沐
### 论文精读
* [如何读论文](https://www.youtube.com/watch?v=txjl_Q4jCyQ)
* [AlexNet](https://www.youtube.com/watch?v=zjnxu8KUYKA)
* [ResNet](https://www.youtube.com/watch?v=pWMnzCX4cwQ)
* [零基础多图详解图神经网络（GNN/GCN）](https://www.youtube.com/watch?v=sejA2PtCITw)
* [GAN](https://www.youtube.com/watch?v=g_0HtlrLiDo)
* [Transformer](https://www.youtube.com/watch?v=nzqlFIcCSWQ)
* [BERT](https://www.youtube.com/watch?v=ULD3uIb2MHQ)
    * [Pre-training](https://youtu.be/ULD3uIb2MHQ?t=104)
* [ViT](https://www.youtube.com/watch?v=FRFt3x0bO94)
    * [卷积神经网络的两个归纳偏置：1、locality（相同区域有相同的特征）；2、translation equivariance（平移等变性）](https://youtu.be/FRFt3x0bO94?t=1004)
    * [local neighborhoods](https://youtu.be/FRFt3x0bO94?t=1585)
* [MAE](https://www.youtube.com/watch?v=mYlX2dpdHHM)
    * [Autoencoder](https://youtu.be/mYlX2dpdHHM?t=222)
* [对比学习论文综述](https://www.youtube.com/watch?v=1pvxufGRuW4)
    * [数据增强：Crop 和 Color 的组合最有效](https://youtu.be/1pvxufGRuW4?t=1694)
* [MoCo](https://www.youtube.com/watch?v=pXvMXfPJZ2M)
* [CLIP](https://www.youtube.com/watch?v=OZF1t_Hieq8)
    * [How to Train Really Large Models on Many GPUs?](https://lilianweng.github.io/posts/2021-09-25-train-large/)
    * [Zero-Shot Transfer](https://youtu.be/OZF1t_Hieq8?t=3143)
    * [Using Zero-Shot Transfer](https://youtu.be/OZF1t_Hieq8?t=3222)
    * [PROMPT ENGINEERING AND ENSEMBLING](https://youtu.be/OZF1t_Hieq8?t=3434)
    * [Prompt Engineering for ImageNet](https://github.com/openai/CLIP/blob/main/notebooks/Prompt_Engineering_for_ImageNet.ipynb)
    * [在 27 个数据集上测试 Zero-Shot](https://youtu.be/OZF1t_Hieq8?t=3813)
* [DALL·E 2](https://www.youtube.com/watch?v=hO57mntSMl0)
    * [GAN]()
    * [Autoencoder](https://youtu.be/hO57mntSMl0?t=1833)
    * [DAE(Denoising Autoencoder)](https://youtu.be/hO57mntSMl0?t=1870)
    * [VAE(Variational Autoencoder)](https://youtu.be/hO57mntSMl0?t=1976)
    * [VQVAE(Vector Quantized Variational Autoencoder)](https://youtu.be/hO57mntSMl0?t=2100)
    * [VQVAE2](https://youtu.be/hO57mntSMl0?t=2330)
    * [DALL·E](https://youtu.be/hO57mntSMl0?t=2384)
    * [Diffusion Model](https://youtu.be/hO57mntSMl0?t=2488)
    * [U-Net](https://youtu.be/hO57mntSMl0?t=2690)
    * [扩散模型的发展历程](https://youtu.be/hO57mntSMl0?t=2738)
        * [DDPM(Denoising Diffusion Probabilistic Models)](https://youtu.be/hO57mntSMl0?t=2762)
        * [Improved DDPM](https://youtu.be/hO57mntSMl0?t=3125)
        * [Diffusion Models Beat GANs](https://youtu.be/hO57mntSMl0?t=3189)
* [CLIP 改进工作串讲（上）](https://www.youtube.com/watch?v=x4CDhZz_Dvg)
* [CLIP 改进工作串讲（下）](https://www.youtube.com/watch?v=ugJeBivv65s)
* [ViLT](https://www.youtube.com/watch?v=ug8YvZOjOCE)
* [GPT，GPT-2，GPT-3](https://www.youtube.com/watch?v=t70Bl3w7bxY)
* [OpenAI Codex](https://www.youtube.com/watch?v=oZriUGkQSNM)
    * [HumanEval: Hand-Written Evaluation Set](https://github.com/openai/human-eval)
* [DeepMind AlphaCode](https://www.youtube.com/watch?v=t8Gzkca9pW4)
* [InstructGPT](https://www.youtube.com/watch?v=zfIGAwD1jOQ)
    * [aligned](https://youtu.be/zfIGAwD1jOQ?t=615)
    * [RLHF](https://youtu.be/zfIGAwD1jOQ?t=992)
    * [Train InstructGPT Models](https://youtu.be/zfIGAwD1jOQ?t=1337)
* [GPT-4](https://www.youtube.com/watch?v=K0SZ9mdygTw)

## 🔥 李宏毅
### [MACHINE LEARNING 2023 SPRING](https://speech.ee.ntu.edu.tw/~hylee/ml/2023-spring.php)
* [【DLHLP 2020】來自獵人暗黑大陸的模型 GPT-3](https://www.youtube.com/watch?v=DOG1L9lvsDY)
* [【機器學習2021】Transformer (上)](https://www.youtube.com/watch?v=n9TlOhRjYoc)
* [【機器學習2021】Transformer (下)](https://www.youtube.com/watch?v=N6aRv06iv2g)
* [ML Lecture 6: Brief Introduction of Deep Learning](https://www.youtube.com/watch?v=Dr-WRlEFefw)
### [機器學習2022](https://www.youtube.com/watch?v=7XZR0-4uS5s&list=PLJV_el3uVTsPM2mM-OQzJXziCGJa8nJL8)
### [機器學習2021](https://www.youtube.com/playlist?list=PLJV_el3uVTsMhtt7_Y6sgTHGHp1Vb2P2J)
### [Machine Learning (Hung-yi Lee, NTU)](https://www.youtube.com/playlist?list=PLJV_el3uVTsPy9oCRY30oBPNLCo89yu49)

## 🔥 DeepLearning.AI 课程 [中文视频](https://www.bilibili.com/video/BV1Bo4y1A7FU/)
### [ChatGPT Prompt Engineering for Developers](https://learn.deeplearning.ai/chatgpt-prompt-eng)
[中文笔记](https://github.com/datawhalechina/prompt-engineering-for-developers/tree/main/content/Prompt%20Engineering)
### [LangChain for LLM Application Development](https://learn.deeplearning.ai/langchain)
[中文笔记](https://github.com/datawhalechina/prompt-engineering-for-developers/tree/main/content/LangChain%20for%20LLM%20Application%20Development)
### [Building Systems with the ChatGPT API](https://learn.deeplearning.ai/chatgpt-building-system)
[中文笔记](https://github.com/datawhalechina/prompt-engineering-for-developers/tree/main/content/Building%20Systems%20with%20the%20ChatGPT%20API)
### [How Diffusion Models Work](https://learn.deeplearning.ai/diffusion-models)

## 🔥 Datawhale
### [Bilibili Datawhale](https://space.bilibili.com/431850986)
### [GitHub Datawhale]
### [HuggingLLM](https://github.com/datawhalechina/hugging-llm)

## 🔥 开发文档
### [OpenAI Cookbook](https://github.com/openai/openai-cookbook)
### [LangChain](https://github.com/hwchase17/langchain)

## 🔥 相关文档
* [Building the New Bing](https://blogs.bing.com/search-quality-insights/february-2023/Building-the-New-Bing)

## 🔥 数据
### 指令数据（用于微调）
* [OpenGVLab/LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter/blob/main/llama_adapter_v2_multimodal/docs/train.md)
    * [alpaca_gpt4_data.json](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data.json)
    * [alpaca_gpt4_data_zh.json](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM/blob/main/data/alpaca_gpt4_data_zh.json)
    * [llava_instruct_150k.json](https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K/raw/main/llava_instruct_150k.json)
    * [alpaca_data_zh_51k.json](https://github.com/ymcui/Chinese-LLaMA-Alpaca/blob/main/data/alpaca_data_zh_51k.json)

## 🔥 测评基准
### [通用语言理解测评基准 CLUE](https://gluebenchmark.com/)
通用语言理解评估 (GLUE) 基准是用于训练、评估和分析自然语言理解系统的资源集合。
* 九个句子或句子对语言理解任务的基准，建立在已建立的现有数据集上，并选择覆盖各种数据集大小、文本类型和难度，
* 诊断数据集，旨在评估和分析自然语言中发现的各种语言现象的模型性能，以及
* 用于跟踪基准性能的公共排行榜和用于可视化诊断集上模型性能的仪表板。

GLUE 基准测试的格式与模型无关，因此任何能够处理句子和句子对并产生相应预测的系统都有资格参与。 选择基准任务是为了支持使用参数共享或其他迁移学习技术跨任务共享信息的模型。 GLUE 的最终目标是推动通用且强大的自然语言理解系统的开发研究。

### [中文语言理解测评基准(CLUE)](https://cluebenchmarks.com/)
中文语言理解测评基准，包括代表性的数据集、基准(预训练)模型、语料库、排行榜。我们会选择一系列有一定代表性的任务对应的数据集，做为我们测试基准的数据集。这些数据集会覆盖不同的任务、数据量、任务难度。

### [SUPERB(Speech processing Universal PERformance Benchmark)](https://superbbenchmark.org)


## [Segment Anything](https://segment-anything.com/)
### [Demo](https://segment-anything.com/demo)
### [论文（中文）](https://zhuanlan.zhihu.com/p/619962145)
### [GitHub](https://github.com/facebookresearch/segment-anything)

## Grounded-Segment-Anything
### [HuggingFace](https://huggingface.co/spaces/yizhangliu/Grounded-Segment-Anything)
### [GitHub](https://github.com/IDEA-Research/Grounded-Segment-Anything)

## 参考资料
* [FastSAM](https://github.com/CASIA-IVA-Lab/FastSAM)
* [Recognize Anything](https://recognize-anything.github.io/)


## 🔥 AI 应用
* [CodeGeeX](https://codegeex.cn/zh-CN)


## 人工智能会议
[2023 世界人工智能大会 - WORLD ARTIFICIAL INTELLIGENCE CONFERENCE（WAIC）](https://www.worldaic.com.cn/)


## 参考资料
* [经济机器是怎样运行的 (时长30分钟) Ray Dalio](https://www.youtube.com/watch?v=rFV7wdEX-Mo)
* [LLM 全景图（The Landscape of LLM）](https://zhuanlan.zhihu.com/p/637154782)
* [LLaMA-Adapter V2: Parameter-Efficient Visual Instruction Model（2023）](https://zhuanlan.zhihu.com/p/626278423)
* [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca)
* [MiniGPT-4](https://minigpt-4.github.io)
* [什么是大模型？超大模型和 Foundation Model 呢？](https://www.zhihu.com/question/498275802)
* [Best ChatGPT Prompts](https://prompthero.com/chatgpt-prompts)
