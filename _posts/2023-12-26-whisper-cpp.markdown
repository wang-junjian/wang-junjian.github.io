---
layout: post
title:  "whisper.cpp"
date:   2023-12-26 08:00:00 +0800
categories: Whisper
tags: [Whisper, MacBookProM2Max]
---

## ä¸‹è½½æ¨¡å‹
### large-v3
```shell
models/download-ggml-model.sh large-v3
```

## NEON & MPS
### ç¼–è¯‘
```shell
make clean
make -j
```

### è¯­éŸ³è¯†åˆ«
```shell
time ./main -m models/ggml-large-v3.bin -f test.wav -l auto
```
```
whisper_init_from_file_with_params_no_state: loading model from 'models/ggml-large-v3.bin'
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51866
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 1280
whisper_model_load: n_audio_head  = 20
whisper_model_load: n_audio_layer = 32
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 1280
whisper_model_load: n_text_head   = 20
whisper_model_load: n_text_layer  = 32
whisper_model_load: n_mels        = 128
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 5 (large v3)
whisper_model_load: adding 1609 extra tokens
whisper_model_load: n_langs       = 100
whisper_backend_init: using Metal backend
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M2 Max
ggml_metal_init: picking default device: Apple M2 Max
ggml_metal_init: default.metallib not found, loading from source
ggml_metal_init: loading '/Users/junjian/GitHub/ggerganov/whisper.cpp/ggml-metal.metal'
ggml_metal_init: GPU name:   Apple M2 Max
ggml_metal_init: GPU family: MTLGPUFamilyApple8 (1008)
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 51539.61 MB
ggml_metal_init: maxTransferRate               = built-in GPU
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =  3117.88 MB, ( 3118.53 / 51539.61)
whisper_model_load:    Metal buffer size =  3117.87 MB
whisper_model_load: model size    = 3117.39 MB
whisper_backend_init: using Metal backend
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M2 Max
ggml_metal_init: picking default device: Apple M2 Max
ggml_metal_init: default.metallib not found, loading from source
ggml_metal_init: loading '/Users/junjian/GitHub/ggerganov/whisper.cpp/ggml-metal.metal'
ggml_metal_init: GPU name:   Apple M2 Max
ggml_metal_init: GPU family: MTLGPUFamilyApple8 (1008)
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 51539.61 MB
ggml_metal_init: maxTransferRate               = built-in GPU
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =   220.20 MB, ( 3338.73 / 51539.61)
whisper_init_state: kv self size  =  220.20 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =   245.76 MB, ( 3584.49 / 51539.61)
whisper_init_state: kv cross size =  245.76 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     0.02 MB, ( 3584.51 / 51539.61)
whisper_init_state: compute buffer (conv)   =   32.36 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     0.02 MB, ( 3584.52 / 51539.61)
whisper_init_state: compute buffer (encode) =  212.36 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     0.02 MB, ( 3584.54 / 51539.61)
whisper_init_state: compute buffer (cross)  =    9.32 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     0.02 MB, ( 3584.56 / 51539.61)
whisper_init_state: compute buffer (decode) =   99.17 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =    30.72 MB, ( 3615.28 / 51539.61)
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =   210.73 MB, ( 3826.01 / 51539.61)
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     7.68 MB, ( 3833.69 / 51539.61)
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =    97.53 MB, ( 3931.23 / 51539.61)

system_info: n_threads = 4 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | METAL = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | CUDA = 0 | COREML = 0 | OPENVINO = 0 | 

main: processing 'test.wav' (6939648 samples, 433.7 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = auto, task = transcribe, timestamps = 1 ...

whisper_full_with_state: auto-detected language: zh (p = 0.916022)

[00:00:00.000 --> 00:00:12.760]  ä¸‰çš„å‰é¢çš„ä¸€ä¸ªæ•°å­—
[00:00:12.760 --> 00:00:21.520]  ä¹çš„åé¢çš„ä¸€ä¸ªæ•°å­—
[00:00:21.520 --> 00:00:28.480]  å…«çš„å‰é¢çš„ä¸‰ä¸ªæ•°å­—
[00:00:28.480 --> 00:00:34.940]  å…«çš„åé¢ä¸‰ä¸ªæ•°å­—
[00:00:34.940 --> 00:00:46.080]  é•¿æ–¹å½¢ æ­£æ–¹å½¢ æ­£æ–¹å½¢ åœ†æŸ±çƒ
[00:00:46.080 --> 00:00:53.440]  åŒå·¦è¾¹æ•°D
[00:00:53.440 --> 00:00:57.340]  æ˜¯D
[00:00:57.340 --> 00:01:05.080]  åŒå·¦ åŒå³è¾¹æ•°
[00:01:05.080 --> 00:01:08.020]  æ˜¯Då‡ ä¸ª
[00:01:08.020 --> 00:01:22.080]  æœ‰ä¸ª ç„¶åè¿™ä¸ªæ•°
[00:01:22.080 --> 00:01:24.840]  è¿™ä»€ä¹ˆå­—å•Š ç­”æ¡ˆéƒ½ä¸æ¸…æ¥š
[00:01:24.840 --> 00:01:25.840]  æœ€
[00:01:25.840 --> 00:01:27.080]  æœ€å¤š
[00:01:27.080 --> 00:01:34.820]  æœ€å¤š
[00:01:34.820 --> 00:01:40.820]  ä¸€å…±æœ‰å‡ ä¸ªå‡æ³•
[00:01:40.820 --> 00:01:45.620]  è¿˜å‰©å‡ ä¸ªç”¨
[00:01:45.620 --> 00:01:49.620]  ç”¨
[00:01:49.620 --> 00:01:55.620]  åŠ æ³• å‡æ³•
[00:01:55.620 --> 00:01:56.820]  ä¸€ä¸ª
[00:01:56.820 --> 00:01:59.080]  ä¸‰ä¸ªæ•°
[00:01:59.080 --> 00:02:02.180]  ä¸ªä½ä¸Šæ˜¯äº”
[00:02:02.180 --> 00:02:05.220]  åä½ä¸Šæ˜¯ä¸€
[00:02:05.220 --> 00:02:12.620]  è¿™ä¸ªæ•°æ˜¯åä¸ªå
[00:02:12.620 --> 00:02:18.880]  å’Œå››ä¸ªä¸€åˆèµ·æ¥
[00:02:18.880 --> 00:02:26.560]  æ˜¯ä¸€ä¸ªåå’Œä¹ä¸ªä¸€åˆèµ·æ¥
[00:02:26.560 --> 00:02:48.320]  æ˜¯ä¸€ä¸ªåå…­é‡Œé¢æœ‰ä¸ªåå’Œä¸€ä¸ªä¸€äºŒåé‡Œé¢æœ‰ä¸ªå
[00:02:48.320 --> 00:02:56.300]  äºŒåäº”å’Œåå‡ ä¸­é—´çš„æ•°æ˜¯
[00:02:56.300 --> 00:03:06.400]  å’Œä¹ç›¸é‚»çš„ä¸¤ä¸ªæ•°æ˜¯
[00:03:06.400 --> 00:03:14.560]  æ¯”å…­æ¯”åå…­å¤šä¸€çš„æ•°æ˜¯
[00:03:14.560 --> 00:03:19.560]  æ¯”åå…­å°‘ä¸‰çš„æ•°æ˜¯
[00:03:19.560 --> 00:03:20.100]  æ¯”åå…­å°‘ä¸‰çš„æ•°æ˜¯
[00:03:20.100 --> 00:03:20.660]  æ¯”åå…­å°‘ä¸‰çš„æ•°æ˜¯
[00:03:20.660 --> 00:03:21.660]  æ¯”åå…­å°‘ä¸‰çš„æ•°æ˜¯
[00:03:21.660 --> 00:03:22.660]  æ¯”åå…­å°‘ä¸‰çš„æ•°æ˜¯
[00:03:22.660 --> 00:03:24.040]  æ¯”åå…­å°‘ä¸‰çš„æ•°æ˜¯
[00:03:24.040 --> 00:03:26.040]  æ¯”åå…­å°‘ä¸‰çš„æ•°æ˜¯
[00:03:26.040 --> 00:03:26.780]  æ¯”åå…­å°‘ä¸‰çš„æ•°æ˜¯
[00:03:26.780 --> 00:03:29.100]  è¢«å‡æ•°
[00:03:29.100 --> 00:03:31.500]  äºŒæ˜¯åä¸€
[00:03:31.500 --> 00:03:34.280]  å‡æ•°æ˜¯ä¸‰
[00:03:34.280 --> 00:03:39.380]  å·®æ˜¯äº”
[00:03:39.380 --> 00:03:43.900]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯
[00:03:43.900 --> 00:03:52.280]  æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:03:52.280 --> 00:03:55.780]  ä¹
[00:03:55.780 --> 00:04:05.640]  åä¹è¿™ä¸ªæ•°åœ¨ä½ç½®
[00:04:05.640 --> 00:04:07.980]  æ¼‚äº®çš„å­—æˆ‘çœ‹
[00:04:07.980 --> 00:04:19.580]  è¡¨è¡¨å¿«ç‚¹å°±ç‰‡ä¸æ˜¯å—
[00:04:19.580 --> 00:04:22.820]  è¡¨æ˜¯
[00:04:22.820 --> 00:04:27.040]  ä¸ªåœ¨ä½
[00:04:27.040 --> 00:04:32.040]  è¡¨ç¤ºä¸ª
[00:04:32.040 --> 00:04:36.280]  è¿™ä¸ª
[00:04:36.280 --> 00:04:38.340]  ç®—
[00:04:38.340 --> 00:04:44.680]  æ˜¯ä¸­é—´æ•°æ˜¯å’Œ
[00:04:44.680 --> 00:04:47.740]  å’Œæ˜¯
[00:04:47.740 --> 00:04:49.320]  è¿™ä¸ª
[00:04:49.320 --> 00:04:57.760]  ç®—æ˜¯ä¸­
[00:04:57.760 --> 00:05:01.160]  è¢«å‡æ•°æ˜¯
[00:05:01.160 --> 00:05:06.160]  å‡æ•°æ˜¯å·®æ˜¯
[00:05:06.160 --> 00:05:12.880]  ä¸€ä¸ªåŠ æ•°æ˜¯åäºŒ
[00:05:12.880 --> 00:05:19.060]  ä¸€ä¸ªåŠ æ•°æ˜¯å…­
[00:05:19.060 --> 00:05:21.100]  å’Œæ˜¯åäºŒ
[00:05:21.100 --> 00:05:27.260]  è¢«å‡æ•°æ˜¯åäº”
[00:05:27.260 --> 00:05:34.900]  å‡æ•°æ˜¯åä¸‰å·®æ˜¯åäº”
[00:05:34.900 --> 00:05:48.800]  ä¸€ä¸ªæ•°ä»å³è¾¹èµ·ç¬¬ä¸€ä½æ˜¯ä½ç¬¬äºŒ
[00:05:48.800 --> 00:06:03.140]  ä¸€ä¸ªæ•°æ˜¯åäºŒåŠ æ•°æ˜¯åä¸‰é‡Œé¢æœ‰ä¸ªåå’Œä¸ªä¸€
[00:06:03.140 --> 00:06:11.840]  ä¸€ä¸ªæ•°æ˜¯åäºŒåŠ æ•°æ˜¯åäºŒåŠ æ•°æ˜¯åä¸‰é‡Œé¢æœ‰ä¸ªåå’Œä¸ªä¸€
[00:06:11.840 --> 00:06:22.580]  å’ŒåäºŒç›¸é‚»çš„ä¸¤ä¸ªæ•°æ˜¯
[00:06:22.580 --> 00:06:34.880]  ä¸ªä¸‰ä¸ªä¸€å’Œä¸€ä¸ªååˆèµ·æ¥æ˜¯
[00:06:34.880 --> 00:06:41.580]  å†è¿‡ä¸¤å°å¯¹
[00:06:41.580 --> 00:06:55.920]  ä¸€ä¸ªæ•°æ˜¯åäºŒåŠ æ•°æ˜¯åä¸‰é‡Œé¢æœ‰ä¸ªåå’Œä¸ªä¸€
[00:06:55.920 --> 00:07:00.780]  ä¸€ä¸ªæ•°æ˜¯åäºŒåŠ æ•°æ˜¯åä¸‰é‡Œé¢æœ‰ä¸ªåå’Œä¸ªä¸€
[00:07:00.780 --> 00:07:05.380]  ä¸€ä¸ªæ•°æ˜¯åäºŒåŠ æ•°æ˜¯åä¸‰é‡Œé¢æœ‰ä¸ªåå’Œä¸ªä¸€
[00:07:05.380 --> 00:07:11.320]  ä¸€ä¸ªæ•°æ˜¯åäºŒåŠ æ•°æ˜¯åä¸‰é‡Œé¢æœ‰ä¸ªåå’Œä¸ªä¸€
[00:07:11.320 --> 00:07:13.320]  è¬è¬


whisper_print_timings:     load time =  1007.19 ms
whisper_print_timings:     fallbacks =   5 p /   4 h
whisper_print_timings:      mel time =   216.87 ms
whisper_print_timings:   sample time =  3550.35 ms / 12205 runs (    0.29 ms per run)
whisper_print_timings:   encode time =  7821.69 ms /    17 runs (  460.10 ms per run)
whisper_print_timings:   decode time =  2958.22 ms /   198 runs (   14.94 ms per run)
whisper_print_timings:   batchd time = 88241.95 ms / 11913 runs (    7.41 ms per run)
whisper_print_timings:   prompt time =  1618.32 ms /  3783 runs (    0.43 ms per run)
whisper_print_timings:    total time = 105432.62 ms
ggml_metal_free: deallocating
ggml_metal_free: deallocating
./main -m models/ggml-large-v3.bin -f test.wav -l auto  11.65s user 1.89s system 12% cpu 1:45.50 total
```


## CoreML
### å®‰è£…ä¾èµ–
```shell
pip install openai-whisper coremltools ane-transformers
```

### ç”Ÿæˆ CoreML æ¨¡å‹
```shell
models/generate-coreml-model.sh large-v3
```
```
ModelDimensions(n_mels=128, n_audio_ctx=1500, n_audio_state=1280, n_audio_head=20, n_audio_layer=32, n_vocab=51866, n_text_ctx=448, n_text_state=1280, n_text_head=20, n_text_layer=32)
/Users/junjian/GitHub/ggerganov/whisper.cpp/env/lib/python3.10/site-packages/whisper/model.py:166: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  assert x.shape[1:] == self.positional_embedding.shape, "incorrect audio shape"
/Users/junjian/GitHub/ggerganov/whisper.cpp/env/lib/python3.10/site-packages/whisper/model.py:97: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  scale = (n_state // self.n_head) ** -0.25
Converting PyTorch Frontend ==> MIL Ops: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2611/2612 [00:00<00:00, 4137.49 ops/s]
Running MIL frontend_pytorch pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 34.67 passes/s]
Running MIL default pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71/71 [00:15<00:00,  4.46 passes/s]
Running MIL backend_mlprogram pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 331.10 passes/s]
done converting
/Users/junjian/GitHub/ggerganov/whisper.cpp/models/coreml-encoder-large-v3.mlmodelc/coremldata.bin
models/coreml-encoder-large-v3.mlmodelc -> models/ggml-large-v3-encoder.mlmodelc
```

### ç¼–è¯‘
```shell
make clean
WHISPER_COREML=1 make -j
```

### è¯­éŸ³è¯†åˆ«
```shell
time ./main -m models/ggml-large-v3.bin -f test.wav -l auto 
```
```
whisper_init_from_file_with_params_no_state: loading model from 'models/ggml-large-v3.bin'
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51866
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 1280
whisper_model_load: n_audio_head  = 20
whisper_model_load: n_audio_layer = 32
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 1280
whisper_model_load: n_text_head   = 20
whisper_model_load: n_text_layer  = 32
whisper_model_load: n_mels        = 128
whisper_model_load: ftype         = 1
whisper_model_load: qntvr         = 0
whisper_model_load: type          = 5 (large v3)
whisper_model_load: adding 1609 extra tokens
whisper_model_load: n_langs       = 100
whisper_backend_init: using Metal backend
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M2 Max
ggml_metal_init: picking default device: Apple M2 Max
ggml_metal_init: default.metallib not found, loading from source
ggml_metal_init: loading '/Users/junjian/GitHub/ggerganov/whisper.cpp/ggml-metal.metal'
ggml_metal_init: GPU name:   Apple M2 Max
ggml_metal_init: GPU family: MTLGPUFamilyApple8 (1008)
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 51539.61 MB
ggml_metal_init: maxTransferRate               = built-in GPU
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =  3117.88 MB, ( 3118.53 / 51539.61)
whisper_model_load:    Metal buffer size =  3117.87 MB
whisper_model_load: model size    = 3117.39 MB
whisper_backend_init: using Metal backend
ggml_metal_init: allocating
ggml_metal_init: found device: Apple M2 Max
ggml_metal_init: picking default device: Apple M2 Max
ggml_metal_init: default.metallib not found, loading from source
ggml_metal_init: loading '/Users/junjian/GitHub/ggerganov/whisper.cpp/ggml-metal.metal'
ggml_metal_init: GPU name:   Apple M2 Max
ggml_metal_init: GPU family: MTLGPUFamilyApple8 (1008)
ggml_metal_init: hasUnifiedMemory              = true
ggml_metal_init: recommendedMaxWorkingSetSize  = 51539.61 MB
ggml_metal_init: maxTransferRate               = built-in GPU
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =   220.20 MB, ( 3338.73 / 51539.61)
whisper_init_state: kv self size  =  220.20 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =   245.76 MB, ( 3584.49 / 51539.61)
whisper_init_state: kv cross size =  245.76 MB
whisper_init_state: loading Core ML model from 'models/ggml-large-v3-encoder.mlmodelc'
whisper_init_state: first run on a device may take a while ...
whisper_init_state: Core ML model loaded
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     0.02 MB, ( 3584.51 / 51539.61)
whisper_init_state: compute buffer (conv)   =   10.85 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     0.02 MB, ( 3584.52 / 51539.61)
whisper_init_state: compute buffer (cross)  =    9.32 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     0.02 MB, ( 3584.54 / 51539.61)
whisper_init_state: compute buffer (decode) =   99.17 MB
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     9.22 MB, ( 3593.76 / 51539.61)
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =     7.68 MB, ( 3601.45 / 51539.61)
ggml_metal_add_buffer: allocated 'backend         ' buffer, size =    97.53 MB, ( 3698.98 / 51539.61)

system_info: n_threads = 4 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | METAL = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | CUDA = 0 | COREML = 1 | OPENVINO = 0 | 

main: processing 'test.wav' (6939648 samples, 433.7 sec), 4 threads, 1 processors, 5 beams + best of 5, lang = auto, task = transcribe, timestamps = 1 ...

whisper_full_with_state: auto-detected language: zh (p = 0.916203)

[00:00:00.000 --> 00:00:12.760]  ä¸‰çš„å‰é¢çš„ä¸€ä¸ªæ•°å­—
[00:00:12.760 --> 00:00:21.520]  ä¹çš„åé¢çš„ä¸€ä¸ªæ•°å­—
[00:00:21.520 --> 00:00:28.480]  å…«çš„å‰é¢çš„ä¸‰ä¸ªæ•°å­—
[00:00:28.480 --> 00:00:34.940]  å…«çš„åé¢ä¸‰ä¸ªæ•°å­—
[00:00:34.940 --> 00:00:43.720]  é•¿æ–¹å½¢æ­£æ–¹å½¢
[00:00:43.720 --> 00:00:46.080]  åœ†æŸ±çƒ
[00:00:46.080 --> 00:00:53.740]  åŒå·¦è¾¹æ•°åœ°
[00:00:53.740 --> 00:00:57.500]  æ˜¯åœ°
[00:00:57.500 --> 00:01:02.880]  åŒå·¦
[00:01:02.880 --> 00:01:05.120]  åŒå³è¾¹æ•°
[00:01:05.120 --> 00:01:06.860]  æ˜¯åœ°
[00:01:06.860 --> 00:01:08.040]  å‡ ä¸ª
[00:01:08.040 --> 00:01:17.120]  æœ‰ä¸ª
[00:01:17.120 --> 00:01:18.640]  æœ‰ä¸ª
[00:01:18.640 --> 00:01:20.680]  ç„¶åè¿™ä¸ª
[00:01:20.680 --> 00:01:22.120]  æ•°
[00:01:22.120 --> 00:01:24.840]  è¿™ä»€ä¹ˆå­—å•Šç­”æ¡ˆéƒ½ä¸æ¸…æ¥š
[00:01:24.840 --> 00:01:25.820]  æœ€
[00:01:25.820 --> 00:01:27.460]  æœ€å¤š
[00:01:27.460 --> 00:01:27.480]  æœ€å¤š
[00:01:27.480 --> 00:01:38.520]  ä¸€å…±æœ‰å‡ ä¸ªå‡æ³•
[00:01:38.520 --> 00:01:42.720]  è¿˜å‰©å‡ ä¸ª
[00:01:42.720 --> 00:01:44.080]  ç”¨
[00:01:44.080 --> 00:01:46.000]  ç”¨
[00:01:46.000 --> 00:01:50.960]  åŠ æ³•å‡æ³•
[00:01:50.960 --> 00:01:51.480]  å¥½
[00:01:51.480 --> 00:01:53.160]  è¿™ä¸ª
[00:01:53.160 --> 00:01:56.660]  ä¸€ä¸ª
[00:01:56.660 --> 00:01:57.460]  ä¸€ä¸ª
[00:01:57.460 --> 00:01:59.140]  è¿™ä¸ªæ•°
[00:01:59.140 --> 00:02:02.200]  ä¸ªä½ä¸Šæ˜¯äº”
[00:02:02.200 --> 00:02:05.260]  åä½ä¸Šæ˜¯ä¸€
[00:02:05.260 --> 00:02:08.060]  è¿™ä¸ªæ•°æ˜¯
[00:02:08.060 --> 00:02:12.820]  åä¸ªå
[00:02:12.820 --> 00:02:21.900]  å’Œå››ä¸ªä¸€åˆèµ·æ¥æ˜¯ä¸€ä¸ª
[00:02:21.900 --> 00:02:29.660]  åå’Œä¹ä¸ªä¸€åˆèµ·æ¥æ˜¯
[00:02:29.660 --> 00:02:33.980]  åå…­é‡Œé¢æœ‰
[00:02:33.980 --> 00:02:35.780]  ä¸ª
[00:02:35.780 --> 00:02:38.540]  åå’Œ
[00:02:38.540 --> 00:02:42.460]  ä¸ªä¸€äºŒåé‡Œé¢
[00:02:42.460 --> 00:02:44.620]  æœ‰
[00:02:44.620 --> 00:02:48.340]  ä¸ªå
[00:02:48.340 --> 00:02:51.620]  äº”åäº”åˆåä¸€
[00:02:51.620 --> 00:03:05.100]  ä¸­é—´çš„æ•°æ˜¯å’Œ9ç›¸é‚»çš„ä¸¤ä¸ªæ•°æ˜¯
[00:03:05.100 --> 00:03:19.280]  æ¯”16å¤š1çš„æ•°æ˜¯æ¯”16å°‘3çš„æ•°æ˜¯
[00:03:19.280 --> 00:03:35.280]  è¢«è§£æ•°æ˜¯11è§£æ•°æ˜¯3å·®æ˜¯
[00:03:35.280 --> 00:03:46.880]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:03:46.880 --> 00:03:47.280]  5
[00:03:47.280 --> 00:03:49.260]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:03:49.260 --> 00:03:49.260]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:03:49.260 --> 00:03:49.260]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:03:49.260 --> 00:03:49.260]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:03:49.260 --> 00:03:49.260]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:03:49.260 --> 00:04:19.240]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:04:19.240 --> 00:04:49.220]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:04:49.220 --> 00:05:19.200]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:05:19.200 --> 00:05:49.180]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:05:49.180 --> 00:06:19.160]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:06:19.160 --> 00:06:49.140]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯
[00:06:49.140 --> 00:07:13.760]  æœ€å¤§çš„ç–‘é—®æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯æœ€å°çš„ä¸¤ä½æ•°æ˜¯


whisper_print_timings:     load time =   859.73 ms
whisper_print_timings:     fallbacks =   3 p /   1 h
whisper_print_timings:      mel time =   224.71 ms
whisper_print_timings:   sample time =  2659.66 ms /  8154 runs (    0.33 ms per run)
whisper_print_timings:   encode time =  5801.61 ms /    16 runs (  362.60 ms per run)
whisper_print_timings:   decode time =  4105.18 ms /   279 runs (   14.71 ms per run)
whisper_print_timings:   batchd time = 54016.19 ms /  7797 runs (    6.93 ms per run)
whisper_print_timings:   prompt time =  1218.58 ms /  2721 runs (    0.45 ms per run)
whisper_print_timings:    total time = 71318.02 ms
ggml_metal_free: deallocating
ggml_metal_free: deallocating
./main -m models/ggml-large-v3.bin -f test.wav -l auto  8.81s user 2.29s system 15% cpu 1:11.44 total
```

### ä»…ç¼–ç 
æ„Ÿè§‰å’Œä¸Šé¢çš„ä¸€æ ·ï¼ŒåŒ…æ‹¬æ•ˆæœå’Œé€Ÿåº¦ã€‚

```shell
models/generate-coreml-model.sh large-v3 --encoder-only True
time ./main -m models/ggml-large-v3.bin -f test.wav -l auto 
```


## å¯¹æ¯”
|  | Neon & MPS ğŸ‘ | CoreML ğŸš€ (47%) |
| --- | ---: | ---: |
| load time | 1007.19 ms | 859.73 ms |
| mel time | 216.87 ms | 224.71 ms |
| sample time | 3550.35 ms | 2659.66 ms |
| encode time | 7821.69 ms | 5801.61 ms |
| decode time | 2958.22 ms | 4105.18 ms |
| batchd time | 88241.95 ms | 54016.19 ms |
| prompt time | 1618.32 ms | 1218.58 ms |
| total time | 105432.62 ms | 71318.02 ms |
| cpu time | 1:45.50 | 1:11.44 |


## å‚è€ƒèµ„æ–™
- [Introducing Accelerated PyTorch Training on Mac](https://pytorch.org/blog/introducing-accelerated-pytorch-training-on-mac/)
- [ARM NEONä¼˜åŒ–ï¼ˆä¸€ï¼‰â€”â€”NEONç®€ä»‹åŠåŸºæœ¬æ¶æ„](https://zyddora.github.io/2016/02/28/neon_1/)
