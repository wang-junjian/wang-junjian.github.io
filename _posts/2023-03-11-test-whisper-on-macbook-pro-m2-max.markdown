---
layout: post
title:  "åœ¨ MacBook Pro M2 Max ä¸Šæµ‹è¯• Whisper"
date:   2023-03-11 08:00:00 +0800
categories: Whisper
tags: [ffmpeg, MacBookProM2Max]
---

## å‡†å¤‡éŸ³é¢‘æ–‡ä»¶
### macOS ä¸Šæ‰“å¼€ QuickTimePlayer
1. [æ–‡ä»¶] -> [æ–°å»ºéŸ³é¢‘å½•åˆ¶]
2. å½•åˆ¶
3. æœ—è¯»ï¼šè·å…°å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸ºâ€œå®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠå¯¼ä½“åˆ¶é€ è®¾å¤‡é‡‡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½â€çš„å…¬å‘Šè¡¨ç¤ºï¼Œé‰´äºæŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯ï¼Œæ”¿åºœå·²ç»å¾—å‡ºç»“è®ºï¼Œæœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠå¯¼ä½“åˆ¶é€ è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶ã€‚
4. åœæ­¢
5. ä¿å­˜(test.m4a)

* [è·å…°é™åˆ¶éƒ¨åˆ†å‹å·å…‰åˆ»æœºå‡ºå£ ä¸­å›½å¸‚åœºå½±å“å‡ ä½•](https://www.163.com/dy/article/HVFHDTT905199DKK.html)

### m4a è½¬æ¢ wav
```shell
ffmpeg -i test.m4a -ar 16000 -ac 1 -c:a pcm_s16le test.wav
```


## [OpenAI Whisper](https://github.com/openai/whisper)

### åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
```shell
conda create --name whisper python
conda activate whisper
```

### å®‰è£…
```shell
pip install --upgrade --no-deps --force-reinstall git+https://github.com/openai/whisper.git

wget https://raw.githubusercontent.com/openai/whisper/main/requirements.txt
pip install -r requirements.txt
```

### æµ‹è¯•
æ¨¡å‹é»˜è®¤ä¿å­˜åœ¨ ```~/.cache/whisper```
```shell
ls ~/.cache/whisper
base.pt     large-v2.pt medium.pt   small.pt    tiny.pt
```

è½¬å½•(X->X)
```shell
whisper test.wav --model small
```

ç¿»è¯‘(X->English)
```shell
whisper test.wav --model small --task translate
```

### æµ‹è¯•ä¸åŒæ¨¡å‹çš„ä½¿ç”¨æƒ…å†µ
æµ‹è¯•è„šæœ¬
```shell
for type in 'tiny' 'base' 'small' 'medium' 'large'
do
    echo '>> ' $type
    time whisper --language zh --model $type test.wav
    print
done
```

ä½¿ç”¨ time å‘½ä»¤æµ‹è¯•ä½¿ç”¨èµ„æºè¯¦æƒ…å’Œåº¦é‡

| model  | user(s) | system(s) | cpu   | total(s) | å†…å­˜ |
| :----: | ------: | --------: | ----: | -------: | ---: |
| tiny   |    7.13 |      6.01 |  358% |    3.664 | 370M |
| base   |   12.21 |     10.29 |  362% |    6.211 | 430M |
| small  |   39.15 |     23.90 |  380% |   16.569 | 1.2G |
| medium |  117.27 |     68.43 |  377% |   49.172 | 3.2G |
| large  |  184.13 |    114.85 |  361% |  1:22.73 | 6.3G |

* tiny
```
[00:00.000 --> 00:04.000] è·è˜­å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸º
[00:04.000 --> 00:09.500] å®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠé“ä½“çŸ¥é“è®¾å¤‡é‡‡å–çš„
[00:09.500 --> 00:13.000] å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º
[00:13.000 --> 00:17.000] åšäºæŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯
[00:17.000 --> 00:20.000] æ”¿åºœå·²ç»å¾—å‡ºç»“è®º
[00:20.000 --> 00:24.000] æœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠé“ä½“
[00:24.000 --> 00:27.000] çŸ¥é“è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶
```

* base
```
[00:00.000 --> 00:12.800] æ ¼è˜­ç™¼å¸ƒäº†ä¸€ä»½ä¸»é¡Œç‚ºå®£å¸ƒå³å°‡å°å…ˆé€²åŠå°é«”è£½é€ è¨­å‚™æ¡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º
[00:12.800 --> 00:17.140] ç›£ç„æŠ€è¡“çš„ç™¼å±•å’Œåœ°ç·£æ”¿æ²»çš„èƒŒæ™¯
[00:17.140 --> 00:26.880] æ”¿åºœå·²ç¶“å¾—å‡ºçµè«–æœ‰å¿…è¦æ“´å¤§ç¾æœ‰çš„ç‰¹å®šåŠå°é«”è£½é€ è¨­å‚™çš„å‡ºå£ç®¡åˆ¶
```

* small
```
[00:00.000 --> 00:13.000] æ ¼å…°å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸º,å®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠå¯¼ä½“åˆ¶é€ è®¾å¤‡é‡‡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º,
[00:13.000 --> 00:27.000] ç›‘ç‹±æŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯,æ”¿åºœå·²ç»å¾—å‡ºç»“è®ºæœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠå¯¼ä½“åˆ¶é€ è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶ã€‚
```

* medium
```
[00:00.000 --> 00:03.840] æ ¼å…°å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸º
[00:03.840 --> 00:08.440] å®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠå¯¼ä½“åˆ¶é€ è®¾å¤‡
[00:08.440 --> 00:12.800] é‡‡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º
[00:12.800 --> 00:17.040] åšäºæŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯
[00:17.040 --> 00:19.840] æ”¿åºœå·²ç»å¾—å‡ºç»“è®º
[00:19.840 --> 00:24.080] æœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠå¯¼ä½“
[00:24.080 --> 00:26.880] åˆ¶é€ è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶
```

* large
```
[00:00.000 --> 00:04.000] æ ¼å…°å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸º
[00:04.000 --> 00:13.000] å®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠå¯¼ä½“åˆ¶é€ è®¾å¤‡é‡‡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º
[00:13.000 --> 00:17.000] é‰´äºæŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯
[00:17.000 --> 00:20.000] æ”¿åºœå·²ç»å¾—å‡ºç»“è®º
[00:20.000 --> 00:27.000] æœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠå¯¼ä½“åˆ¶é€ è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶
```


## [whisper.cpp](https://github.com/ggerganov/whisper.cpp)

### å…‹éš†
```shell
git clone https://github.com/ggerganov/whisper.cpp
```

### ç¼–è¯‘
```shell
cd whisper.cpp
make
```

### ä¸‹è½½æ¨¡å‹
```shell
bash ./models/download-ggml-model.sh base.en
bash ./models/download-ggml-model.sh tiny
bash ./models/download-ggml-model.sh base
bash ./models/download-ggml-model.sh small
bash ./models/download-ggml-model.sh medium
bash ./models/download-ggml-model.sh large
```

### æµ‹è¯•
```shell
./main -f samples/jfk.wav
```
```
whisper_init_from_file_no_state: loading model from 'models/ggml-base.en.bin'
whisper_model_load: loading model
whisper_model_load: n_vocab       = 51864
whisper_model_load: n_audio_ctx   = 1500
whisper_model_load: n_audio_state = 512
whisper_model_load: n_audio_head  = 8
whisper_model_load: n_audio_layer = 6
whisper_model_load: n_text_ctx    = 448
whisper_model_load: n_text_state  = 512
whisper_model_load: n_text_head   = 8
whisper_model_load: n_text_layer  = 6
whisper_model_load: n_mels        = 80
whisper_model_load: f16           = 1
whisper_model_load: type          = 2
whisper_model_load: mem required  =  215.00 MB (+    6.00 MB per decoder)
whisper_model_load: adding 1607 extra tokens
whisper_model_load: model ctx     =  140.60 MB
whisper_model_load: model size    =  140.54 MB
whisper_init_state: kv self size  =    5.25 MB
whisper_init_state: kv cross size =   17.58 MB

system_info: n_threads = 4 / 12 | AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | 

main: processing 'samples/jfk.wav' (176000 samples, 11.0 sec), 4 threads, 1 processors, lang = en, task = transcribe, timestamps = 1 ...


[00:00:00.000 --> 00:00:11.000]   And so my fellow Americans, ask not what your country can do for you, ask what you can do for your country.


whisper_print_timings:     load time =    64.96 ms
whisper_print_timings:     fallbacks =   0 p /   0 h
whisper_print_timings:      mel time =    14.07 ms
whisper_print_timings:   sample time =    10.42 ms /    27 runs (    0.39 ms per run)
whisper_print_timings:   encode time =   217.08 ms /     1 runs (  217.08 ms per run)
whisper_print_timings:   decode time =    62.48 ms /    27 runs (    2.31 ms per run)
whisper_print_timings:    total time =   378.26 ms
```

### æµ‹è¯•ä¸åŒæ¨¡å‹çš„ä½¿ç”¨æƒ…å†µ
æµ‹è¯•è„šæœ¬
```shell
for type in 'tiny' 'base' 'small' 'medium' 'large'
do
    echo '>> ' $type
    time ./main -m models/ggml-$type.bin -f test.wav -l auto
    print
done
```

ä½¿ç”¨ time å‘½ä»¤æµ‹è¯•ä½¿ç”¨èµ„æºè¯¦æƒ…å’Œåº¦é‡

| model  | user(s) | system(s) | cpu   | total(s) | å†…å­˜ |
| :----: | ------: | --------: | ----: | -------: | ---: |
| tiny   |    1.67 |      0.05 |  334% |    0.514 | 130M |
| base   |    2.93 |      0.08 |  355% |    0.848 | 220M |
| small  |    9.16 |      0.20 |  377% |    2.475 | 620M |
| medium |   23.74 |      0.60 |  381% |    6.383 | 1.8G |
| large  |   43.18 |      1.07 |  384% |   11.512 | 3.4G |

* tiny
```
[00:00:00.000 --> 00:00:12.760]  è·è˜­ç™¼å¸ƒäº†ä¸€ä»½ä¸»é¡Œç‚ºå®£å¸ƒå³å°‡å°å…ˆé€²åŠå°é«”çŸ¥é“ç¤¾æœƒæ¡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º
[00:00:12.760 --> 00:00:17.080]  é–“æ–¼æŠ€è¡“çš„ç™¼å±•å’Œåœ°ç·£æ”¿æ²»çš„èƒŒæ™¯
[00:00:17.080 --> 00:00:24.120]  æ”¿åºœå·²ç¶“å¾—å‡ºçµè«–æœ‰å¿…è¦æ“´å¤§ç¾æœ‰çš„ç‰¹å®šåŠå°é«”
[00:00:24.120 --> 00:00:26.760]  çŸ¥é“ç¤¾æœƒçš„å‡ºå£ç®¡åˆ¶
```

* base
```
[00:00:00.000 --> 00:00:12.800]  éš”ç„¶å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸ºå®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠå¯¼ä½“åˆ¶åˆ°è®¾å¤‡é‡‡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º
[00:00:12.800 --> 00:00:17.140]  ç›‘ä¸æŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯
[00:00:17.140 --> 00:00:26.880]  æ”¿åºœå·²ç»å¾—å‡ºç»“è®ºæœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠå¯¼ä½“åˆ¶åˆ°è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶
```

* small
```
[00:00:00.000 --> 00:00:12.360]  è·å…°å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸º,å®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠå¯¼ä½“åˆ¶é€ è®¾å¤‡é‡‡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º,
[00:00:12.360 --> 00:00:26.560]  ç›‘ç‹±æŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯,æ”¿åºœå·²ç»å¾—å‡ºç»“è®ºæœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠå¯¼ä½“åˆ¶é€ è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶ã€‚
```

* medium
```
[00:00:00.000 --> 00:00:03.760]  æ ¼å…°å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸º
[00:00:03.760 --> 00:00:08.440]  å®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠå¯¼ä½“åˆ¶é€ è®¾å¤‡
[00:00:08.440 --> 00:00:12.680]  é‡‡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º
[00:00:12.680 --> 00:00:16.920]  å…¼äºæŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯
[00:00:16.920 --> 00:00:19.720]  æ”¿åºœå·²ç»å¾—å‡ºç»“è®º
[00:00:19.720 --> 00:00:26.600]  æœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠå¯¼ä½“åˆ¶é€ è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶
```

* large
```
[00:00:00.000 --> 00:00:04.000]  æ ¼å…°å‘å¸ƒäº†ä¸€ä»½ä¸»é¢˜ä¸º
[00:00:04.000 --> 00:00:13.000]  å®£å¸ƒå³å°†å¯¹å…ˆè¿›åŠå¯¼ä½“åˆ¶é€ è®¾å¤‡é‡‡å–çš„å‡ºå£ç®¡åˆ¶æªæ–½çš„å…¬å‘Šè¡¨ç¤º
[00:00:13.000 --> 00:00:17.000]  é‰´äºæŠ€æœ¯çš„å‘å±•å’Œåœ°ç¼˜æ”¿æ²»çš„èƒŒæ™¯
[00:00:17.000 --> 00:00:20.000]  æ”¿åºœå·²ç»å¾—å‡ºç»“è®º
[00:00:20.000 --> 00:00:27.000]  æœ‰å¿…è¦æ‰©å¤§ç°æœ‰çš„ç‰¹å®šåŠå¯¼ä½“åˆ¶é€ è®¾å¤‡çš„å‡ºå£ç®¡åˆ¶
```


## OpenAI Whisper & Whisper.cpp

| model  | OpenAI Whisper Total(s) | Whisper.cpp Total(s) | ğŸš€(x) | OpenAI Whisper Memory | Whisper.cpp Memory | ğŸš€(x) | 
| :----: | ----------------------: | -------------------: | ----: | --------------------: | -----------------: | ---: | 
| tiny   |                   3.664 |                0.514 |   6.1 |                  370M |               130M |  1.8 |
| base   |                   6.211 |                0.848 |   6.3 |                  430M |               220M |  1.0 |
| small  |                  16.569 |                2.475 |   5.7 |                  1.2G |               620M |  0.9 |
| medium |                  49.172 |                6.383 |   6.7 |                  3.2G |               1.8G |  0.8 |
| large  |                 1:22.73 |               11.512 |   6.2 |                  6.3G |               3.4G |  0.9 |


## å‚è€ƒèµ„æ–™
* [openai/whisper](https://github.com/openai/whisper)
* [ggerganov/whisper.cpp](https://github.com/ggerganov/whisper.cpp)
* [How to convert any mp3 file to .wav 16khz mono 16bit](https://stackoverflow.com/questions/13358287/how-to-convert-any-mp3-file-to-wav-16khz-mono-16bit)
* [I think I can make 4-bit LLaMA-65B inference run on a 64 GB M1 Pro](https://twitter.com/ggerganov/status/1632422491682484230)
* [Fine-Tune Whisper For Multilingual ASR with ğŸ¤— Transformers](https://huggingface.co/blog/fine-tune-whisper)
