---
layout: post
title:  "åœ¨ MLX ä¸Šä½¿ç”¨ LoRA / QLoRA å¾®è°ƒ Text2SQLï¼ˆå…­ï¼‰ï¼šä½¿ç”¨ LoRA åŸºäº Deepseek-Coder-7B å¾®è°ƒ"
date:   2024-01-27 08:00:00 +0800
categories: MLX Text2SQL
tags: [MLX, LoRA, Deepseek-Coder-7B, Text2SQL, WikiSQL, MacBookProM2Max]
---

## å¤§æ¨¡å‹ Deepseek-Coder-7B
- [deepseek-ai/deepseek-coder-7b-base-v1.5](https://huggingface.co/deepseek-ai/deepseek-coder-7b-base-v1.5)
- [deepseek-ai/deepseek-coder-7b-instruct-v1.5](https://huggingface.co/deepseek-ai/deepseek-coder-7b-instruct-v1.5)


## æ•°æ®é›† WikiSQL

- [WikiSQL](https://github.com/salesforce/WikiSQL)
- [sqllama/sqllama-V0](https://huggingface.co/sqllama/sqllama-V0/blob/main/wikisql.ipynb)

### ä¿®æ”¹è„šæœ¬ mlx-examples/lora/data/wikisql.py
```py
if __name__ == "__main__":
    # ......
    for dataset, name, size in datasets:
        with open(f"data/{name}.jsonl", "w") as fid:
            for e, t in zip(range(size), dataset):
                # deepseek-ai/deepseek-coder-7b-instruct-v1.5
                # å»æ‰å¼€å¤´çš„ <ï½œbeginâ–ofâ–sentenceï½œ>ï¼Œå› ä¸º tokenizer ä¼šè‡ªåŠ¨æ·»åŠ  <ï½œbeginâ–ofâ–sentenceï½œ>
                t = t[3:-4] + "<ï½œendâ–ofâ–sentenceï½œ>"
                json.dump({"text": t}, fid)
                fid.write("\n")
```

æ‰§è¡Œè„šæœ¬ `data/wikisql.py` ç”Ÿæˆæ•°æ®é›†ã€‚
    
```bash
data/wikisql.py
```


## å®‰è£… mlx-lm

```bash
pip install mlx-lm
```


## å¾®è°ƒ

ä½¿ç”¨ LoRA å¾®è°ƒ

### deepseek-ai/deepseek-coder-7b-instruct-v1.5

```bash
time python -m mlx_lm.lora --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
               --train \
               --iters 600
```
```
Loading pretrained model
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Total parameters 6912.463M
Trainable parameters 2.097M
Loading datasets
Training
Starting training..., iters: 600
Iter 1: Val loss 2.532, Val took 23.017s
Iter 10: Train loss 2.476, It/sec 0.610, Tokens/sec 233.939
Iter 20: Train loss 2.254, It/sec 0.603, Tokens/sec 231.470
Iter 30: Train loss 2.027, It/sec 0.564, Tokens/sec 219.675
Iter 40: Train loss 1.810, It/sec 0.623, Tokens/sec 229.324
Iter 50: Train loss 1.629, It/sec 0.626, Tokens/sec 235.960
Iter 60: Train loss 1.433, It/sec 0.612, Tokens/sec 230.657
Iter 70: Train loss 1.440, It/sec 0.536, Tokens/sec 205.828
Iter 80: Train loss 1.445, It/sec 0.580, Tokens/sec 221.729
Iter 90: Train loss 1.454, It/sec 0.644, Tokens/sec 230.853
Iter 100: Train loss 1.465, It/sec 0.629, Tokens/sec 227.520
Iter 110: Train loss 1.308, It/sec 0.642, Tokens/sec 234.599
Iter 120: Train loss 1.258, It/sec 0.547, Tokens/sec 203.351
Iter 130: Train loss 1.208, It/sec 0.535, Tokens/sec 202.567
Iter 140: Train loss 1.242, It/sec 0.535, Tokens/sec 197.166
Iter 150: Train loss 1.230, It/sec 0.484, Tokens/sec 185.982
Iter 160: Train loss 1.115, It/sec 0.514, Tokens/sec 192.832
Iter 170: Train loss 1.141, It/sec 0.530, Tokens/sec 205.737
Iter 180: Train loss 1.131, It/sec 0.566, Tokens/sec 194.020
Iter 190: Train loss 1.142, It/sec 0.551, Tokens/sec 208.123
Iter 200: Train loss 1.189, It/sec 0.568, Tokens/sec 205.594
Iter 200: Val loss 1.175, Val took 28.336s
Iter 210: Train loss 1.109, It/sec 0.625, Tokens/sec 225.139
Iter 220: Train loss 1.069, It/sec 0.587, Tokens/sec 223.650
Iter 230: Train loss 1.046, It/sec 0.586, Tokens/sec 215.076
Iter 240: Train loss 1.023, It/sec 0.607, Tokens/sec 219.824
Iter 250: Train loss 1.072, It/sec 0.530, Tokens/sec 207.403
Iter 260: Train loss 0.981, It/sec 0.596, Tokens/sec 216.396
Iter 270: Train loss 0.889, It/sec 0.569, Tokens/sec 218.139
Iter 280: Train loss 1.112, It/sec 0.594, Tokens/sec 227.021
Iter 290: Train loss 1.069, It/sec 0.551, Tokens/sec 205.965
Iter 300: Train loss 0.907, It/sec 0.562, Tokens/sec 214.827
Iter 310: Train loss 0.960, It/sec 0.585, Tokens/sec 213.497
Iter 320: Train loss 0.858, It/sec 0.601, Tokens/sec 213.847
Iter 330: Train loss 0.937, It/sec 0.571, Tokens/sec 205.752
Iter 340: Train loss 0.935, It/sec 0.552, Tokens/sec 212.401
Iter 350: Train loss 0.907, It/sec 0.552, Tokens/sec 209.727
Iter 360: Train loss 0.996, It/sec 0.530, Tokens/sec 201.702
Iter 370: Train loss 0.892, It/sec 0.554, Tokens/sec 205.891
Iter 380: Train loss 1.008, It/sec 0.588, Tokens/sec 211.078
Iter 390: Train loss 0.972, It/sec 0.557, Tokens/sec 211.817
Iter 400: Train loss 0.822, It/sec 0.602, Tokens/sec 216.862
Iter 400: Val loss 1.115, Val took 28.797s
Iter 410: Train loss 0.858, It/sec 0.543, Tokens/sec 202.470
Iter 420: Train loss 0.866, It/sec 0.592, Tokens/sec 218.569
Iter 430: Train loss 0.846, It/sec 0.570, Tokens/sec 210.504
Iter 440: Train loss 0.897, It/sec 0.567, Tokens/sec 221.815
Iter 450: Train loss 0.879, It/sec 0.525, Tokens/sec 200.252
Iter 460: Train loss 0.896, It/sec 0.582, Tokens/sec 214.533
Iter 470: Train loss 0.829, It/sec 0.544, Tokens/sec 204.817
Iter 480: Train loss 0.825, It/sec 0.526, Tokens/sec 199.035
Iter 490: Train loss 0.901, It/sec 0.572, Tokens/sec 208.777
Iter 500: Train loss 0.919, It/sec 0.555, Tokens/sec 214.673
Iter 510: Train loss 0.816, It/sec 0.617, Tokens/sec 224.638
Iter 520: Train loss 0.796, It/sec 0.585, Tokens/sec 209.467
Iter 530: Train loss 0.835, It/sec 0.575, Tokens/sec 203.523
Iter 540: Train loss 0.831, It/sec 0.536, Tokens/sec 206.305
Iter 550: Train loss 0.842, It/sec 0.591, Tokens/sec 216.378
Iter 560: Train loss 0.751, It/sec 0.545, Tokens/sec 207.297
Iter 570: Train loss 0.772, It/sec 0.538, Tokens/sec 203.582
Iter 580: Train loss 0.897, It/sec 0.502, Tokens/sec 199.693
Iter 590: Train loss 0.754, It/sec 0.559, Tokens/sec 205.148
Iter 600: Train loss 0.828, It/sec 0.523, Tokens/sec 201.825
Iter 600: Val loss 1.082, Val took 29.715s
Saved final adapter weights to adapters.npz.
python -m mlx_lm.lora --model deepseek-ai/deepseek-coder-7b-instruct-v1.5     42.47s user 176.35s system 18% cpu 19:35.47 total
```


## è¯„ä¼°

è®¡ç®—æµ‹è¯•é›†å›°æƒ‘åº¦ï¼ˆPPLï¼‰å’Œäº¤å‰ç†µæŸå¤±ï¼ˆLossï¼‰ã€‚

### deepseek-ai/deepseek-coder-7b-instruct-v1.5

```bash
python -m mlx_lm.lora --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                      --adapter-file adapters.npz \
                      --test
```
```
Test loss 1.473, Test ppl 4.364.
```


## èåˆï¼ˆFuseï¼‰

```bash
python -m mlx_lm.fuse --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                      --adapter-file adapters.npz \
                      --save-path lora_fused_model
```


## æç¤ºè¯

ç›´æ¥ä½¿ç”¨ `deepseek-ai/deepseek-coder-7b-instruct-v1.5` ç”Ÿæˆæ¨¡å‹ï¼Œéœ€è¦å¯¹æç¤ºè¯è¿›è¡Œä¿®æ”¹ã€‚

### âŒ ä¸å¥½çš„æç¤ºè¯ã€‚

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: What is Wang Junjian's name?
A: "
```
```
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
==========
Prompt: <ï½œbeginâ–ofâ–sentenceï½œ>You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer
### Instruction:
table: students
columns: Name, Age, School, Grade, Height, Weight
Q: What is Wang Junjian's name?
A: 
### Response:

As an AI model, I don't have access to any specific database, including the "students" table you've mentioned. Therefore, I can't provide the specific information you're looking for, such as Wang Junjian'
==========
Prompt: 282.062 tokens-per-sec
Generation: 86.552 tokens-per-sec
```

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 100 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜çš„SQLï¼šWhat is Wang Junjian's name?"
```
```
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
==========
Prompt: <ï½œbeginâ–ofâ–sentenceï½œ>You are an AI programming assistant, utilizing the Deepseek Coder model, developed by Deepseek Company, and you only answer questions related to computer science. For politically sensitive questions, security and privacy issues, and other non-computer science questions, you will refuse to answer
### Instruction:
table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜çš„SQLï¼šWhat is Wang Junjian's name?
### Response:

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹çš„SQLæŸ¥è¯¢æ¥è·å–Wang Junjiançš„åå­—ï¼š

SELECT Name 
FROM students 
WHERE Name = 'Wang Junjian';

è¯·æ³¨æ„ï¼Œè¿™ä¸ªæŸ¥è¯¢å‡è®¾ä½ çš„"students"è¡¨ä¸­çš„"Name"åˆ—æ˜¯ç”¨æ¥å­˜å‚¨æ¯ä¸ªå­¦ç”Ÿçš„åå­—çš„ã€‚å¦‚æœè¿™ä¸ªå‡è®¾ä¸æˆç«‹ï¼Œæˆ–è€…ä½ çš„è¡¨ç»“æ„æœ‰æ‰€ä¸åŒï¼Œä½ å¯èƒ½éœ€è¦è°ƒæ•´è¿™ä¸ªæŸ¥è¯¢ã€‚

==========
Prompt: 296.709 tokens-per-sec
Generation: 46.091 tokens-per-sec
```

### ğŸ‘ å¥½çš„æç¤ºè¯ã€‚

```
table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆä¸‹é¢é—®é¢˜çš„SQLï¼š\nWhat is Wang Junjian's name?
```

```
table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆWhat is Wang Junjian's name?ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚
```


## ç”Ÿæˆ

### ç‹å†›å»ºçš„å§“åæ˜¯ä»€ä¹ˆï¼Ÿ

- deepseek-coder-7b-instruct-v1.5ï¼ˆä¸­æ–‡ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆç‹å†›å»ºçš„å§“åæ˜¯ä»€ä¹ˆï¼Ÿï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name FROM students WHERE Name = 'ç‹å†›å»º';
```

- deepseek-coder-7b-instruct-v1.5ï¼ˆè‹±æ–‡é—®é¢˜ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆWhat is Wang Junjian's name?ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name FROM students WHERE Name = 'Wang Junjian';
```

- deepseek-coder-7b-instruct-v1.5 + LoRA

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: What is Wang Junjian's name?
A: "
```

```
SELECT Name FROM students WHERE Age = 'Wang Junjian'
```

### ç‹å†›å»ºçš„å¹´é¾„æ˜¯å¤šå°‘ï¼Ÿ

- deepseek-coder-7b-instruct-v1.5ï¼ˆä¸­æ–‡ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆç‹å†›å»ºçš„å¹´é¾„æ˜¯å¤šå°‘ï¼Ÿï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Age FROM students WHERE Name = 'ç‹å†›å»º';
```

- deepseek-coder-7b-instruct-v1.5ï¼ˆè‹±æ–‡é—®é¢˜ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆHow old is Wang Junjian?ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Age FROM students WHERE Name = 'Wang Junjian';
```

- deepseek-coder-7b-instruct-v1.5 + LoRA

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: How old is Wang Junjian?
A: "
```

```
SELECT Age FROM students WHERE Name = 'Wang Junjian'
```

### ç‹å†›å»ºæ¥è‡ªå“ªæ‰€å­¦æ ¡ï¼Ÿ

- deepseek-coder-7b-instruct-v1.5ï¼ˆä¸­æ–‡ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆç‹å†›å»ºæ¥è‡ªå“ªæ‰€å­¦æ ¡ï¼Ÿï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT School FROM students WHERE Name = 'ç‹å†›å»º';
```

- deepseek-coder-7b-instruct-v1.5ï¼ˆè‹±æ–‡é—®é¢˜ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆWhich school did Wang Junjian come from?ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT School FROM students WHERE Name = 'Wang Junjian';
```

- deepseek-coder-7b-instruct-v1.5 + LoRA

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: Which school did Wang Junjian come from?
A: "
```

```
SELECT School FROM students WHERE Name = 'Wang Junjian'
```

### æŸ¥è¯¢ç‹å†›å»ºçš„å§“åã€å¹´é¾„ã€å­¦æ ¡ä¿¡æ¯ã€‚

- deepseek-coder-7b-instruct-v1.5ï¼ˆä¸­æ–‡ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆæŸ¥è¯¢ç‹å†›å»ºçš„å§“åã€å¹´é¾„ã€å­¦æ ¡ä¿¡æ¯ã€‚ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name, Age, School FROM students WHERE Name = 'ç‹å†›å»º';
```

- deepseek-coder-7b-instruct-v1.5ï¼ˆè‹±æ–‡é—®é¢˜ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆQuery Wang Junjianâ€™s name, age, and school information.ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name, Age, School 
FROM students 
WHERE Name = 'Wang Junjian';
```

- deepseek-coder-7b-instruct-v1.5 + LoRA

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: Query Wang Junjianâ€™s name, age, and school information.
A: "
```

```
SELECT Name, Age, School FROM students WHERE Name = 'Wang Junjian'
```

### æŸ¥è¯¢ç‹å†›å»ºçš„æ‰€æœ‰ä¿¡æ¯ã€‚

- deepseek-coder-7b-instruct-v1.5ï¼ˆä¸­æ–‡ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆæŸ¥è¯¢ç‹å†›å»ºçš„æ‰€æœ‰ä¿¡æ¯ã€‚ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT * FROM students WHERE Name = 'ç‹å†›å»º';
```

- deepseek-coder-7b-instruct-v1.5ï¼ˆè‹±æ–‡é—®é¢˜ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆQuery all information about Wang Junjian.ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT * FROM students WHERE Name = 'Wang Junjian';
```

- deepseek-coder-7b-instruct-v1.5 + LoRA

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: Query all information about Wang Junjian.
A: "
```

```
SELECT * FROM students WHERE Name = 'Wang Junjian'
```

### æŸ¥è¯¢å§“åï¼Œå¹´é¾„ï¼Œå­¦æ ¡ï¼Œå¹´çº§ç­‰ä¿¡æ¯ï¼Œæ¡ä»¶ä¸ºå§“åç­‰äºç‹å†›å»ºä¸”å¹´é¾„å°äº20å²ã€‚

- deepseek-coder-7b-instruct-v1.5ï¼ˆä¸­æ–‡ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆæŸ¥è¯¢å§“åï¼Œå¹´é¾„ï¼Œå­¦æ ¡ï¼Œå¹´çº§ç­‰ä¿¡æ¯ï¼Œæ¡ä»¶ä¸ºå§“åç­‰äºç‹å†›å»ºä¸”å¹´é¾„å°äº20å²ã€‚ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name, Age, School, Grade 
FROM students 
WHERE Name = 'ç‹å†›å»º' AND Age < 20;
```

- deepseek-coder-7b-instruct-v1.5ï¼ˆè‹±æ–‡é—®é¢˜ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆQuery information such as name, age, school, grade, etc. The condition is that the name is equal to Wang Junjian and the age is less than 20 years old.ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name, Age, School, Grade 
FROM students 
WHERE Name = 'Wang Junjian' AND Age < 20;
```

- deepseek-coder-7b-instruct-v1.5 + LoRA

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: Query information such as name, age, school, grade, etc. The condition is that the name is equal to Wang Junjian and the age is less than 20 years old.
A: "
```

```
SELECT Name, Age, School, Grade 
FROM students 
WHERE Name = 'Wang Junjian' AND Age < 20
```

### ç»Ÿè®¡ä¸€ä¸‹ä¹å¹´çº§æœ‰å¤šå°‘å­¦ç”Ÿã€‚

- deepseek-coder-7b-instruct-v1.5ï¼ˆä¸­æ–‡ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆç»Ÿè®¡ä¸€ä¸‹ä¹å¹´çº§æœ‰å¤šå°‘å­¦ç”Ÿã€‚ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT COUNT(*) FROM students WHERE Grade = 9;
```

- deepseek-coder-7b-instruct-v1.5ï¼ˆè‹±æ–‡é—®é¢˜ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆCount how many students there are in ninth grade.ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT COUNT(*) FROM students WHERE Grade = 9;
```

- deepseek-coder-7b-instruct-v1.5 + LoRA

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: Count how many students there are in ninth grade.
A: "
```

```
SELECT COUNT(*) FROM students WHERE Grade = 'Ninth'
```

### ç»Ÿè®¡ä¸€ä¸‹ä¹å¹´çº§æœ‰å¤šå°‘å­¦ç”Ÿï¼ˆä¹å¹´çº§çš„å€¼æ˜¯9thï¼‰ã€‚

- deepseek-coder-7b-instruct-v1.5ï¼ˆä¸­æ–‡ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆç»Ÿè®¡ä¸€ä¸‹ä¹å¹´çº§æœ‰å¤šå°‘å­¦ç”Ÿï¼ˆä¹å¹´çº§çš„å€¼æ˜¯9thï¼‰ã€‚ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT COUNT(*) FROM students WHERE Grade = '9th';
```

- deepseek-coder-7b-instruct-v1.5ï¼ˆè‹±æ–‡é—®é¢˜ï¼‰

```bash
python -m mlx_lm.generate --model deepseek-ai/deepseek-coder-7b-instruct-v1.5 \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆCount how many students there are in ninth grade.ï¼ˆThe value for ninth grade is 9th.ï¼‰ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT COUNT(*) FROM students WHERE Grade = '9th';
```

- deepseek-coder-7b-instruct-v1.5 + LoRA

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
Q: Count how many students there are in ninth grade.ï¼ˆThe value for ninth grade is 9th.ï¼‰
A: "
```

```
SELECT COUNT(*) FROM students WHERE Grade = '9th'
```


## éªŒè¯ LoRA å¾®è°ƒçš„æ¨¡å‹åŸæœ¬çš„åŠŸèƒ½æ˜¯å¦æ­£å¸¸

### ç‹å†›å»ºçš„å§“åæ˜¯ä»€ä¹ˆï¼Ÿ

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆWhat is Wang Junjian's name?ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name FROM students WHERE Age = 'Wang Junjian'
```

### ç‹å†›å»ºçš„å¹´é¾„æ˜¯å¤šå°‘ï¼Ÿ

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆHow old is Wang Junjian?ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Age FROM students WHERE Name = 'Wang Junjian'
```

### ç‹å†›å»ºæ¥è‡ªå“ªæ‰€å­¦æ ¡ï¼Ÿ

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆWhich school did Wang Junjian come from?ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT School FROM students WHERE Name = 'Wang Junjian'
```

### æŸ¥è¯¢ç‹å†›å»ºçš„å§“åã€å¹´é¾„ã€å­¦æ ¡ä¿¡æ¯ã€‚

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆQuery Wang Junjianâ€™s name, age, and school information.ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name, Age, School FROM students WHERE Name = 'Wang Junjian'
```

### æŸ¥è¯¢ç‹å†›å»ºçš„æ‰€æœ‰ä¿¡æ¯ã€‚

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆQuery all information about Wang Junjian.ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT * FROM students WHERE Name = 'Wang Junjian'
```

### æŸ¥è¯¢å§“åï¼Œå¹´é¾„ï¼Œå­¦æ ¡ï¼Œå¹´çº§ç­‰ä¿¡æ¯ï¼Œæ¡ä»¶ä¸ºå§“åç­‰äºç‹å†›å»ºä¸”å¹´é¾„å°äº20å²ã€‚
```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆQuery information such as name, age, school, grade, etc. The condition is that the name is equal to Wang Junjian and the age is less than 20 years old.ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT Name, Age, School, Grade FROM students WHERE Name = 'Wang Junjian' AND Age < 20
```

### ç»Ÿè®¡ä¸€ä¸‹ä¹å¹´çº§æœ‰å¤šå°‘å­¦ç”Ÿã€‚

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆCount how many students there are in ninth grade.ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT COUNT(*) FROM students WHERE Grade = 'Ninth'
```

### ç»Ÿè®¡ä¸€ä¸‹ä¹å¹´çº§æœ‰å¤šå°‘å­¦ç”Ÿï¼ˆä¹å¹´çº§çš„å€¼æ˜¯9thï¼‰ã€‚

```bash
python -m mlx_lm.generate --model lora_fused_model \
                          --max-tokens 50 \
                          --prompt "table: students
columns: Name, Age, School, Grade, Height, Weight
ä½¿ç”¨ä¸Šé¢çš„æ•°æ®åº“ä¿¡æ¯ï¼Œå¸®æˆ‘ç”Ÿæˆè¿™ä¸ªé—®é¢˜ï¼ˆCount how many students there are in ninth grade.ï¼ˆThe value for ninth grade is 9th.ï¼‰ï¼‰çš„ SQLï¼Œå›ç­”åªè¦ SQL è¯­å¥ã€‚"
```

```
SELECT COUNT(*) FROM students WHERE Grade = '9th'
```


## æ€»ç»“
- `deepseek-ai/deepseek-coder-7b-instruct-v1.5` æ˜¯ä¸“é—¨ä¸ºç¼–å†™ä»£ç è€Œè®¾è®¡çš„ï¼Œæ‰€ä»¥å¯¹äº SQL è¯­å¥çš„ç”Ÿæˆèƒ½åŠ›å¾ˆå¼ºã€‚
- `deepseek-ai/deepseek-coder-7b-instruct-v1.5` ä¸­è‹±æ–‡èƒ½åŠ›éƒ½å¾ˆå¼ºï¼Œä¸­æ–‡ä¸è‹±æ–‡ä¹‹é—´çš„è½¬æ¢ä¹Ÿå¾ˆå¥½ã€‚
- `deepseek-ai/deepseek-coder-7b-instruct-v1.5` æœ¬èº«çš„åŠŸèƒ½å°±å¾ˆå¼ºå¤§ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œéœ€è¦è°ƒè¯•å¥½æç¤ºè¯ã€‚
- `deepseek-ai/deepseek-coder-7b-instruct-v1.5` ä½¿ç”¨ LoRA å¾®è°ƒåçš„æ¨¡å‹ï¼Œå¯ä»¥å¾ˆå¥½çš„ä¿ç•™åŸæœ¬çš„åŠŸèƒ½ï¼Œä¹Ÿå¯ä»¥å¾ˆå¥½çš„æ‰©å±•æ–°çš„åŠŸèƒ½ã€‚


## å‚è€ƒèµ„æ–™
- [MLX Community](https://huggingface.co/mlx-community)
- [Fine-Tuning with LoRA or QLoRA](https://github.com/ml-explore/mlx-examples/tree/main/lora)
- [Generate Text with LLMs and MLX](https://github.com/ml-explore/mlx-examples/tree/main/llms)
- [Awesome Text2SQL](https://github.com/eosphoros-ai/Awesome-Text2SQL)
- [Awesome Text2SQLï¼ˆä¸­æ–‡ï¼‰](https://github.com/eosphoros-ai/Awesome-Text2SQL/blob/main/README.zh.md)
- [Mistral AI](https://huggingface.co/mistralai)
- [A Beginnerâ€™s Guide to Fine-Tuning Mistral 7B Instruct Model](https://adithyask.medium.com/a-beginners-guide-to-fine-tuning-mistral-7b-instruct-model-0f39647b20fe)
- [Mistral Instruct 7B Finetuning on MedMCQA Dataset](https://saankhya.medium.com/mistral-instruct-7b-finetuning-on-medmcqa-dataset-6ec2532b1ff1)
- [Fine-tuning Mistral on your own data](https://github.com/brevdev/notebooks/blob/main/mistral-finetune-own-data.ipynb)
- [mlx-examples llms Mistral](https://github.com/ml-explore/mlx-examples/blob/main/llms/mistral/README.md)
- [deepseek-ai/deepseek-coder-7b-base-v1.5](https://huggingface.co/deepseek-ai/deepseek-coder-7b-base-v1.5)
- [DeepSeek LLM: Scaling Open-Source Language Models with Longtermism](https://arxiv.org/abs/2401.02954)
