---
layout: single
title:  "GraphRAG"
date:   2024-07-25 08:00:00 +0800
categories: GraphRAG LLM
tags: [GraphRAG, Ollama, XInference, GettingStarted]
---

## [GraphRAG](https://github.com/microsoft/graphrag)
GraphRAG é¡¹ç›®æ˜¯ä¸€ä¸ªæ•°æ®ç®¡é“å’Œè½¬æ¢å¥—ä»¶ï¼Œæ—¨åœ¨åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰çš„åŠ›é‡ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­æå–æœ‰æ„ä¹‰çš„ç»“æ„åŒ–æ•°æ®ã€‚

è‹¥è¦äº†è§£æ›´å¤šå…³äº GraphRAG ä»¥åŠå®ƒå¦‚ä½•ç”¨äºå¢å¼ºæ‚¨çš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å¯¹æ‚¨çš„ç§æœ‰æ•°æ®è¿›è¡Œæ¨ç†çš„èƒ½åŠ›ï¼Œè¯·è®¿é—® [Microsoft Research Blog Post](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)ã€‚

- [Welcome to GraphRAG](https://microsoft.github.io/graphrag/)
- [GraphRAG: Unlocking LLM discovery on narrative private data](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)
- [GraphRAG: New tool for complex data discovery now on GitHub](https://www.microsoft.com/en-us/research/blog/graphrag-new-tool-for-complex-data-discovery-now-on-github/)
- [arxiv: From Local to Global: A Graph RAG Approach to Query-Focused Summarization](https://arxiv.org/pdf/2404.16130)
- []()
- []()


## [Get Started](https://microsoft.github.io/graphrag/posts/get_started/)

### æ„å»ºè™šæ‹Ÿç¯å¢ƒ
```bash
cd /Users/junjian/GitHub/microsoft/graphrag

python -m venv env
source env/bin/activate
```

### å®‰è£… GraphRAG
```bash
pip install graphrag
```

### å‡†å¤‡æ•°æ®
```bash
mkdir -p ./ragtest/input
curl https://www.gutenberg.org/cache/epub/24022/pg24022.txt > ./ragtest/input/book.txt
```

### è¿è¡Œç´¢å¼•å™¨

#### è®¾ç½®æ‚¨çš„å·¥ä½œåŒºå˜é‡

åˆå§‹åŒ–æ‚¨çš„å·¥ä½œåŒºï¼Œè¿è¡Œ `graphrag.index --init` å‘½ä»¤
```bash
python -m graphrag.index --init --root ./ragtest
```

è¿™å°†åœ¨ `./ragtest` ç›®å½•ä¸­åˆ›å»ºä¸¤ä¸ªæ–‡ä»¶ï¼š`.env` å’Œ `settings.yaml` ã€‚
- `.env` åŒ…å«è¿è¡Œ GraphRAG pipeline æ‰€éœ€çš„ç¯å¢ƒå˜é‡ã€‚å¦‚æœæ‚¨æ£€æŸ¥è¯¥æ–‡ä»¶ï¼Œæ‚¨å°†çœ‹åˆ°å®šä¹‰äº†ä¸€ä¸ªå•ä¸€çš„ç¯å¢ƒå˜é‡ï¼Œ`GRAPHRAG_API_KEY=<API_KEY>` ã€‚è¿™æ˜¯ OpenAI API æˆ– Azure OpenAI ç«¯ç‚¹çš„ API å¯†é’¥ã€‚æ‚¨å¯ä»¥ç”¨æ‚¨è‡ªå·±çš„ API å¯†é’¥æ›¿æ¢å®ƒã€‚
- `settings.yaml` åŒ…å« pipeline çš„è®¾ç½®ã€‚æ‚¨å¯ä»¥ä¿®æ”¹æ­¤æ–‡ä»¶æ¥æ›´æ”¹ pipeline çš„è®¾ç½®ã€‚

#### ä¿®æ”¹é…ç½® `ragtest/settings.yaml`

```yaml
encoding_model: cl100k_base
skip_workflows: []
llm:
  api_key: ${GRAPHRAG_API_KEY}
  model: mistral
  api_base: http://127.0.0.1:11434/v1

embeddings:
  llm:
    api_key: ${GRAPHRAG_API_KEY}
    model: nomic-embed-text
    api_base: http://127.0.0.1:11434/v1
```

##### æ¨ç†æœåŠ¡é…ç½®

| æ¨ç†æœåŠ¡ | OpenAI API (api_base) |
| --- | --- |
| Ollama     | http://127.0.0.1:11434/v1 |
| FastChat   | http://127.0.0.1:8000/v1  |
| XInference | http://127.0.0.1:9997/v1  |

##### æ¨¡å‹é…ç½®

| æ¨¡å‹ (model) | ç±»å‹ | è¯­è¨€ | ä¸‹è½½ |
| --- | --- | --- | --- |
| mistral:v0.2          | llm        | è‹±æ–‡  | ollama pull mistral:v0.2 |
| aya:35b               | llm        | å¤šè¯­è¨€ | ollama pull aya:35b |
| phi3:medium           | llm        | è‹±æ–‡  | ollama pull phi3:medium |
| yi:9b                 | llm        | ä¸­è‹±æ–‡ | ollama pull yi:9b |
| codestral:22b         | llm        | ä»£ç   | ollama pull codestral:22b |
| nomic-embed-text      | embeddings | è‹±æ–‡  | ollama pull nomic-embed-text |
| mxbai-embed-large     | embeddings | è‹±æ–‡  | ollama pull mxbai-embed-large |
| bge-base-zh-v1.5      | embeddings | ä¸­è‹±æ–‡ | ollama pull quentinz/bge-base-zh-v1.5 |
| dmeta-embedding-zh    | embeddings | ä¸­è‹±æ–‡ | ollama pull herald/dmeta-embedding-zh |

ä½¿ç”¨äº† Ollama çš„å¾ˆå¤šæ¨¡å‹è¿›è¡Œäº†æµ‹è¯•ï¼Œæœ€ç»ˆå¾—åˆ°äº†ä¸Šé¢çš„ç»“æœã€‚

ä¸‹é¢çš„æ¨¡å‹åœ¨ä½¿ç”¨è¿‡ç¨‹ä¸­å‡ºç°äº†é—®é¢˜ï¼š
- mistral:v0.3 æœ€åˆå‘å¸ƒçš„å¯ä»¥ï¼Œæœ€æ–°çš„ç‰ˆæœ¬æœ‰é—®é¢˜ã€‚
- llama3:8b
- llama3.1:8b
- llama3.1:70b
- aya:8b
- gemma2:9b
- gemma2:27b
- glm4:9b
- internlm2:7b
- yi:6b
- yi:34b
- qwen2:0.5b
- qwen2:1.5b
- qwen2:7b
- qwen2:72b
- deepseek-v2:16b
- deepseek-coder-v2:16b
- codeqwen:7b
- codegeex4:9b

##### é”™è¯¯å¤„ç†

âŒ embeddings ä½¿ç”¨ Ollama å®¹æ˜“å‡ºç°é”™è¯¯ ZeroDivisionErrorï¼Œå¦‚ä¸‹ï¼š
```bash
Error embedding chunk {'OpenAIEmbedding': "Error code: 400 - {'error': {'message': 'invalid input type', 'type': 'api_error', 'param': None, 'code': None}}"}
Traceback (most recent call last):
  File "/opt/miniconda/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/miniconda/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/query/__main__.py", line 76, in <module>
    run_local_search(
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/query/cli.py", line 154, in run_local_search
    result = search_engine.search(query=query)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/query/structured_search/local_search/search.py", line 118, in search
    context_text, context_records = self.context_builder.build_context(
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/query/structured_search/local_search/mixed_context.py", line 139, in build_context
    selected_entities = map_query_to_entities(
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/query/context_builder/entity_extraction.py", line 55, in map_query_to_entities
    search_results = text_embedding_vectorstore.similarity_search_by_text(
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/vector_stores/lancedb.py", line 118, in similarity_search_by_text
    query_embedding = text_embedder(text)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/query/context_builder/entity_extraction.py", line 57, in <lambda>
    text_embedder=lambda t: text_embedder.embed(t),
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/query/llm/oai/embedding.py", line 96, in embed
    chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/numpy/lib/function_base.py", line 550, in average
    raise ZeroDivisionError(
ZeroDivisionError: Weights sum to zero, can't be normalized
```
**å¯ä»¥æŠŠ embeddings çš„ api_base æ¢æˆ XInferenceçš„**

âŒ ä½¿ç”¨ `Qwen2:7b` æ¨¡å‹åœ¨ create_base_entity_graph é˜¶æ®µå‡ºç°é”™è¯¯ï¼Œå¦‚ä¸‹ï¼š 
```bash
datashaper.workflow.workflow ERROR Error executing verb "cluster_graph" in create_base_entity_graph: Columns must be same length as key
Traceback (most recent call last):
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/datashaper/workflow/workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/index/verbs/graph/clustering/cluster_graph.py", line 102, in cluster_graph
    output_df[[level_to, to]] = pd.DataFrame(
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/pandas/core/frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/pandas/core/frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/pandas/core/indexers/utils.py", line 391, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
```
**æ¢ä¸Šé¢çš„æ¨¡å‹**

âŒ ä½¿ç”¨ `Llama3.1:8b` æ¨¡å‹åœ¨ create_base_entity_graph é˜¶æ®µå‡ºç°é”™è¯¯ï¼Œå¦‚ä¸‹ï¼š 
```bash
datashaper.workflow.workflow ERROR Error executing verb "cluster_graph" in create_base_entity_graph: EmptyNetworkError
Traceback (most recent call last):
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/datashaper/workflow/workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/index/verbs/graph/clustering/cluster_graph.py", line 61, in cluster_graph
    results = output_df[column].apply(lambda graph: run_layout(strategy, graph))
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/pandas/core/series.py", line 4924, in apply
    ).apply()
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/pandas/core/apply.py", line 1427, in apply
    return self.apply_standard()
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/pandas/core/apply.py", line 1507, in apply_standard
    mapped = obj._map_values(
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/pandas/core/base.py", line 921, in _map_values
    return algorithms.map_array(arr, mapper, na_action=na_action, convert=convert)
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/pandas/core/algorithms.py", line 1743, in map_array
    return lib.map_infer(values, mapper, convert=convert)
  File "lib.pyx", line 2972, in pandas._libs.lib.map_infer
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/index/verbs/graph/clustering/cluster_graph.py", line 61, in <lambda>
    results = output_df[column].apply(lambda graph: run_layout(strategy, graph))
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/index/verbs/graph/clustering/cluster_graph.py", line 167, in run_layout
    clusters = run_leiden(graph, strategy)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/index/verbs/graph/clustering/strategies/leiden.py", line 26, in run
    node_id_to_community_map = _compute_leiden_communities(
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/index/verbs/graph/clustering/strategies/leiden.py", line 61, in _compute_leiden_communities
    community_mapping = hierarchical_leiden(
  File "<@beartype(graspologic.partition.leiden.hierarchical_leiden) at 0x319eddd80>", line 304, in hierarchical_leiden
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/graspologic/partition/leiden.py", line 588, in hierarchical_leiden
    hierarchical_clusters_native = gn.hierarchical_leiden(
leiden.EmptyNetworkError: EmptyNetworkError
```
**æ¢ä¸Šé¢çš„æ¨¡å‹**

âŒ ä½¿ç”¨ `Llama3.1:70b` æ¨¡å‹åœ¨ create_final_community_reports é˜¶æ®µå‡ºç°é”™è¯¯ï¼Œå¦‚ä¸‹ï¼š 
```bash
graphrag.index.graph.extractors.community_reports.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/index/graph/extractors/community_reports/community_reports_extractor.py", line 58, in __call__
    await self._llm(
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/openai/json_parsing_llm.py", line 34, in __call__
    result = await self._delegate(input, **kwargs)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/openai/openai_token_replacing_llm.py", line 37, in __call__
    return await self._delegate(input, **kwargs)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/openai/openai_history_tracking_llm.py", line 33, in __call__
    output = await self._delegate(input, **kwargs)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/base/caching_llm.py", line 104, in __call__
    result = await self._delegate(input, **kwargs)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 177, in __call__
    result, start = await execute_with_retry()
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 159, in execute_with_retry
    async for attempt in retryer:
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 166, in __anext__
    do = await self.iter(retry_state=self._retry_state)
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/tenacity/asyncio/__init__.py", line 153, in iter
    result = await action(retry_state)
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/tenacity/_utils.py", line 99, in inner
    return call(*args, **kwargs)
  File "/Users/junjian/GitHub/microsoft/graphrag/env/lib/python3.10/site-packages/tenacity/__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
  File "/opt/miniconda/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/opt/miniconda/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 165, in execute_with_retry
    return await do_attempt(), start
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/base/rate_limiting_llm.py", line 147, in do_attempt
    return await self._delegate(input, **kwargs)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/base/base_llm.py", line 48, in __call__
    return await self._invoke_json(input, **kwargs)
  File "/Users/junjian/GitHub/microsoft/graphrag/graphrag/llm/openai/openai_chat_llm.py", line 90, in _invoke_json
    raise RuntimeError(FAILED_TO_CREATE_JSON_ERROR)
RuntimeError: Failed to generate valid JSON output
```
**æ¢ä¸Šé¢çš„æ¨¡å‹**

#### è¿è¡Œç´¢å¼• pipeline

```bash
python -m graphrag.index --root ./ragtest
```
```bash
â ¦ GraphRAG Indexer 
â”œâ”€â”€ Loading Input (text) - 1 files loaded (0 filtered) â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00 0:00:00
â”œâ”€â”€ create_base_text_units
â”œâ”€â”€ create_base_extracted_entities
â”œâ”€â”€ create_summarized_entities
â”œâ”€â”€ create_base_entity_graph
â”œâ”€â”€ create_final_entities
â”œâ”€â”€ create_final_nodes
â”œâ”€â”€ create_final_communities
â”œâ”€â”€ join_text_units_to_entity_ids
â”œâ”€â”€ create_final_relationships
â”œâ”€â”€ join_text_units_to_relationship_ids
â”œâ”€â”€ create_final_community_reports
â”œâ”€â”€ create_final_text_units
â”œâ”€â”€ create_base_documents
â””â”€â”€ create_final_documents
ğŸš€ All workflows completed successfully.
```

æ­¤è¿‡ç¨‹è¿è¡Œå°†éœ€è¦ä¸€äº›æ—¶é—´ã€‚è¿™å–å†³äºæ‚¨çš„è¾“å…¥æ•°æ®çš„å¤§å°ã€æ‚¨æ­£åœ¨ä½¿ç”¨çš„æ¨¡å‹ä»¥åŠæ‰€ä½¿ç”¨çš„æ–‡æœ¬å—å¤§å°ï¼ˆè¿™äº›å¯ä»¥åœ¨æ‚¨çš„ `.env` æ–‡ä»¶ä¸­è¿›è¡Œé…ç½®ï¼‰ã€‚ä¸€æ—¦ pipeline å®Œæˆï¼Œæ‚¨åº”è¯¥ä¼šçœ‹åˆ°ä¸€ä¸ªåä¸º `./ragtest/output/<timestamp>/artifacts` çš„æ–°æ–‡ä»¶å¤¹ï¼Œå…¶ä¸­åŒ…å«ä¸€ç³»åˆ—çš„ parquet æ–‡ä»¶ã€‚

### è¿è¡ŒæŸ¥è¯¢å¼•æ“

#### ä½¿ç”¨ `å…¨å±€(global)æœç´¢` æå‡ºé«˜å±‚æ¬¡é—®é¢˜

What are the top themes in this story?ï¼ˆè¿™ä¸ªæ•…äº‹çš„ä¸»é¢˜æ˜¯ä»€ä¹ˆï¼Ÿï¼‰

```bash
python -m graphrag.query \
    --root ./ragtest \
    --method global \
    "What are the top themes in this story?"
```
```
INFO: Reading settings from ragtest/settings.yaml
creating llm client with {'api_key': 'REDACTED,len=9', 'type': "openai_chat", 'model': 'mistral:v0.3', 'max_tokens': 4000, 'temperature': 0.0, 'top_p': 1.0, 'n': 1, 'request_timeout': 180.0, 'api_base': 'http://127.0.0.1:11434/v1', 'api_version': None, 'organization': None, 'proxy': None, 'cognitive_services_endpoint': None, 'deployment_name': None, 'model_supports_json': True, 'tokens_per_minute': 0, 'requests_per_minute': 0, 'max_retries': 10, 'max_retry_wait': 10.0, 'sleep_on_rate_limit_recommendation': True, 'concurrent_requests': 25}

SUCCESS: Global Search Response:  The story primarily revolves around the themes of redemption and transformation, as depicted in Charles Dickens' classic tale 'A Christmas Carol'. This narrative centers around Ebenezer Scrooge, a man who undergoes a profound change after being visited by three ghosts on Christmas Eve [Data: Reports 1].

In addition to the story, the Verdant Oasis Plaza community benefits from a digital library that offers electronic resources such as books and texts for free use under the Project Gutenberg License [Data: Reports 2].

Furthermore, the Unity March taking place in Verdant Oasis Plaza has garnered media attention from Tribune Spotlight, suggesting it may have a significant impact on the community dynamics [Data: Reports 3]. This event could potentially shape the social landscape of the area.
```

#### ä½¿ç”¨ `æœ¬åœ°(local)æœç´¢` é’ˆå¯¹ç‰¹å®šè§’è‰²æå‡ºæ›´å…·ä½“é—®é¢˜

Who is Scrooge, and what are his main relationships?ï¼ˆæ–¯å…‹é²å¥‡æ˜¯è°ï¼Œä»–çš„ä¸»è¦å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿï¼‰

```bash
python -m graphrag.query \
    --root ./ragtest \
    --method local \
    "Who is Scrooge, and what are his main relationships?"
```
```
INFO: Reading settings from ragtest/settings.yaml
creating llm client with {'api_key': 'REDACTED,len=9', 'type': "openai_chat", 'model': 'mistral:v0.3', 'max_tokens': 4000, 'temperature': 0.0, 'top_p': 1.0, 'n': 1, 'request_timeout': 180.0, 'api_base': 'http://127.0.0.1:11434/v1', 'api_version': None, 'organization': None, 'proxy': None, 'cognitive_services_endpoint': None, 'deployment_name': None, 'model_supports_json': True, 'tokens_per_minute': 0, 'requests_per_minute': 0, 'max_retries': 10, 'max_retry_wait': 10.0, 'sleep_on_rate_limit_recommendation': True, 'concurrent_requests': 25}
creating embedding llm client with {'api_key': 'REDACTED,len=9', 'type': "openai_embedding", 'model': 'bge-base-zh-v1.5', 'max_tokens': 4000, 'temperature': 0, 'top_p': 1, 'n': 1, 'request_timeout': 180.0, 'api_base': 'http://127.0.0.1:9997/v1', 'api_version': None, 'organization': None, 'proxy': None, 'cognitive_services_endpoint': None, 'deployment_name': None, 'model_supports_json': None, 'tokens_per_minute': 0, 'requests_per_minute': 0, 'max_retries': 10, 'max_retry_wait': 10.0, 'sleep_on_rate_limit_recommendation': True, 'concurrent_requests': 25}

SUCCESS: Local Search Response:  Ebenezer Scrooge is a fictional character created by Charles Dickens, who first appeared in the novel "A Christmas Carol," published in 1843. Scrooge is a miserly old man who values money above all else and is known for being cold-hearted and uncaring towards others.

Throughout the story, we learn about Scrooge's main relationships:

1. Jacob Marley: Scrooge's former business partner who died seven years prior to the events of the novel. Marley appears to Scrooge as a ghostly figure and warns him about his fate if he does not change his ways.

2. Bob Cratchit: Scrooge employs Bob Cratchit as his clerk, and they have a master-servant relationship. Scrooge is harsh towards Cratchit, but after his transformation, he becomes kinder and more generous to him.

3. Tiny Tim: Bob Cratchit's youngest son, who is sickly and disabled. Scrooge initially shows no concern for Tiny Tim's well-being but later expresses regret for not having been more compassionate towards him.

4. Fred: Scrooge's nephew, who invites him to Christmas dinner every year but is always rejected. Despite this, Fred remains friendly and hopeful that his uncle will change. After Scrooge's transformation, he welcomes Fred warmly into his life.

5. Belle: Scrooge was once engaged to Belle, but their relationship ended due to Scrooge's obsession with money. She represents the love and warmth that Scrooge has lost over the years.

6. The Ghosts of Christmas Past, Present, and Yet to Come: These supernatural beings visit Scrooge on Christmas Eve and show him visions of his past, present, and future, respectively. They play a crucial role in helping Scrooge understand the error of his ways and inspiring him to change.
```


## OpenAI API
### Ollama
- completions
```bash
curl http://localhost:11434/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "mistral:v0.3",
        "messages": [
            {
                "role": "user",
                "content": "Hello!"
            }
        ]
    }'|jq
```
```json
{
  "id": "chatcmpl-14",
  "object": "chat.completion",
  "created": 1722220031,
  "model": "mistral:v0.3",
  "system_fingerprint": "fp_ollama",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": " Hello there! How can I assist you today? Feel free to ask me anything related to programming, data analysis, or machine learning. I'm here to help!\n\nIf you have any general questions or just need someone to bounce ideas off of, I'll do my best to help out or guide you in the right direction. Let's get started! ğŸ˜Š"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 7,
    "completion_tokens": 79,
    "total_tokens": 86
  }
}
```

- embeddings
```bash
curl http://localhost:11434/v1/embeddings \
    -H "Content-Type: application/json" \
    -d '{
        "input": "Hello!",
        "model": "nomic-embed-text"
    }'|jq
```
```json
{
  "object": "list",
  "data": [
    {
      "object": "embedding",
      "embedding": [
        0.020163044,
        -0.0036894183,
        //......
        -0.04950454,
        -0.010347797
      ],
      "index": 0
    }
  ],
  "model": "nomic-embed-text"
}
```

### XIinference
- completions
```bash
curl http://localhost:9997/v1/chat/completions \
    -H "Content-Type: application/json" \
    -d '{
        "model": "qwen-chat",
        "messages": [
            {
                "role": "user",
                "content": "Hello!"
            }
        ]
    }'|jq
```
```json
{
  "id": "chat27fca670-4d54-11ef-bbf6-8e835058c3ee",
  "object": "chat.completion",
  "created": 1722220931,
  "model": "qwen-chat",
  "choices": [
    {
      "index": 0,
      "message": {
        "role": "assistant",
        "content": "Hello! How can I help you today?"
      },
      "finish_reason": "stop"
    }
  ],
  "usage": {
    "prompt_tokens": 21,
    "completion_tokens": 9,
    "total_tokens": 30
  }
}
```

- embeddings
```bash
curl http://127.0.0.1:9997/v1/embeddings \
    -H "Content-Type: application/json" \
    -d '{
        "input": "Hello!",
        "model": "bge-base-zh"
    }'|jq
```
```json
{
  "object": "list",
  "model": "bge-base-zh-1-0",
  "data": [
    {
      "index": 0,
      "object": "embedding",
      "embedding": [
        0.007897183299064636,
        -0.012519387528300285,
        //......
        -0.01635596714913845,
        -0.08653949201107025
      ]
    }
  ],
  "usage": {
    "prompt_tokens": 37,
    "total_tokens": 37
  }
}
```


## å‚è€ƒèµ„æ–™
- [ä»ä¼ ç»ŸRAGåˆ°GraphRAG](https://www.bilibili.com/video/BV1bm41117XN/?vd_source=16d75c77a472e53d327450ec8d54c043)
- [Ollama Embedding models](https://ollama.com/blog/embedding-models)
- [ValueError: Columns must be same length as key #514](https://github.com/microsoft/graphrag/issues/514)
- [/v1/embeddings OpenAI compatible API endpoint #2416](https://github.com/ollama/ollama/issues/2416)
- [OpenAI: /v1/embeddings compatibility #5285](https://github.com/ollama/ollama/pull/5285)
- [Error executing verb "cluster_graph" in create_base_entity_graph: EmptyNetworkError details=None #562](https://github.com/microsoft/graphrag/issues/562)
- [Ollama GraphRAG OSS LLM community support #339](https://github.com/microsoft/graphrag/issues/339)
- [Use llama2 locally, keep requesting '/chat/completions' got 404 in ollama serve. #1052](https://github.com/OpenDevin/OpenDevin/issues/1052)
- [OpenAI API compatibility #305](https://github.com/ollama/ollama/issues/305)
- [503 Server Error #1724](https://github.com/ollama/ollama/issues/1724)
