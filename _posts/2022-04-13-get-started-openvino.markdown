---
layout: post
title:  "Get Started OpenVINO"
date:   2022-04-13 08:00:00 +0800
categories: AI OpenVINO
tags: [Install, venv]
---

## [OpenVINO](https://www.intel.cn/content/www/cn/zh/developer/tools/openvino-toolkit/overview.html)
> **Open** **V**isual **I**nference and **N**eural network **O**ptimization

## [OpenVINO å®‰è£…](https://docs.openvino.ai/nightly/openvino_docs_install_guides_overview.html)
### [Development](https://pypi.org/project/openvino-dev/)
#### pip å®‰è£…
* [ä¸‹è½½](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/download.html)

å®‰è£… OpenVINO å¼€å‘å·¥å…·
```shell
python -m venv openvino_env
```

* Linux
```shell
source openvino_env/bin/activate
```
* Windows
```shell
openvino_env\Scripts\activate.bat
```

```shell
python -m pip install --upgrade pip
pip install openvino-dev[onnx,pytorch,kaldi,mxnet,caffe,tensorflow2]==2022.1.0 -i https://mirrors.aliyun.com/pypi/simple/
```
* [Install OpenVINOâ„¢ Development Tools](https://docs.openvino.ai/nightly/openvino_docs_install_guides_install_dev_tools.html)

#### æºä»£ç ç¼–è¯‘å®‰è£…(æ²¡æœ‰æˆåŠŸ)ğŸ‘¹
[Build OpenVINOâ„¢ Inference Engine](https://github.com/openvinotoolkit/openvino/wiki/BuildingCode)

```shell
mkdir openvinotoolkit && cd openvinotoolkit
git clone -b 2022.1.0 https://github.com/openvinotoolkit/openvino.git
git clone https://github.com/openvinotoolkit/open_model_zoo.git

cd openvino
sudo ./install_build_dependencies.sh 
sudo ./scripts/install_dependencies/install_NEO_OCL_driver.sh -y --no_numa
sudo ./scripts/install_dependencies/install_openvino_dependencies.sh -y -c=python

cmake --install . --prefix /opt/intel/openvino
```
* [OpenVINO Dockerfile](https://github.com/openvinotoolkit/docker_ci/blob/master/dockerfiles/ubuntu20/build_custom/Dockerfile)

### [Runtime](https://pypi.org/project/openvino/)

## OpenVINO å¼€å‘åŒ…ä¸‹çš„ç»„ä»¶
### [Model Optimizer](https://docs.openvino.ai/latest/openvino_docs_MO_DG_Deep_Learning_Model_Optimizer_DevGuide.html)
* mo
è®­ç»ƒçš„æ¨¡å‹å¯¼å…¥ã€è½¬æ¢å’Œä¼˜åŒ–ä¸º OpenVINO å¯ç”¨çš„æ ¼å¼ï¼ˆIRï¼‰ã€‚

### [Benchmark Tool](https://docs.openvino.ai/latest/openvino_inference_engine_tools_benchmark_tool_README.html)
* benchmark_app
å…è®¸æ‚¨åœ¨åŒæ­¥å’Œå¼‚æ­¥æ¨¡å¼ä¸‹ä¼°è®¡å—æ”¯æŒè®¾å¤‡ä¸Šçš„æ·±åº¦å­¦ä¹ æ¨¡å‹æ¨ç†æ€§èƒ½ã€‚

### [Accuracy Checker](https://docs.openvino.ai/latest/omz_tools_accuracy_checker.html) å’Œ [Annotation Converter](https://docs.openvino.ai/latest/omz_tools_accuracy_checker_annotation_converters.html)
* accuracy_check
æ·±åº¦å­¦ä¹ å‡†ç¡®æ€§éªŒè¯å·¥å…·ï¼Œå¯ç”¨äºæ”¶é›†é’ˆå¯¹å¸¸ç”¨æ•°æ®é›†çš„å‡†ç¡®æ€§æŒ‡æ ‡ã€‚è¯¥å·¥å…·çš„ä¸»è¦ä¼˜ç‚¹æ˜¯é…ç½®çš„çµæ´»æ€§å’Œä¸€ç»„æ”¯æŒçš„æ•°æ®é›†ã€é¢„å¤„ç†ã€åå¤„ç†å’ŒæŒ‡æ ‡ã€‚
* convert_annotation
ç”¨äºå‡†å¤‡æ•°æ®é›†ä»¥ä½¿ç”¨ accuracy_check è¿›è¡Œè¯„ä¼°ã€‚

### [Post-Training Optimization Tool](https://docs.openvino.ai/latest/pot_README.html)
* pot
è®­ç»ƒåä¼˜åŒ–å·¥å…·å…è®¸æ‚¨ä½¿ç”¨é«˜çº§åŠŸèƒ½ï¼ˆå¦‚é‡åŒ–å’Œä½ç²¾åº¦ä¼˜åŒ–ï¼‰ä¼˜åŒ–è®­ç»ƒçš„æ¨¡å‹ï¼Œè€Œæ— éœ€é‡æ–°è®­ç»ƒæˆ–å¾®è°ƒæ¨¡å‹ã€‚è¿˜å¯ä»¥é€šè¿‡ [API](https://docs.openvino.ai/latest/pot_compression_api_README.html) è¿›è¡Œä¼˜åŒ–ã€‚

### [Open Model Zoo tools](https://docs.openvino.ai/latest/omz_tools_downloader.html)
* omz_downloader
ç”¨äºè®¿é—®é¢„è®­ç»ƒæ·±åº¦å­¦ä¹ å…¬å…±æ¨¡å‹å’Œè‹±ç‰¹å°”è®­ç»ƒæ¨¡å‹çš„é›†åˆã€‚
* omz_converter
ä½¿ç”¨æ¨¡å‹ä¼˜åŒ–å™¨å°†å­˜å‚¨åœ¨åŸå§‹æ·±åº¦å­¦ä¹ æ¡†æ¶æ ¼å¼ä¸­çš„ Open Model Zoo æ¨¡å‹è½¬æ¢ä¸º OpenVINO ä¸­é—´è¡¨ç¤º (IR)ã€‚
* omz_quantizer
ç”¨äºä½¿ç”¨è®­ç»ƒåä¼˜åŒ–å·¥å…·ï¼ˆPost-Training Optimization Toolï¼‰å°† IR æ ¼å¼çš„å…¨ç²¾åº¦æ¨¡å‹è‡ªåŠ¨é‡åŒ–ä¸ºä½ç²¾åº¦ç‰ˆæœ¬ã€‚
* omz_info_dumper
ç”¨äºå°†æœ‰å…³æ¨¡å‹çš„ä¿¡æ¯è½¬å‚¨ä¸ºæœºå™¨å¯è¯»æ ¼å¼ã€‚
* omz_data_downloader
æ•°æ®é›†ä¸‹è½½å™¨

## éªŒè¯å®‰è£…
```shell
$ python -c "from openvino.inference_engine import IECore; print('Inference Engine Available Devices: ', IECore().available_devices)"
Inference Engine Available Devices:  ['CPU', 'GPU']
```

## æŸ¥è¯¢ OpenVINO Runtime è®¾å¤‡åŠæŒ‡æ ‡
[Hello Query Device Python Sample](https://github.com/openvinotoolkit/openvino/tree/master/samples/python/hello_query_device)

```shell
$ cd <openvino_dir>
$ python samples/python/hello_query_device/hello_query_device.py
[ INFO ] Available devices:
[ INFO ] CPU :
[ INFO ]        SUPPORTED_PROPERTIES:
[ INFO ]                AVAILABLE_DEVICES:
[ INFO ]                RANGE_FOR_ASYNC_INFER_REQUESTS: 1, 1, 1
[ INFO ]                RANGE_FOR_STREAMS: 1, 12
[ INFO ]                FULL_DEVICE_NAME: Intel(R) Core(TM) i7-8700 CPU @ 3.20GHz
[ INFO ]                OPTIMIZATION_CAPABILITIES: FP32, FP16, INT8, BIN, EXPORT_IMPORT
[ INFO ]                CACHE_DIR:
[ INFO ]                NUM_STREAMS: 1
[ INFO ]                AFFINITY: UNSUPPORTED TYPE
[ INFO ]                INFERENCE_NUM_THREADS: 0
[ INFO ]                PERF_COUNT: False
[ INFO ]                INFERENCE_PRECISION_HINT: UNSUPPORTED TYPE
[ INFO ]                PERFORMANCE_HINT: UNSUPPORTED TYPE
[ INFO ]                PERFORMANCE_HINT_NUM_REQUESTS: 0
[ INFO ]
[ INFO ] GPU :
[ INFO ]        SUPPORTED_PROPERTIES:
[ INFO ]                AVAILABLE_DEVICES: 0
[ INFO ]                RANGE_FOR_ASYNC_INFER_REQUESTS: 1, 2, 1
[ INFO ]                RANGE_FOR_STREAMS: 1, 2
[ INFO ]                OPTIMAL_BATCH_SIZE: 1
[ INFO ]                MAX_BATCH_SIZE: 1
[ INFO ]                FULL_DEVICE_NAME: Intel(R) UHD Graphics 630 (iGPU)
[ INFO ]                DEVICE_TYPE: UNSUPPORTED TYPE
[ INFO ]                DEVICE_GOPS: UNSUPPORTED TYPE
[ INFO ]                OPTIMIZATION_CAPABILITIES: FP32, BIN, FP16
[ INFO ]                GPU_DEVICE_TOTAL_MEM_SIZE: UNSUPPORTED TYPE
[ INFO ]                GPU_UARCH_VERSION: unknown
[ INFO ]                GPU_EXECUTION_UNITS_COUNT: 24
[ INFO ]                GPU_MEMORY_STATISTICS: UNSUPPORTED TYPE
[ INFO ]                PERF_COUNT: False
[ INFO ]                MODEL_PRIORITY: UNSUPPORTED TYPE
[ INFO ]                GPU_HOST_TASK_PRIORITY: UNSUPPORTED TYPE
[ INFO ]                GPU_QUEUE_PRIORITY: UNSUPPORTED TYPE
[ INFO ]                GPU_QUEUE_THROTTLE: UNSUPPORTED TYPE
[ INFO ]                GPU_ENABLE_LOOP_UNROLLING: True
[ INFO ]                CACHE_DIR:
[ INFO ]                PERFORMANCE_HINT: UNSUPPORTED TYPE
[ INFO ]                COMPILATION_NUM_THREADS: 12
[ INFO ]                NUM_STREAMS: 1
[ INFO ]                PERFORMANCE_HINT_NUM_REQUESTS: 0
[ INFO ]                DEVICE_ID: 0
[ INFO ]
```

## æ¨¡å‹
* [Intel Pre-Trained Models](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/index.md)
    * [Intel's Pre-Trained Models Device Support](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/intel/device_support.md)
* [Public Pre-Trained Models](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/index.md)
    * [Public Pre-Trained Models Device Support](https://github.com/openvinotoolkit/open_model_zoo/blob/master/models/public/device_support.md)

### ä¸‹è½½æ‰€æœ‰æ¨¡å‹
```shell
omz_downloader --all
```

### è½¬æ¢æ‰€æœ‰ä¸‹è½½çš„æ¨¡å‹åˆ° IR æ ¼å¼
```shell
omz_converter --all
```

## æ¨¡å‹æŸ¥çœ‹
netron å¯ä»¥æŸ¥çœ‹å„ç§æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ æ¡†æ¶è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹ã€‚

### å®‰è£… [netron](https://pypi.org/project/netron/)
```shell
pip install netron
```

### æŸ¥çœ‹ç½‘ç»œ
é€šè¿‡è®¾ç½® ```--host 0.0.0.0```ï¼Œå±€åŸŸç½‘å†…çš„å…¶å®ƒä¸»æœºä¹Ÿå¯ä»¥é€šè¿‡ http://ip:8080 è®¿é—®ã€‚
```shell
netron public/alexnet/FP16/alexnet.xml --host 0.0.0.0
```

### Web åº”ç”¨ [netron](https://netron.app)
é€šè¿‡é¡µé¢çš„ä¸‹è½½å¯ä»¥å®‰è£…æœ¬åœ°ç¨‹åºã€‚

## Samples
### å›¾åƒåˆ†ç±»
å¼‚æ­¥æ¨ç† [Image Classification Async Python Sample](https://github.com/openvinotoolkit/openvino/tree/master/samples/python/classification_sample_async)

åŒæ­¥æ¨ç† [Hello Classification Python Sample](https://github.com/openvinotoolkit/openvino/tree/master/samples/python/hello_classification)

[Image å’Œ Video æ–‡ä»¶](https://github.com/intel-iot-devkit/sample-videos)
[download.01.org](https://download.01.org)

ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
```shell
omz_downloader --name alexnet
```

è½¬æ¢æ¨¡å‹ï¼Œå¦‚æœæ¨¡å‹é IR æˆ– ONNX æ ¼å¼å°±éœ€è¦è½¬æ¢ã€‚

```shell
omz_converter --name alexnet
```

ä¸‹è½½å›¾ç‰‡
```shell
wget https://pamsdailydish.com/wp-content/uploads/2015/04/Bunch-Bananas-1.jpg -O banana.jpg
```

å¼‚æ­¥æ¨¡å‹æ¨ç†
```shell
$ python samples/python/classification_sample_async/classification_sample_async.py -m public/alexnet/FP16/alexnet.xml -i banana.jpg -d CPU
[ INFO ] Creating OpenVINO Runtime Core
[ INFO ] Reading the model: public/alexnet/FP16/alexnet.xml
[ INFO ] Loading the model to the plugin
[ INFO ] Starting inference in asynchronous mode
[ INFO ] Image path: banana.jpg
[ INFO ] Top 10 results: 
[ INFO ] class_id probability
[ INFO ] --------------------
[ INFO ] 954      0.9999748
[ INFO ] 666      0.0000086
[ INFO ] 953      0.0000053
[ INFO ] 939      0.0000025
[ INFO ] 951      0.0000020
[ INFO ] 945      0.0000017
[ INFO ] 941      0.0000016
[ INFO ] 940      0.0000009
[ INFO ] 943      0.0000005
[ INFO ] 950      0.0000002
[ INFO ] 
[ INFO ] This sample is an API example, for any performance measurements please use the dedicated benchmark_app tool
```

åŒæ­¥æ¨¡å‹æ¨ç†
```shell
$ python samples/python/hello_classification/hello_classification.py public/alexnet/FP16/alexnet.xml banana.jpg CPU
```

### å›¾åƒè¯†åˆ«
[Hello Reshape SSD Python Sample](https://github.com/openvinotoolkit/openvino/tree/master/samples/python/hello_reshape_ssd)

ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
```shell
omz_downloader --name mobilenet-ssd
```

è½¬æ¢æ¨¡å‹ï¼Œå¦‚æœæ¨¡å‹é IR æˆ– ONNX æ ¼å¼å°±éœ€è¦è½¬æ¢ã€‚

```shell
omz_converter --name mobilenet-ssd
```

æ¨¡å‹æ¨ç†
```shell
$ python samples/python/hello_reshape_ssd/hello_reshape_ssd.py public/mobilenet-ssd/FP16/mobilenet-ssd.xml banana.jpg CPU
[ INFO ] Creating OpenVINO Runtime Core
[ INFO ] Reading the model: public/mobilenet-ssd/FP16/mobilenet-ssd.xml
[ INFO ] Reshaping the model to the height and width of the input image
[ INFO ] Loading the model to the plugin
[ INFO ] Starting inference in synchronous mode
[ INFO ] Found: class_id = 3, confidence = 0.69, coords = (139, 16), (418, 319)
[ INFO ] Image out.bmp was created!
```

### ä½¿ç”¨æºç åŠ¨æ€åˆ›å»ºæ¨¡å‹ï¼ˆä¸éœ€è¦ XML æ–‡ä»¶ï¼‰
[Model Creation Python Sample](https://github.com/openvinotoolkit/openvino/tree/master/samples/python/model_creation_sample)

```shell
$ python samples/python/model_creation_sample/model_creation_sample.py samples/python/model_creation_sample/lenet.bin CPU
[ INFO ] Creating OpenVINO Runtime Core
[ INFO ] Loading the model using ngraph function with weights from samples/python/model_creation_sample/lenet.bin
[ INFO ] Loading the model to the plugin
[ INFO ] Starting inference in synchronous mode
[ INFO ] Top 1 results: 
[ INFO ] Image 0
[ INFO ] 
[ INFO ] classid probability label
[ INFO ] -------------------------
[ INFO ] 0       1.0000000   0
[ INFO ] 
[ INFO ] Image 1
[ INFO ] 
......
[ INFO ] Image 9
[ INFO ] 
[ INFO ] classid probability label
[ INFO ] -------------------------
[ INFO ] 9       1.0000000   9
```

## å·¥å…·å¥—ä»¶æ’ä»¶
[è‹±ç‰¹å°”Â® å‘è¡Œç‰ˆ OpenVINOâ„¢ å·¥å…·å¥—ä»¶](https://www.intel.cn/content/www/cn/zh/developer/tools/openvino-toolkit/overview.html)

### [è®¡ç®—æœºè§†è§‰æ³¨é‡Šå·¥å…·](https://github.com/openvinotoolkit/cvat)
è¿™ä¸ªåŸºäº Web çš„å·¥å…·å¯åœ¨è®­ç»ƒæ¨¡å‹ä¹‹å‰å¸®åŠ©æ³¨é‡Šè§†é¢‘å’Œå›¾åƒã€‚

### [æ•°æ®é›†ç®¡ç†æ¡†æ¶](https://github.com/openvinotoolkit/datumaro)
ä½¿ç”¨æ­¤æ’ä»¶å¯ä»¥æ„å»ºã€è½¬æ¢å’Œåˆ†ææ•°æ®é›†ã€‚

### [æ·±åº¦å­¦ä¹ æµåª’ä½“æ’­æ”¾å™¨](https://github.com/dlstreamer/dlstreamer)
è€ƒè™‘ä½¿ç”¨æ­¤åˆ†ææ¡†æ¶ï¼Œä»¥ä½¿ç”¨è‹±ç‰¹å°”å‘è¡Œç‰ˆ OpenVINO å·¥å…·å¥—ä»¶åˆ›å»ºå’Œéƒ¨ç½²å¤æ‚çš„åª’ä½“åˆ†æç®¡é“ã€‚

### [ç¥ç»ç½‘ç»œå‹ç¼©æ¡†æ¶](https://github.com/openvinotoolkit/nncf)
ä½¿ç”¨æ­¤åŸºäº PyTorch çš„æ¡†æ¶è¿›è¡Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒã€‚

### [OpenVINOâ„¢ æ¨¡å‹æœåŠ¡å™¨](https://github.com/openvinotoolkit/model_server)
è¯¥å¯æ‰©å±•æ¨ç†æœåŠ¡å™¨ç”¨äºæœåŠ¡é€šè¿‡è‹±ç‰¹å°”Â® å‘è¡Œç‰ˆ OpenVINOâ„¢ å·¥å…·å¥—ä»¶ä¼˜åŒ–çš„æ¨¡å‹ã€‚

### [OpenVINOâ„¢ å®‰å…¨é™„åŠ ç»„ä»¶](https://github.com/openvinotoolkit/security_addon)
æ”¯æŒé‡‡ç”¨åŸºäºå†…æ ¸çš„è™šæ‹Ÿæœº (KVM) å’Œ Docker* å®¹å™¨è¿›è¡Œå®‰å…¨å°è£…å’Œçµæ´»éƒ¨ç½²ã€‚ä¸ OpenVINO æ¨¡å‹æœåŠ¡å™¨å…¼å®¹ã€‚

### [è®­ç»ƒæ‰©å±•](https://github.com/openvinotoolkit/training_extensions)
è®¿é—®å¯è®­ç»ƒçš„æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œä½¿ç”¨è‡ªå®šä¹‰æ•°æ®è¿›è¡Œè®­ç»ƒã€‚

## å¼€å‘æ–‡æ¡£
* [è‹±ç‰¹å°”Â® å‘è¡Œç‰ˆ OpenVINOâ„¢ å·¥å…·å¥—ä»¶](https://www.intel.cn/content/www/cn/zh/developer/tools/openvino-toolkit/overview.html)
* [Get Started](https://docs.openvino.ai/nightly/get_started.html)
* [Get Started with Sample and Demo Applications](https://docs.openvino.ai/latest/openvino_docs_get_started_get_started_demos.html)
* [Open Model Zoo Demos](https://docs.openvino.ai/latest/omz_demos.html)
* [OpenVINO Notebooks Documentation](https://docs.openvino.ai/latest/notebooks/notebooks.html)
* [OpenVINO è¯¾ç¨‹](https://bizwebcast.intel.cn/dev/curriculum.html)
* [è‹±ç‰¹å°”Â® è¾¹ç¼˜äººå·¥æ™ºèƒ½å¼€å‘è€…è®¤è¯](https://www.intel.cn/content/www/cn/zh/developer/tools/devcloud/edge/learn/certification.html)

## å‚è€ƒèµ„æ–™
* [OpenVINO](https://github.com/openvinotoolkit/openvino)
* [Open Model Zoo](https://github.com/openvinotoolkit/open_model_zoo)
* [Install OpenVINO Overview](https://docs.openvino.ai/latest/openvino_docs_install_guides_overview.html)
* [pypip openvino-runtime](https://pypi.org/project/openvino/)
* [pypip openvino-dev](https://pypi.org/project/openvino-dev/)
* [netron](https://github.com/lutzroeder/netron)
* [netron](https://pypi.org/project/netron/)
* [Visualize Neural Network Model using Netron](https://lindevs.com/visualize-neural-network-model-using-netron/)
