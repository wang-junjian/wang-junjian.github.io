---
layout: single
title:  "SenseVoice"
date:   2025-11-20 08:00:00 +0800
categories: SenseVoice ASR
tags: [SenseVoice, ASR]
---

[SenseVoice](https://github.com/FunAudioLLM/SenseVoice/blob/main/README_zh.md) æ˜¯å…·æœ‰éŸ³é¢‘ç†è§£èƒ½åŠ›çš„éŸ³é¢‘åŸºç¡€æ¨¡å‹ï¼ŒåŒ…æ‹¬è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰ã€è¯­ç§è¯†åˆ«ï¼ˆLIDï¼‰ã€è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼ˆSERï¼‰å’Œå£°å­¦äº‹ä»¶åˆ†ç±»ï¼ˆAECï¼‰æˆ–å£°å­¦äº‹ä»¶æ£€æµ‹ï¼ˆAEDï¼‰ã€‚

<!--more-->

## SenseVoice

### æ ¸å¿ƒåŠŸèƒ½ ğŸ¯

**SenseVoice** ä¸“æ³¨äºé«˜ç²¾åº¦å¤šè¯­è¨€è¯­éŸ³è¯†åˆ«ã€æƒ…æ„Ÿè¾¨è¯†å’ŒéŸ³é¢‘äº‹ä»¶æ£€æµ‹

- **å¤šè¯­è¨€è¯†åˆ«ï¼š** é‡‡ç”¨è¶…è¿‡ 40 ä¸‡å°æ—¶æ•°æ®è®­ç»ƒï¼Œæ”¯æŒè¶…è¿‡ 50 ç§è¯­è¨€ï¼Œè¯†åˆ«æ•ˆæœä¸Šä¼˜äº Whisper æ¨¡å‹ã€‚
- **å¯Œæ–‡æœ¬è¯†åˆ«ï¼š**
  - å…·å¤‡ä¼˜ç§€çš„æƒ…æ„Ÿè¯†åˆ«ï¼Œèƒ½å¤Ÿåœ¨æµ‹è¯•æ•°æ®ä¸Šè¾¾åˆ°å’Œè¶…è¿‡ç›®å‰æœ€ä½³æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹çš„æ•ˆæœã€‚
  - æ”¯æŒå£°éŸ³äº‹ä»¶æ£€æµ‹èƒ½åŠ›ï¼Œæ”¯æŒéŸ³ä¹ã€æŒå£°ã€ç¬‘å£°ã€å“­å£°ã€å’³å—½ã€å–·åšç­‰å¤šç§å¸¸è§äººæœºäº¤äº’äº‹ä»¶è¿›è¡Œæ£€æµ‹ã€‚
- **é«˜æ•ˆæ¨ç†ï¼š** SenseVoice-Small æ¨¡å‹é‡‡ç”¨éè‡ªå›å½’ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œæ¨ç†å»¶è¿Ÿæä½ï¼Œ10s éŸ³é¢‘æ¨ç†ä»…è€—æ—¶ 70msï¼Œ15 å€ä¼˜äº Whisper-Largeã€‚
- **å¾®è°ƒå®šåˆ¶ï¼š** å…·å¤‡ä¾¿æ·çš„å¾®è°ƒè„šæœ¬ä¸ç­–ç•¥ï¼Œæ–¹ä¾¿ç”¨æˆ·æ ¹æ®ä¸šåŠ¡åœºæ™¯ä¿®å¤é•¿å°¾æ ·æœ¬é—®é¢˜ã€‚
- **æœåŠ¡éƒ¨ç½²ï¼š** å…·æœ‰å®Œæ•´çš„æœåŠ¡éƒ¨ç½²é“¾è·¯ï¼Œæ”¯æŒå¤šå¹¶å‘è¯·æ±‚ï¼Œæ”¯æŒå®¢æˆ·ç«¯è¯­è¨€æœ‰ï¼Œpythonã€c++ã€htmlã€java ä¸ c# ç­‰ã€‚

### æ¶æ„å›¾

![](/images/2025/SenseVoice/sensevoice-arch.jpeg)

- è¯­éŸ³è¯†åˆ«ï¼ˆASRï¼‰
- è¯­è¨€è¯†åˆ«ï¼ˆLIDï¼‰
- è¯­éŸ³æƒ…æ„Ÿè¯†åˆ«ï¼ˆSERï¼‰
- éŸ³é¢‘äº‹ä»¶æ£€æµ‹ï¼ˆAEDï¼Œæ¯”å¦‚ç¬‘å£°ã€æŒå£°ã€èƒŒæ™¯éŸ³ä¹ã€å’³å—½ç­‰ï¼‰
- é€†æ–‡æœ¬å½’ä¸€åŒ–ï¼ˆITNï¼‰

## å®‰è£…

### å…‹éš†ä»£ç åº“

```bash
git clone https://github.com/FunAudioLLM/SenseVoice
cd SenseVoice
```

### åˆ›å»ºå¹¶æ¿€æ´» Conda ç¯å¢ƒ

```bash
# âŒ conda create -n funasr python=3.13.0 -y
conda create -n funasr python=3.10.9 -y
conda activate funasr
```

| Python ç‰ˆæœ¬ | PyTorch æ”¯æŒ |
| --------- | ---------- |
| 3.10      | æ”¯æŒ         |
| 3.11      | æ”¯æŒ         |
| 3.12      | åˆšå¼€å§‹æ”¯æŒï¼ˆéƒ¨åˆ†ï¼‰  |
| **3.13**  | âŒ ç›®å‰ä¸æ”¯æŒ    |

### å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
pip install "fastapi[standard]" -i https://pypi.tuna.tsinghua.edu.cn/simple
```


## è¿è¡Œ
### è¿è¡Œ API æœåŠ¡

```bash
# macOS Silicon
export SENSEVOICE_DEVICE=mps
fastapi run --port 50000
```

![](/images/2025/SenseVoice/sensevoice-fastapi.png)

### è¿è¡Œ WebUI

```bash
python webui.py
```
```bash
You are using the latest version of funasr-1.2.7
Downloading Model from https://www.modelscope.cn to directory: /Users/junjian/.cache/modelscope/hub/models/iic/SenseVoiceSmall
Loading remote code successfully: model
Downloading Model from https://www.modelscope.cn to directory: /Users/junjian/.cache/modelscope/hub/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch
* Running on local URL:  http://127.0.0.1:7860
* To create a public link, set `share=True` in `launch()`.
audio_fs: 44100
language: zh, merge_vad: True
rtf_avg: 0.009: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 20.79it/s]
rtf_avg: 0.125: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.45it/s]
rtf_avg: 0.125, time_speech:  5.520, time_escape: 0.692: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.44it/s]
[{'key': 'rand_key_W4Acq9GFz6Y1t', 'text': '<|zh|><|NEUTRAL|><|Speech|><|withitn|>å—¨ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ'}]
å—¨ä½ å¥½ï¼Œä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ
```

![](/images/2025/SenseVoice/sensevoice-webui.jpeg)


## æ¨ç†

| å¼•æ“ | è®¾å¤‡ | ç”¨æ—¶ (s) | éŸ³é¢‘æ—¶é•¿ (s) |
| --- | --- | ---: | ---: |
| funasr ğŸš€ | mps | 0.47 | 72 |
|        | cpu | 1.7 | 72 |
| directly | mps | 0.58 | 72 |
|        | cpu | 1.82 | 72 |
| onnx | cpu | 4 | 72 |
| onnx(quantize) | cpu | 2.5 | 72 |

> `â„¹` å®‰è£… onnxruntime-silicon æ²¡æœ‰æˆåŠŸä½¿ç”¨ï¼Œæ‰€ä»¥æ²¡æœ‰æµ‹è¯• mpsã€‚

### funasr æ¨ç†

```py
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "iic/SenseVoiceSmall"

model = AutoModel(
    model=model_dir,
    trust_remote_code=True,
    remote_code="./model.py",  
    device="mps",
)

# ----------- æµ‹è¯• E2E æ¨ç†æ—¶é—´ -----------

wav = "wav/all2.wav"
# è®¡ç®—éŸ³é¢‘æ—¶é•¿
import soundfile as sf
audio, sr = sf.read(wav)
audio_dur = len(audio) / sr

import time
t0 = time.perf_counter()

res = model.generate(
    input=wav,
    cache={},
    language="auto",  # "zh", "en", "yue", "ja", "ko", "nospeech"
    use_itn=True,
    batch_size_s=60,
)

t1 = time.perf_counter()
e2e_time = t1 - t0
rtf = e2e_time / audio_dur

print("----- ASR Benchmark -----")
print(f"Audio duration: {audio_dur:.3f} s")
print(f"ğŸš€ğŸš€ğŸš€ E2E inference time: {e2e_time:.3f} s")
print(f"RTF: {rtf:.4f}")

text = rich_transcription_postprocess(res[0]["text"])
print(text)
```

### ç›´æ¥æ¨ç†

```py
from model import SenseVoiceSmall
from funasr.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "iic/SenseVoiceSmall"
m, kwargs = SenseVoiceSmall.from_pretrained(model=model_dir, device="mps")
m.eval()

# ----------- æµ‹è¯• E2E æ¨ç†æ—¶é—´ -----------

wav = "wav/all2.wav"
# è®¡ç®—éŸ³é¢‘æ—¶é•¿
import soundfile as sf
audio, sr = sf.read(wav)
audio_dur = len(audio) / sr

import time
t0 = time.perf_counter()

res = m.inference(
    data_in=wav,
    language="auto", # "zh", "en", "yue", "ja", "ko", "nospeech"
    use_itn=False,
    ban_emo_unk=False,
    **kwargs,
)

t1 = time.perf_counter()
e2e_time = t1 - t0
rtf = e2e_time / audio_dur

print("----- ASR Benchmark -----")
print(f"Audio duration: {audio_dur:.3f} s")
print(f"ğŸš€ğŸš€ğŸš€ E2E inference time: {e2e_time:.3f} s")
print(f"RTF: {rtf:.4f}")

text = rich_transcription_postprocess(res [0][0]["text"])
print(text)
```

### ONNX æ¨ç†

```py
from pathlib import Path
from funasr_onnx import SenseVoiceSmall
from funasr_onnx.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "iic/SenseVoiceSmall"
model = SenseVoiceSmall(model_dir, batch_size=10, quantize=True, device="cpu")

# ----------- æµ‹è¯• E2E æ¨ç†æ—¶é—´ -----------

wav = "wav/all2.wav"
# è®¡ç®—éŸ³é¢‘æ—¶é•¿
import soundfile as sf
audio, sr = sf.read(wav)
audio_dur = len(audio) / sr

import time
t0 = time.perf_counter()

res = model(wav, language="auto", use_itn=True)

t1 = time.perf_counter()
e2e_time = t1 - t0
rtf = e2e_time / audio_dur

print("----- ASR Benchmark -----")
print(f"Audio duration: {audio_dur:.3f} s")
print(f"ğŸš€ğŸš€ğŸš€ E2E inference time: {e2e_time:.3f} s")
print(f"RTF: {rtf:.4f}")

print([rich_transcription_postprocess(i) for i in res])
```

### Libtorch æ¨ç†

> âŒ ä½¿ç”¨ `pip install funasr_torch` å®‰è£…åï¼Œå¹¶æ²¡æœ‰çœŸæ­£å®‰è£…æˆåŠŸï¼Œå¯ä»¥è€ƒè™‘ä½¿ç”¨æºç æ–¹å¼å®‰è£…ã€‚

```py
from pathlib import Path
from funasr_torch import SenseVoiceSmall
from funasr_torch.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "iic/SenseVoiceSmall"
model = SenseVoiceSmall(model_dir, batch_size=10, device="mps")

# ----------- æµ‹è¯• E2E æ¨ç†æ—¶é—´ -----------

wav = "wav/all2.wav"
# è®¡ç®—éŸ³é¢‘æ—¶é•¿
import soundfile as sf
audio, sr = sf.read(wav)
audio_dur = len(audio) / sr

import time
t0 = time.perf_counter()

res = model(wav, language="auto", use_itn=True)

t1 = time.perf_counter()
e2e_time = t1 - t0
rtf = e2e_time / audio_dur

print("----- ASR Benchmark -----")
print(f"Audio duration: {audio_dur:.3f} s")
print(f"ğŸš€ğŸš€ğŸš€ E2E inference time: {e2e_time:.3f} s")
print(f"RTF: {rtf:.4f}")

print([rich_transcription_postprocess(i) for i in res])
```

### æ··åˆ VAD æ¨ç†ï¼ˆç¦»çº¿ï¼‰

```py
from funasr import AutoModel
from funasr.utils.postprocess_utils import rich_transcription_postprocess

model_dir = "/Users/junjian/.cache/modelscope/hub/models/iic/SenseVoiceSmall"
vad_model_dir = "/Users/junjian/.cache/modelscope/hub/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch"

model = AutoModel(
    model=model_dir,
    trust_remote_code=True,
    remote_code="./model.py",
    vad_model=vad_model_dir,
    vad_kwargs={"max_single_segment_time": 30000},
    device="mps",
    disable_update=True
)

res = model.generate(
    input=f"wav/all2.wav",
    cache={},
    language="auto",  # "zh", "en", "yue", "ja", "ko", "nospeech"
    use_itn=True,
    batch_size_s=60,
    merge_vad=True,
    merge_length_s=15,
)

text = rich_transcription_postprocess(res[0]["text"])
print(text)
```


## å‚è€ƒèµ„æ–™
- [SenseVoice-Small](https://www.modelscope.cn/models/iic/SenseVoiceSmall)
