---
layout: post
title:  "Whisper è¯­éŸ³è¯†åˆ«"
date:   2023-05-26 08:00:00 +0800
categories: Whisper
tags: [OpenAI, Pydub]
---

## Whisper
### åŠŸèƒ½
* å°†éŸ³é¢‘è½¬å½•æˆéŸ³é¢‘æ‰€ä½¿ç”¨çš„ä»»ä½•è¯­è¨€ã€‚
* å°†éŸ³é¢‘ç¿»è¯‘å¹¶è½¬å½•æˆè‹±æ–‡ã€‚

æ–‡ä»¶ä¸Šä¼ ç›®å‰é™åˆ¶ä¸º `25 MB`ï¼Œå¹¶ä¸”æ”¯æŒä»¥ä¸‹è¾“å…¥æ–‡ä»¶ç±»å‹ï¼š`mp3`, `mp4`, `mpeg`, `mpga`, `m4a`, `wav`, `webm`.

### è¯­éŸ³å†…å®¹
Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ï¼Œå¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚

å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ï¼Œå¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·ï¼Œè€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚

å¥¹æŒ‡å‡ºï¼Œäººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡ï¼Œå› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒï¼Œä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼ï¼Œå°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚

## OpenAI Whisper
### å®‰è£… OpenAI
```bash
!pip install -U openai
```

### æµ‹è¯•
#### è¯­éŸ³è¯†åˆ«
```py
import openai
audio_file= open("data/audios/test.m4a", "rb")
transcript = openai.Audio.transcribe("whisper-1", audio_file)
print(transcript["text"])
```

Miramuratiæ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢– ä»–çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ ä»–è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„ å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…· è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…· ä»–æŒ‡å‡ºäººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡ å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒ ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼ å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­

ğŸ‘ **å¯ä»¥çœ‹åˆ°è½¬æ¢çš„éå¸¸å‡†ç¡®ï¼Œä½†æ˜¯ç¼ºå°‘äº†æ ‡ç‚¹ç¬¦å·ï¼Œè‹±æ–‡åå­—ä¹Ÿæœ‰ä¸€ç‚¹å°å°çš„é—®é¢˜ã€‚**

#### é€šè¿‡æç¤ºï¼ˆpromptï¼‰æ”¹è¿›è¯­éŸ³è¯†åˆ«
```py
import openai
audio_file= open("data/audios/test.m4a", "rb")
transcript = openai.Audio.transcribe("whisper-1", audio_file,
                                     prompt="æ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚")
print(transcript["text"])
```

Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„, å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·, è€Œä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ å¥¹æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡, å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒ, ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚ äººå·¥æ™ºèƒ½æŠ€æœ¯çš„åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼, å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚

**è¿™é‡Œè¿˜æœ‰ä¸ªå°é—®é¢˜ï¼Œæ¯ä¸ªæ ‡ç‚¹ç¬¦å·åé¢éƒ½æœ‰ä¸€ä¸ªç©ºæ ¼ã€‚è¿™ä¸ªå°é—®é¢˜ä¸å¥½è§£å†³å•Šã€‚**

### æ›´é•¿çš„è¾“å…¥

é»˜è®¤æƒ…å†µä¸‹ï¼ŒWhisper API ä»…æ”¯æŒå°äº 25 MB çš„æ–‡ä»¶ã€‚å¦‚æœæ‚¨æœ‰æ¯”è¿™æ›´é•¿çš„éŸ³é¢‘æ–‡ä»¶ï¼Œåˆ™éœ€è¦å°†å…¶åˆ†æˆ 25 MB æˆ–æ›´å°çš„å—æˆ–ä½¿ç”¨å‹ç¼©éŸ³é¢‘æ ¼å¼ã€‚ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨é¿å…åœ¨å¥å­ä¸­é—´æ‰“æ–­éŸ³é¢‘ï¼Œå› ä¸ºè¿™å¯èƒ½ä¼šå¯¼è‡´æŸäº›ä¸Šä¸‹æ–‡ä¸¢å¤±ã€‚

ä¸€ç§å¤„ç†æ–¹æ³•æ˜¯ä½¿ç”¨ [PyDub](https://github.com/jiaaro/pydub) å¼€æº Python åŒ…æ¥åˆ†å‰²éŸ³é¢‘ï¼š

#### å®‰è£… Pydub
```
pip install pydub
```

#### æ‰‹åŠ¨åˆ†å‰²æµ‹è¯•
```py
from pydub import AudioSegment

audio = AudioSegment.from_file("data/audios/test.m4a")

# Pydub handles time in milliseconds
thirty_seconds = 30 * 1000

first_30_seconds = audio[:thirty_seconds]
first_30_seconds.export("tmp/test1.mp3", format="mp3")

last_seconds = audio[thirty_seconds:]
last_seconds.export("tmp/test2.mp3", format="mp3")

import openai

for file in ["tmp/test1.mp3", "tmp/test2.mp3"]:
    audio_file= open(file, "rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file,
                                        prompt="å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚")
    print(transcript["text"])
```

Mira Murati æ˜¯ä¸€ä½å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯å……æ»¡çƒ­æƒ…çš„ç§‘æŠ€é¢†è¢–ã€‚ å¥¹çš„ç†å¿µå’Œå½±å“å¯¹äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•å’Œåº”ç”¨äº§ç”Ÿäº†æ·±è¿œçš„å½±å“ã€‚ å¥¹è®¤ä¸ºäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä»¥äººä¸ºæœ¬çš„, å¼ºè°ƒäººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥æ˜¯ä¸€ç§èƒ½å¤ŸæœåŠ¡äºäººç±»çš„å·¥å…·, è€Œä¸æ˜¯ä¸€ç§å·¥å…·ã€‚

äººå·¥æ™ºèƒ½æŠ€æœ¯ä¸æ˜¯å–ä»£äººç±»çš„å·¥å…·ã€‚ ä»–æŒ‡å‡º,äººå·¥æ™ºèƒ½æŠ€æœ¯çš„æœ€ç»ˆç›®çš„æ˜¯ä¸ºäººç±»æœåŠ¡, å› æ­¤äººå·¥æ™ºèƒ½æŠ€æœ¯åº”è¯¥ä»¥äººç±»çš„åˆ©ç›Šå’Œéœ€æ±‚ä¸ºä¸­å¿ƒ, ä»¥è§£å†³äººç±»é¢ä¸´çš„å®é™…é—®é¢˜ã€‚ äººå·¥æ™ºèƒ½æŠ€æœ¯åº”ç”¨éœ€è¦æ·±å…¥äº†è§£äººç±»ç¤¾ä¼šçš„éœ€è¦å’Œä»·å€¼, å°†å…¶åº”ç”¨åˆ°çœŸæ­£æœ‰æ„ä¹‰çš„é¢†åŸŸä¸­ã€‚

**å¯ä»¥çœ‹å‡ºæš´åŠ›åˆ†å‰²ï¼Œå¯¹äºåˆ†å‰²çš„å¥å­æ˜¯æœ‰å½±å“çš„ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹çœ‹å¦‚ä½•åœ¨æ ‡ç‚¹ç¬¦å·å¤„è¿›è¡Œåˆ†å‰²ã€‚**

#### è‡ªåŠ¨åˆ†å‰²æµ‹è¯•
```py
import os
import shutil
from pydub import AudioSegment, silence

def audio_transcribe(file, prompt):
    audio_file= open(file, "rb")
    transcript = openai.Audio.transcribe("whisper-1", audio_file, prompt=prompt)
    return transcript["text"]

def detect_first_silent(audio, start_time, time_step=10, min_silence_len=500, silence_thresh=-40):
    slice_audio = audio[start_time:start_time+time_step*1000]
    silents = silence.detect_silence(slice_audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)
    if len(silents):
        return (start_time+silents[0][0], start_time+silents[0][1])
    return (start_time, start_time)

def split_audio_file(filename, interval_seconds, save_dir):
    audio_files = []

    name = os.path.splitext(os.path.basename(filename))[0]
    audio = AudioSegment.from_file(filename)
    audio_len = len(audio)
    index = 1
    start_time = 0
    while start_time < audio_len:
        end_time = start_time + interval_seconds*1000
        if end_time > audio_len:
            end_time = audio_len

        silent_start_time, slient_end_time = detect_first_silent(audio, end_time)
        end_time = silent_start_time
        
        audio_file = os.path.join(save_dir, f"{name}{index}.mp3")
        audio[start_time:end_time].export(audio_file, format="mp3")
        audio_files.append(audio_file)

        start_time = slient_end_time
        index += 1

    return audio_files

def transcribe_audio_files(audio_files, prompt, prompt_len=100):
    text_files = []
    for audio_file in audio_files:
        print("ğŸ˜", prompt)
        text = audio_transcribe(audio_file, prompt)
        print(text)

        text_file = os.path.splitext(audio_file)[0]+".txt"
        with open(text_file, "a") as f:
            f.write(text)
        text_files.append(text_file)

        prompt = text[-prompt_len:] if len(text) > prompt_len else text

    return text_files

def merge_text_files(text_files, output_file):
    with open(output_file, "a") as f:
        for text_file in text_files:
            with open(text_file, "r") as f_text:
                f.write(f_text.read())

save_dir = "tmp"

shutil.rmtree(save_dir)
os.mkdir(save_dir)

filename = "data/audios/test.m4a"
audio_files = split_audio_file(filename, 20, save_dir)

prompt = "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚"
text_files = transcribe_audio_files(audio_files, prompt)

text_file = os.path.join(save_dir, "test.txt")
merge_text_files(text_files, text_file)
```


## æœ¬åœ° Whisper
### å®‰è£… Whisper
```bash
pip install -U openai-whisper
```

### æœ¬åœ°è¯­éŸ³è¯†åˆ«
```py
import os
import shutil
import whisper
from pydub import AudioSegment, silence


def audio_transcribe_with_openai(whisper_service, file, prompt):
    audio_file= open(file, "rb")
    transcript = whisper_service.transcribe("whisper-1", audio_file, prompt=prompt)
    return transcript["text"]

def audio_transcribe_with_local(whisper_service, file, prompt):
    transcript = whisper_service.transcribe(file, initial_prompt=prompt)
    return transcript["text"]

def detect_first_silent(audio, start_time, time_step=10, min_silence_len=500, silence_thresh=-40):
    slice_audio = audio[start_time:start_time+time_step*1000]
    silents = silence.detect_silence(slice_audio, min_silence_len=min_silence_len, silence_thresh=silence_thresh)
    if len(silents):
        return (start_time+silents[0][0], start_time+silents[0][1])
    return (start_time, start_time)

def split_audio_file(filename, interval_seconds, save_dir):
    audio_files = []

    name = os.path.splitext(os.path.basename(filename))[0]
    audio = AudioSegment.from_file(filename)
    audio_len = len(audio)
    index = 1
    start_time = 0
    while start_time < audio_len:
        end_time = start_time + interval_seconds*1000
        if end_time > audio_len:
            end_time = audio_len

        silent_start_time, slient_end_time = detect_first_silent(audio, end_time)
        end_time = silent_start_time
        
        audio_file = os.path.join(save_dir, f"{name}{index}.mp3")
        audio[start_time:end_time].export(audio_file, format="mp3")
        audio_files.append(audio_file)

        start_time = slient_end_time
        index += 1

    return audio_files

def transcribe_audio_files(audio_transcribe, whisper_service, audio_files, prompt, prompt_len=100):
    text_files = []
    for audio_file in audio_files:
        print("ğŸ˜", prompt)
        text = audio_transcribe(whisper_service, audio_file, prompt)
        print(text)

        text_file = os.path.splitext(audio_file)[0]+".txt"
        with open(text_file, "a") as f:
            f.write(text)
        text_files.append(text_file)

        prompt = text[-prompt_len:] if len(text) > prompt_len else text

    return text_files

def merge_text_files(text_files, output_file):
    with open(output_file, "a") as f:
        for text_file in text_files:
            with open(text_file, "r") as f_text:
                f.write(f_text.read())

save_dir = "tmp"

shutil.rmtree(save_dir)
os.mkdir(save_dir)

filename = "data/audios/test.m4a"
audio_files = split_audio_file(filename, 20, save_dir)

model = whisper.load_model("large")
whisper_handlers = [(audio_transcribe_with_local, model),
                    (audio_transcribe_with_openai, openai.Audio)]

prompt = "å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶å¬ Mira Murati çš„ç†å¿µä¸å½±å“çš„è®²åº§ã€‚"
text_files = transcribe_audio_files(*whisper_handlers[0], audio_files, prompt)

text_file = os.path.join(save_dir, "test.txt")
merge_text_files(text_files, text_file)
```


## å‚è€ƒèµ„æ–™
* [Whisper](https://github.com/openai/whisper)
* [OpenAI Python Library](https://github.com/openai/openai-python)
* [Pydub](https://github.com/jiaaro/pydub)
* [AutoCut: é€šè¿‡å­—å¹•æ¥å‰ªåˆ‡è§†é¢‘](https://github.com/mli/autocut)
