---
layout: post
title:  "AI å¤§æ¨¡å‹"
date:   2024-01-01 08:00:00 +0800
categories: LLM Leaderboard
tags: [LLM, CodeLLM, EmbeddingLLM, Leaderboard]
---

## ğŸ”¶ å¤§æ¨¡å‹
### SLM
- [microsoft/phi-2](https://huggingface.co/microsoft/phi-2)
- [Qwen/Qwen-1_8B-Chat](https://huggingface.co/Qwen/Qwen-1_8B-Chat)
- [TinyLlama/TinyLlama-1.1B-Chat-v1.0](https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0)

### LLM
- [THUDM/chatglm3-6b](https://huggingface.co/THUDM/chatglm3-6b)
- [Qwen/Qwen-7B-Chat](https://huggingface.co/Qwen/Qwen-7B-Chat)
- [deepseek-ai/deepseek-llm-7b-chat](https://huggingface.co/deepseek-ai/deepseek-llm-7b-chat)
- [baichuan-inc/Baichuan2-7B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-7B-Chat)
- [baichuan-inc/Baichuan2-13B-Chat](https://huggingface.co/baichuan-inc/Baichuan2-13B-Chat)
- [mistralai/Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)
- [01-ai/Yi-6B-Chat](https://huggingface.co/01-ai/Yi-6B-Chat)
- [lmsys/vicuna-7b-v1.5](https://huggingface.co/lmsys/vicuna-7b-v1.5)

#### å¯¹è¯ LLM æ’è¡Œæ¦œ ([Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard))

| Model | Average | ARC | HellaSwag | MMLU | TruthfulQA | Winogrande | GSM8K |
| --- | --- | --- | --- | --- | --- | --- | --- |
| mistralai/Mistral-7B-Instruct-v0.2 | 65.71 | 63.14 | 84.88 | 60.78 | 68.26 | 77.19 | 40.03 |
| 01-ai/Yi-34B-Chat     | 65.32 | 65.44 | 84.16 | 74.9  | 55.37 | 80.11 | 31.92 |
| Qwen/Qwen1.5-14B-Chat | 62.37 | 58.79 | 82.33 | 68.52 | 60.38 | 73.32 | 30.86 |
| 01-ai/Yi-6B-200K      | 56.76 | 53.75 | 75.57 | 64.65 | 41.56 | 73.64 | 31.39 |
| Qwen/Qwen1.5-7B-Chat  | 55.15 | 55.89 | 78.56 | 61.65 | 53.54 | 67.72 | 13.57 |
| 01-ai/Yi-6B           | 54.08 | 55.55 | 76.57 | 64.11 | 41.96 | 74.19 | 12.13 |
| deepseek-ai/deepseek-llm-7b-chat | 59.38 | 55.8  | 79.38 | 51.75 | 47.98 | 74.82 | 46.55 |
| internlm/internlm-20b-chat | 55.53 | 55.38 | 78.58 | 58.53 | 43.22 | 78.77 | 18.73 |
| deepseek-ai/deepseek-coder-7b-instruct-v1.5 | 50.89 | 48.55 | 72.35 | 50.45 | 46.73 | 66.85 | 20.39 |

- **Average:** è¿™ä¸ªæŒ‡æ ‡å¯èƒ½æŒ‡çš„æ˜¯æ¨¡å‹åœ¨å¤šä¸ªä»»åŠ¡ä¸Šçš„å¹³å‡è¡¨ç°ã€‚åœ¨è¯„ä¼°LLMæ—¶ï¼Œé€šå¸¸ä¼šåœ¨å¤šä¸ªä¸åŒçš„ä»»åŠ¡æˆ–æ•°æ®é›†ä¸Šæµ‹è¯•æ¨¡å‹ï¼Œç„¶åè®¡ç®—è¿™äº›ä»»åŠ¡çš„å¹³å‡å¾—åˆ†ï¼Œä»¥å¾—åˆ°ä¸€ä¸ªç»¼åˆçš„æ€§èƒ½æŒ‡æ ‡ã€‚

- **ARC (AI2 Reasoning Challenge):** ARCæ˜¯ä¸€ä¸ªç”¨äºè¯„ä¼°æ¨¡å‹åœ¨å¤æ‚æ¨ç†ä»»åŠ¡ä¸Šçš„è¡¨ç°çš„åŸºå‡†ã€‚å®ƒåŒ…å«äº†å¤šç§ç±»å‹çš„é€»è¾‘å’Œæ•°å­¦é—®é¢˜ï¼Œæ—¨åœ¨æµ‹è¯•æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ï¼ŒåŒ…æ‹¬æ•°é‡æ¨ç†ã€ç‰©ç†æ¨ç†å’ŒæŠ½è±¡æ¨ç†ç­‰ã€‚

- **HellaSwag:** HellaSwagæ˜¯ä¸€ä¸ªå¤šæ­¥æ¨ç†ä»»åŠ¡ï¼Œè¦æ±‚æ¨¡å‹é¢„æµ‹ç»™å®šæƒ…å¢ƒçš„åç»­äº‹ä»¶ã€‚è¿™ä¸ªä»»åŠ¡æµ‹è¯•äº†æ¨¡å‹å¯¹å¸¸è¯†ã€å› æœå…³ç³»å’Œäº‹ä»¶è¿è´¯æ€§çš„ç†è§£èƒ½åŠ›ã€‚

- **MMLU (Massive Multitask Language Understanding):** MMLUæ˜¯ä¸€ä¸ªå¤§è§„æ¨¡çš„å¤šä»»åŠ¡è¯­è¨€ç†è§£åŸºå‡†ï¼Œå®ƒåŒ…å«äº†å¤šç§ç±»å‹çš„è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ï¼Œå¦‚æƒ…æ„Ÿåˆ†æã€æ–‡æœ¬åˆ†ç±»ã€é—®ç­”ç­‰ã€‚è¿™ä¸ªæŒ‡æ ‡æ—¨åœ¨è¯„ä¼°æ¨¡å‹åœ¨å¤„ç†å¤šæ ·åŒ–è¯­è¨€ä»»åŠ¡æ—¶çš„æ³›åŒ–èƒ½åŠ›ã€‚

- **TruthfulQA:** TruthfulQAæ˜¯ä¸€ä¸ªè¯„ä¼°æ¨¡å‹åœ¨å¸¸è¯†é—®ç­”ä»»åŠ¡ä¸Šçš„è¡¨ç°çš„åŸºå‡†ã€‚å®ƒç‰¹åˆ«å…³æ³¨æ¨¡å‹åœ¨å›ç­”éœ€è¦å¤–éƒ¨çŸ¥è¯†çš„é—®é¢˜æ—¶çš„å‡†ç¡®æ€§å’Œå¯é æ€§ï¼Œä»¥åŠæ¨¡å‹åœ¨é¢å¯¹é”™è¯¯ä¿¡æ¯æ—¶çš„æŠ—å¹²æ‰°èƒ½åŠ›ã€‚

- **Winogrande:** Winograndeæ˜¯ä¸€ä¸ªé˜…è¯»ç†è§£ä»»åŠ¡ï¼Œå®ƒåŒ…å«äº†éœ€è¦æ¨¡å‹ç†è§£æ–‡æœ¬ä¸­çš„æŒ‡ä»£æ¶ˆæ­§å’Œå¸¸è¯†æ¨ç†çš„é—®é¢˜ã€‚è¿™ä¸ªä»»åŠ¡æ—¨åœ¨æµ‹è¯•æ¨¡å‹åœ¨ç†è§£å¤æ‚æ–‡æœ¬å’Œè¿›è¡Œé€»è¾‘æ¨ç†æ–¹é¢çš„èƒ½åŠ›ã€‚

- **GSM8K:** GSM8Kæ˜¯ä¸€ä¸ªæ•°å­¦é—®é¢˜è§£ç­”ä»»åŠ¡ï¼Œå®ƒåŒ…å«äº†å¤šç§ç±»å‹çš„æ•°å­¦é—®é¢˜ï¼Œè¦æ±‚æ¨¡å‹å±•ç¤ºå…¶æ•°å­¦æ¨ç†å’Œè®¡ç®—èƒ½åŠ›ã€‚è¿™ä¸ªæŒ‡æ ‡è¯„ä¼°æ¨¡å‹åœ¨å¤„ç†æ•°å­¦æ¦‚å¿µå’Œæ‰§è¡Œæ•°å­¦è¿ç®—æ–¹é¢çš„è¡¨ç°ã€‚

æ€»ç»“ï¼š

1. Qwen/Qwen1.5-14B-Chat
è¿™ä¸ªæ¨¡å‹åœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šè¡¨ç°å‡è¡¡ï¼Œç‰¹åˆ«æ˜¯åœ¨ ARC å’Œ HellaSwag ä¸Šå¾—åˆ†è¾ƒé«˜ï¼Œè¿™è¡¨æ˜å®ƒåœ¨æ¨ç†å’Œå¸¸è¯†ç†è§£æ–¹é¢å…·æœ‰è¾ƒå¼ºçš„èƒ½åŠ›ã€‚éå¸¸é€‚åˆæ—¥å¸¸é—®ç­”åœºæ™¯ã€‚ä»å¹³è¡¡æˆæœ¬å’Œæ•ˆæœæ¥çœ‹ä¹Ÿéå¸¸æœ‰ç«äº‰åŠ›ã€‚

2. mistralai/Mistral-7B-Instruct-v0.2
è¿™ä¸ªæ¨¡å‹åœ¨å¹³å‡å¾—åˆ†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†åœ¨ TruthfulQA å’Œ Winogrande ç­‰ä»»åŠ¡ä¸Šçš„å¾—åˆ†ç›¸å¯¹è¾ƒä½ã€‚è¿™å¯èƒ½æ„å‘³ç€å®ƒåœ¨å¤„ç†éœ€è¦å¤–éƒ¨çŸ¥è¯†å’Œå¤æ‚æ¨ç†çš„ä»»åŠ¡æ—¶å¯èƒ½å­˜åœ¨å±€é™æ€§ã€‚éœ€è¦è¿›ä¸€æ­¥éªŒè¯å…¶ä¸­æ–‡èƒ½åŠ›ã€‚

3. deepseek-ai/deepseek-coder-7b-instruct-v1.5
è¿™ä¸ªæ¨¡å‹åœ¨ä¸­æ–‡å’Œä»£ç ç»¼åˆèƒ½åŠ›ä¸Šè¡¨ç°ä¼˜ç§€ã€‚éå¸¸é€‚åˆæŠ€æœ¯æˆ–ç ”å‘ç›¸å…³çš„é—®ç­”åœºæ™¯ã€‚

4. åœ¨æœ¬è¯„ä¼°ä¸­ï¼Œé‡ç‚¹å…³æ³¨äº†å…·æœ‰6Bè‡³34Bå‚æ•°é‡çš„æ¨¡å‹ã€‚

5. ä¸Šè¿°ç­›é€‰å‡ºçš„å¤§æ¨¡å‹éœ€åœ¨æˆ‘ä»¬çš„ç‰¹å®šåº”ç”¨åœºæ™¯ä¸­è¿›è¡Œæ·±å…¥éªŒè¯ï¼Œä»¥ç¡®è®¤å…¶é€‚åº”æ€§å’Œå¯é æ€§ã€‚

#### å¯¹è¯ LLM æ’è¡Œæ¦œ ([OpenCompass 2.0 å¸å—å¤§æ¨¡å‹è¯„æµ‹æ¦œå•](https://rank.opencompass.org.cn/leaderboard-llm-v2))
	
| æ¨¡å‹ | å‡åˆ† | è¯­è¨€ | çŸ¥è¯† | æ¨ç† | æ•°å­¦ | ä»£ç  | æ™ºèƒ½ä½“ |
| --- | --- | --- | --- | --- | --- | --- | --- |
| Qwen1.5-14B-Chat | 50.3 | 57 | 58.4 | 38.6 | 42.9 | 41.5 | 63.2 |
| InternLM2-Chat-7B | 45 | 51.2 | 48.6 | 34 | 33.8 | 47.8 | 54.7 |
| Yi-34B-Chat | 47.1 | 51.8 | 69.2 | 37.6 | 35.8 | 33.9 | 54.2 |
| Qwen1.5-7B-Chat | 38.9 | 45.7 | 51.2 | 22.9 | 30.6 | 34.5 | 48.4 |
| ChatGLM3-6B-32K | 35.2 | 39.4 | 46.1 | 18 | 25.3 | 39.8 | 42.7 |
| Yi-6B-Chat | 31.9 | 39.2 | 58.1 | 17.9 | 18.4 | 17.7 | 40.2 |
| Mistral-7B-Instruct-v0.2 | 28 | 30.6 | 43 | 17.8 | 17.8 | 19.4 | 39.7 |
| DeepSeek-7B-Chat | 28.8 | 24.8 | 39.4 | 16.2 | 18.5 | 37.4 | 36.6 |


### Code LLM
- [deepseek-ai/deepseek-coder-1.3b-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-1.3b-instruct)
- [deepseek-ai/deepseek-coder-6.7b-instruct](https://huggingface.co/deepseek-ai/deepseek-coder-6.7b-instruct)
- [codellama/CodeLlama-7b-Instruct-hf](https://huggingface.co/codellama/CodeLlama-7b-Instruct-hf)
- [WizardLM/WizardCoder-33B-V1.1](https://huggingface.co/WizardLM/WizardCoder-33B-V1.1)

### Embedding LLM
- [infgrad/stella-base-zh-v2](https://huggingface.co/infgrad/stella-base-zh-v2)
- [sensenova/piccolo-large-zh](https://huggingface.co/sensenova/piccolo-large-zh)
- [BAAI/bge-base-zh-v1.5](https://huggingface.co/BAAI/bge-base-zh-v1.5)
- [moka-ai/m3e-base](https://huggingface.co/moka-ai/m3e-base)

### GGUF
- [TheBloke](https://huggingface.co/TheBloke)

## ğŸ† æ’è¡Œæ¦œ
### LLM
- [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)
- [LMSYS Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
- [OpenCompass 2.0 å¸å—å¤§æ¨¡å‹è¯„æµ‹æ¦œå•](https://rank.opencompass.org.cn/leaderboard-llm-v2)

### Code LLM
- [Coding LLMs Leaderboard](https://leaderboard.tabbyml.com/)

### Embedding LLM
- [Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard)
