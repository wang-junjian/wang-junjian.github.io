---
layout: post
title:  "Text Generation Inference"
date:   2023-12-19 08:00:00 +0800
categories: TGI
tags: [TGI, Inference]
---

- [Text Generation Inference](https://github.com/huggingface/text-generation-inference)

## [TGI ä»‹ç»](https://huggingface.co/docs/text-generation-inference/index)
TGI æ˜¯ä¸€ä¸ªç”¨äºéƒ¨ç½²å’ŒæœåŠ¡å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„å·¥å…·åŒ…ã€‚ TGI ä¸ºæœ€æµè¡Œçš„å¼€æº LLM æä¾›é«˜æ€§èƒ½æ–‡æœ¬ç”Ÿæˆï¼ŒåŒ…æ‹¬ Llamaã€Falconã€StarCoderã€BLOOMã€GPT-NeoX å’Œ T5 ã€‚
- å¼ é‡å¹¶è¡Œæ€§ï¼Œå¯åœ¨å¤šä¸ª GPU ä¸Šè¿›è¡Œæ›´å¿«çš„æ¨ç†
- æ‰¹å¤„ç†è¿ç»­ä¼ å…¥çš„è¯·æ±‚ï¼Œä»¥å¢åŠ æ€»ååé‡
- åœ¨æœ€æµè¡Œçš„æ¶æ„ä¸Šä½¿ç”¨ [Flash Attention][Flash-Attention] å’Œ [Paged Attention][Paged-Attention] ä¼˜åŒ– Transformers ä»£ç è¿›è¡Œæ¨ç†
- ä½¿ç”¨ [bitsandbytes][bitsandbytes] å’Œ [GPT-Q][GPT-Q] è¿›è¡Œé‡åŒ–
- [safetensors][safetensors] æƒé‡åŠ è½½
- ç»™æ¨¡å‹è¾“å‡ºåŠ [æ°´å°ï¼ˆWatermarkï¼‰](https://arxiv.org/abs/2301.10226)
- å¾®è°ƒæ”¯æŒï¼šå®šåˆ¶é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¾®è°ƒæ¨¡å‹æ¥å®ç°æ›´é«˜çš„å‡†ç¡®æ€§å’Œæ€§èƒ½

## ç³»ç»Ÿæ¶æ„
![](/images/2023/TGI.png)

## éƒ¨ç½²æ¨¡å‹ [HuggingFaceH4/zephyr-7b-beta](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)
```shell
model=HuggingFaceH4/zephyr-7b-beta
volume=$PWD/data    # Avoid downloading weights every run
docker run --gpus all --shm-size 1g -p 8080:80 -v $volume:/data \
    ghcr.io/huggingface/text-generation-inference \
    --model-id $model --quantize bitsandbytes --num-shard 1
```

## æµ‹è¯•
```shell
curl -X POST http://localhost:8080/generate \
    -H 'Content-Type: application/json' \
    -d '{
        "inputs": "What is Deep Learning?",
        "parameters": {
            "max_new_tokens": 20
        }
    }'
```

## å‚è€ƒèµ„æ–™
- [LLM Note Day 18 - Hugging Face Text Generation Inference](https://ithelp.ithome.com.tw/articles/10332065)
- [Quick Tour](https://huggingface.co/docs/text-generation-inference/main/en/quicktour)
- [Can not load local model by --model-id](https://github.com/huggingface/text-generation-inference/issues/245)
- [Serving Falcon models with ğŸ¤— Text Generation Inference (TGI)](https://vilsonrodrigues.medium.com/serving-falcon-models-with-text-generation-inference-tgi-5f32005c663b)
- [Text Generation Inference for Foundation Models](https://heidloff.net/article/tgi-kserve/)
