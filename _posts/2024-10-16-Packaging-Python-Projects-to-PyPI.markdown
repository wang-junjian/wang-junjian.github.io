---
layout: post
title:  "æ‰“åŒ… Python å·¥ç¨‹åˆ° PyPIï¼šæ„å»º LLM å‹æµ‹å·¥å…· evalscope-perf"
date:   2024-10-16 10:00:00 +0800
categories: Python PyPI
tags: [Python, PyPI, Packaging, evalscope-perf]
---

![](/images/2024/Python_packages_to_Py_PI.avif)

## åˆ›å»º Python å·¥ç¨‹ [evalscope-perf](https://github.com/wang-junjian/evalscope-perf)

### å·¥ç¨‹çš„ç›®å½•ç»“æ„
```shell
evalscope-perf/
â”œâ”€â”€ evalscope_perf/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pyproject.toml
â””â”€â”€ setup.py
```

### evalscope_perf/__init__.py
æ²¡æœ‰å¯ä»¥ä¸å†™ã€‚

### evalscope_perf/main.py
```python
import subprocess
import re
import typer
import matplotlib.pyplot as plt

from typing import List
from typing_extensions import Annotated


app = typer.Typer()

def run_evalscope(url, model, dataset_path, max_prompt_length, stop, read_timeout, parallel, n):
    cmd = [
        'evalscope', 'perf',
        '--api', 'openai',
        '--url', url,
        '--model', model,
        '--dataset', 'openqa',
        '--dataset-path', dataset_path,
        '--max-prompt-length', str(max_prompt_length),
        '--stop', stop,
        '--read-timeout', str(read_timeout),
        '--parallel', str(parallel),
        '-n', str(n)
    ]
    result = subprocess.run(cmd, stdout=subprocess.PIPE, text=True)

    # å°†è¾“å‡ºä¿å­˜åˆ°æ–‡ä»¶
    dataset_name = dataset_path.split('/')[-1].split('.')[0]
    output_filename = f'{model}_{dataset_name}_p{parallel}.txt'
    with open(output_filename, 'w') as f:
        f.write(result.stdout)

    return result.stdout

def parse_output(output):
    print(output)
    metrics = {}
    patterns = {
        'Average QPS': r'Average QPS:\s+([\d.]+)',
        'Average latency': r'Average latency:\s+([\d.]+)',
        'Throughput': r'Throughput\(average output tokens per second\):\s+([\d.]+)'
    }
    for key, pattern in patterns.items():
        match = re.search(pattern, output)
        if match:
            metrics[key] = float(match.group(1))
    print('ğŸ“Œ Metrics:', metrics)
    return metrics

@app.command()
def main(
    url: str = typer.Argument(..., help="OpenAI URL"),
    model: str = typer.Argument(..., help="æ¨¡å‹åç§°"),
    dataset_path: str = typer.Argument(..., help="æ•°æ®é›†è·¯å¾„"),
    max_prompt_length: int = typer.Option(256, help="æœ€å¤§æç¤ºé•¿åº¦"),
    stop: str = typer.Option("<|im_end|>", help="åœæ­¢æ ‡è®°"),
    read_timeout: int = typer.Option(30, help="è¯»å–è¶…æ—¶"),
    parallels: Annotated[List[int], "å¹¶è¡Œæ•°"] = typer.Option([1], help="å¹¶è¡Œæ•°"),
    n: int = typer.Option(1, help="è¯·æ±‚æ•°")
):
    data = {'Parallel': [], 'Average QPS': [], 'Average latency': [], 'Throughput': []}

    for parallel in parallels:
        print(f'Running with parallel={parallel}')
        output = run_evalscope(url, model, dataset_path, max_prompt_length, stop, read_timeout, parallel, n)
        metrics = parse_output(output)
        data['Parallel'].append(parallel)
        data['Average QPS'].append(metrics.get('Average QPS', 0))
        data['Average latency'].append(metrics.get('Average latency', 0))
        data['Throughput'].append(metrics.get('Throughput', 0))

    # ç»˜åˆ¶å­å›¾
    fig, axs = plt.subplots(2, 2, figsize=(18, 9))

    axs[0, 0].plot(data['Parallel'], data['Average QPS'], marker='o')
    axs[0, 0].set_title('Average QPS vs Parallel Number')
    axs[0, 0].set_xlabel('Parallel Number')
    axs[0, 0].set_ylabel('Average QPS')

    axs[0, 1].plot(data['Parallel'], data['Average latency'], marker='o', color='orange')
    axs[0, 1].set_title('Average Latency vs Parallel Number')
    axs[0, 1].set_xlabel('Parallel Number')
    axs[0, 1].set_ylabel('Average Latency (s)')

    axs[1, 0].plot(data['Parallel'], data['Throughput'], marker='o', color='green')
    axs[1, 0].set_title('Throughput vs Parallel Number')
    axs[1, 0].set_xlabel('Parallel Number')
    axs[1, 0].set_ylabel('Throughput (token/s)')

    fig.delaxes(axs[1, 1])  # Remove the empty subplot

    plt.tight_layout()
    plt.savefig('performance_metrics.png')

if __name__ == "__main__":
    app()
```

### README.md
```markdown
evalscope-perf: Model inference performance stress test
```

### pyproject.toml
```toml
[build-system]
requires = ["setuptools>=42", "wheel"]
build-backend = "setuptools.build_meta"
```

### setup.py
```python
from setuptools import setup, find_packages

import os

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
this_directory = os.path.abspath(os.path.dirname(__file__))

# è¯»å– README.md å†…å®¹
with open(os.path.join(this_directory, "README.md"), encoding="utf-8") as fh:
    long_description = fh.read()

setup(
    name='evalscope-perf',
    version='0.1.2',
    author = 'Junjian Wang',
    author_email = 'vwarship@163.com',
    description = 'å¤§æ¨¡å‹æ€§èƒ½å‹æµ‹å¯è§†åŒ–',
    long_description = long_description,
    long_description_content_type = 'text/markdown',
    url = 'http://www.wangjunjian.com',
    packages=find_packages(),
    install_requires=[
        # åœ¨è¿™é‡Œæ·»åŠ ä½ çš„ä¾èµ–åŒ…ï¼Œä¾‹å¦‚ï¼š
        # 'requests',
        'typer',
        'pandas',
        'matplotlib',
        # 'evalscope',  # å¤ªå¤§äº†ï¼Œä¸å»ºè®®ç›´æ¥ä¾èµ–
    ],
    entry_points={
        'console_scripts': [
            # åœ¨è¿™é‡Œæ·»åŠ ä½ çš„å‘½ä»¤è¡Œå·¥å…·ï¼Œä¾‹å¦‚ï¼š
            'evalscope-perf=evalscope_perf.main:app',
        ],
    },
    classifiers=[
        "Programming Language :: Python :: 3",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
    python_requires='>=3.6',
)
```
**ğŸ“Œ è¿™é‡Œè¦æ³¨æ„å‘½ä»¤è¡Œ `evalscope-perf=evalscope_perf.main:app` ä½¿ç”¨çš„æ˜¯ `app`**

å¦‚æœéœ€è¦å¢åŠ é Python ä»£ç çš„æ–‡ä»¶ï¼Œå¯ä»¥åœ¨ `setup.py` ä¸­æ·»åŠ  `package_data` å­—æ®µï¼Œä¾‹å¦‚ï¼š
```python
    include_package_data=True,
    package_data={
        'evalscope_perf': ['assets/*.*'],
    },
```


## å¼€å‘
### ç”Ÿæˆæºä»£ç åˆ†å‘åŒ…
```shell
python setup.py sdist
```

### å®‰è£…æºä»£ç åˆ†å‘åŒ…
```shell
pip install -e .
```
- `-e` `--editable` è¡¨ç¤ºå®‰è£…åˆ°å½“å‰ç›®å½•ï¼Œæ–¹ä¾¿å¼€å‘æ—¶ä¿®æ”¹ä»£ç åç«‹å³ç”Ÿæ•ˆã€‚


## æ‰“åŒ… Python å·¥ç¨‹
### åŒæ—¶ç”Ÿæˆæºä»£ç å’ŒäºŒè¿›åˆ¶ wheel åˆ†å‘åŒ…
```shell
python setup.py sdist bdist_wheel
```
- sdist
    - åŠŸèƒ½ï¼šç”Ÿæˆæºä»£ç åˆ†å‘åŒ…ã€‚
    - äº§ç‰©ï¼šé€šå¸¸ä¸º .tar.gz æˆ– .zip æ–‡ä»¶ï¼ŒåŒ…å«é¡¹ç›®çš„æºä»£ç ã€‚
    - ç”¨é€”ï¼šç”¨æˆ·å¯ä»¥é€šè¿‡æºä»£ç å®‰è£…åŒ…ï¼Œé€‚ç”¨äºæ‰€æœ‰å¹³å°ã€‚
- bdist_wheel
    - åŠŸèƒ½ï¼šç”ŸæˆäºŒè¿›åˆ¶ whell åŒ…ã€‚
    - äº§ç‰©ï¼š.whl æ–‡ä»¶ï¼Œé¢„ç¼–è¯‘çš„åŒ…ï¼ŒåŒ…å«äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ã€‚
    - ç”¨é€”ï¼šåŠ å¿«å®‰è£…é€Ÿåº¦ï¼Œé€‚ç”¨äºæ”¯æŒçš„ç‰¹å®šå¹³å°å’ŒPythonç‰ˆæœ¬ã€‚

åŒæ—¶ç”Ÿæˆæºä»£ç å’ŒäºŒè¿›åˆ¶ wheel åˆ†å‘åŒ…çš„ä¼˜ç‚¹ï¼šæä¾›æ›´çµæ´»çš„å®‰è£…é€‰é¡¹ï¼Œæ»¡è¶³ä¸åŒç”¨æˆ·çš„éœ€æ±‚ã€‚


## å‘å¸ƒ Python å·¥ç¨‹åˆ° PyPI
### å®‰è£… twine
```shell
pip install twine
```

### æ³¨å†Œ PyPI è´¦å·
- [https://pypi.org/account/register/](https://pypi.org/account/register/)
- æ³¨å†Œåï¼Œç™»å½•åˆ° [https://pypi.org/account/login/](https://pypi.org/account/login/)ï¼Œåˆ›å»ºä¸€ä¸ª `API token`ã€‚

### ç¼–è¾‘ PyPI é…ç½®æ–‡ä»¶ ~/.pypirc
```ini
[pypi]
  username = __token__
  password = pypi-api-token_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

### ä¸Šä¼ åŒ…åˆ° PyPI
```shell
twine upload dist/*
```
- `dist/*` è¡¨ç¤ºä¸Šä¼  dist ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ã€‚


## å®‰è£…å‘å¸ƒçš„åŒ…
```shell
pip install evalscope-perf -i https://pypi.org/simple
```


## evalscope-perf ä½¿ç”¨ç¤ºä¾‹

```bash
evalscope-perf http://127.0.0.1:8000/v1/chat/completions lnsoft-chat \
    ./datasets/open_qa.jsonl \
    --read-timeout=120 \
    --parallels 16 \
    --parallels 32 \
    --parallels 64 \
    --parallels 100 \
    --parallels 128 \
    --parallels 150 \
    --parallels 200 \
    --parallels 300 \
    --parallels 400 \
    --parallels 500 \
    --n 1000
```

### SGLang

![](/images/2025/StressTest/performance_metrics-sglang.png)


## å‚è€ƒèµ„æ–™
- [Packaging Python Projects](https://packaging.python.org/en/latest/tutorials/packaging-projects/)
- [huggingface_hub/setup.py](https://github.com/huggingface/huggingface_hub/blob/main/setup.py)
- [Typer - Multiple CLI Options](https://typer.tiangolo.com/tutorial/multiple-values/multiple-options/)
